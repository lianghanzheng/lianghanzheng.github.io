{"posts":[{"title":"Create remote repo for source code","text":"设置本地代码仓库重新初始化本地代码仓库 1git init 提交修改 1git commit -m &quot;&lt;info&gt;&quot; 一系列更新操作 1234git remote add origin https://github.com/lianghanzheng/BlogSrc.git# 更新到main分支git push -u origin main 此时github中也应该出现hexo本地代码。 后续更新时的操作依次执行以下命令 12345git add .git commit -m &quot;&lt;comment&gt;&quot;git push origin main 其它问题OpenSSL SSL_read: Connection was reset, errno 10054通过以下命令解决 12345678# 通过压缩的方式下载git config --global --add core.compression -1# 增大缓存大小git config --global http.postBuffer 524288000# 安全设置git config http.sslVerify &quot;false&quot;git config --global http.sslBackend &quot;openssl&quot; OpenSSL SSL_connect: Connection was reset in connection to github.com:443可能是因为科学上网的端口没有正确设置，查看一下用一下命令修改端口即可： 123git config --global http.proxy 127.0.0.1:7890git config --global https.proxy 127.0.0.1:7890","link":"/2023/08/24/HexoEstablish/Create-remote-repo-for-source-code/"},{"title":"Deploy Blog with Hexo","text":"通过Hexo部署本地博客并发布在github page上前置依赖 git Node.js 安装过程安装hexo1npm install hexo -g 配置ssh key接下来的所有命令默认在git bash上输入。 1ssh-keygen -t rsa -C &quot;&lt;email&gt;&quot; 之后狂按回车即可。 生成的秘钥位于 ~/.ssh/id_rsa.pub 中，将这个文件的内容复制到github个人账户的SSH and GPG Keys选项中。 检查秘钥是否配置成功。 1ssh -T git@github.com 配置账户与密码： 12git config --global user.name &quot;&lt;id&gt;&quot;git config --global user.email &quot;&lt;email&gt;&quot; 搭建博客初始化本地代码仓库： 1hexo init 编写一篇新的博客： 1hexo new &quot;&lt;title&gt;&quot; 博客对应的源文件位于目录 $BLOG_TOP/source/_post 中。 生成静态页面： 1hexo g 预览生成的内容： 1hexo s 配置到github page 显然，我自己已经创建了github page，所以创建page仓库的过程省略 在初始化的hexo blog代码仓库的 _config.yml 文件中添加以下内容 1234deploy: type: git repository: git@github.com:&lt;name&gt;/&lt;name&gt;.github.io.git branch: main 将 hexo g 生成的页面部署在github page中。 在仓库目录安装完 hexo-deployer-git 之后就可以远程部署到github page上了。 123npm install hexo-deployer-git --savehexo d","link":"/2023/08/24/HexoEstablish/Deploy-Blog-with-Hexo/"},{"title":"Theme Next Configure","text":"对Next主题进行自定义作者、版权信息等在自己目录的 _config.yml 中修改 Site 部分的内容，以我自己的博客为例： 12345678# Sitetitle: RRZ's Blogsubtitle: ''description: ''keywords:author: ReRoozenlanguage: zh-CNtimezone: '' 设置文章分类首先应该修改 themes/next/_config.yml 中的内容，取消下列行的注释： 123456789menu: home: / || fa fa-home #about: /about/ || fa fa-user tags: /tags/ || fa fa-tags categories: /categories/ || fa fa-th archives: /archives/ || fa fa-archive #schedule: /schedule/ || fa fa-calendar #sitemap: /sitemap.xml || fa fa-sitemap #commonweal: /404/ || fa fa-heartbeat 1hexo new page categories 该命令会产生一个 index.md 文件，这个文件用于存放分类，与一般的文档相比有着不同的 type，修改其内容如下： 12345---title: categoriesdate: 2023-08-25 16:08:42type: &quot;categories&quot;--- 之后在原本的博客的描述中添加以下 categories 信息，如下： 12345---title: Theme Next Configuredate: 2023-08-25 16:27:57categories: hexo---","link":"/2023/08/25/HexoEstablish/Theme-Next-Configure/"},{"title":"Vim的插件管理","text":"插件管理自动化工具安装vim-plug将github上仓库中的 plug.vim 置于 $HOME/.vim/autoload/plug.vim 即可. 管理方式在 ~/.vimrc 中添加如下内容. 12345678&quot; plugin managementcall plug#begin() Plug 'scrooloose/nerdtree'Plug 'tpope/vim-vinegar'Plug 'preservim/vim-markdown' call plug#end() 修改完成后,通过命令 :PlugInstall 自动下载插件. 修改源打开搜索编辑器搜索一下2行命令 123let fmt = get(g:, 'plug_url_format', 'https://git::@github.com/%s.git')&quot; ...\\ '^https://git::@github\\.com', https://github.com, '') 将 github.com 换成镜像即可.目前可用的镜像有 hub.fastgit.xyz. 手动安装方式遇见一些不能联网的机器也是可能的事情,因此有学习的必要. vim8原生的插件加载方式,为在 ~/vim/pack 搜索插件目录树. .vim/pack/&lt;dirname&gt;/opt 保存手动加载的插件 .vim/pack/&lt;dirname&gt;/start 保存始终加载的插件 &lt;dirname&gt; 可以是一个随便又好记的名字. 手动加载插件的命令为 :packadd &lt;dirname&gt;.","link":"/2023/09/18/vim/PluginsManagement/"},{"title":"Vim的模式","text":"Vim的模式正常模式打开vim后进入的模式.处于其它模式时,按1-2次ESC键即可返回正常模式. 命令行模式正常模式按下 : 后即可进入,输入命令敲下回车开始执行. 命令模式下,上下方向键可翻阅历史命令；ctrl+b跳至命令行开头；ctrl+e跳至命令行结尾；ctrl+f打开i命令行历史记录 (缓冲区),在命令上敲击Enter可以执行,按下ctrl+c可以对缓冲区编辑. 搜索字符串时敲击 / 或 ? 也是进入命令行模式. 插入模式按下i进入. 可视模式 按 v 进入字符可视模式 按 V 进入行可视模式 按ctrl+v进入块可视模式 替换模式按 R 进入.","link":"/2023/09/18/vim/ModesOfVim/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2023/08/24/vim/hello-world/"},{"title":"Git Essential","text":"概要一个VCS (Version Control System) 需要包含以下信息： 为每个文件和目录都保存一个版本信息 每次版本变更时的描述信息 展示每个版本变更时做出的改动 常用操作配置信息查看本地git的配置信息： 1git config --list 根据查看的可配置信息，能够按照以下格式进行修改： 1git config --global &lt;item&gt; &quot;your-value&quot; 比如说，配置用户名能够以下列方式进行： 1git config --global user.email &quot;abcd@gmail.com&quot; 创建git项目在命令行打开一个目录，然后输入 git init。该操作之后，目录出现了一个 .git 目录。这里保存了所有的历史信息。 查看状态命令 git status 能够查看哪些文件还没有通过 git add 追踪，以及哪些文件被 add 了但是还没有被提交。 每次commit之后，对文件的追踪会停止。 追踪文件状态在初始化后的目录中创建一个新的文件，但这个文件的版本信息并不会因为我们按下ctrl+s而自动被记录在git中，只有 git status 知道git仓库中多出来了一个未被追踪的文件。 为了让git能够追踪这个新的文件，应该使用命令 git add 显式地告诉git要追踪这个文件，并为当前的文件在staging area创建一个快照，使得程序员能够知道后续的修改相对记录的版本有哪些改动。 git已经和vscode很好地集成在一起了，看编辑器左边的条就知道了 但是真正想要创建一个新的版本，需要使用命令 git commit 进行提交。 git add . 能够很方便地将所有修改的文件都追踪，但是在大型项目中不要这么做，因为你可能会把没改完的其它文件也一起add了 但是有时候我们可能错误地将文件加入了staging area，这时候需要取消某些文件的追踪。 1234# 查看添加了哪些文件git status# 删除错误添加的文件git restore --staged filename 通过commit，我们能够完全撤销在那次commit之后的所有修改、 1git restore filename 查看每次commit命令 git log 允许我们查看每次commit都是谁做的，并且每个版本的哈希值和描述信息都是什么。 查看git中的修改命令 git diff 能够查看当前文件和上一次add之后的文件相比做出了哪些修改。 查看git维护了哪些文件的状态1git ls-files 从git仓库中移除文件12git rm filenamegit rm -r directory Tagging通常用来标记一个release版本。但是究其本质而言，只是对某个commit的引用 (不用hash值去查)，并没有保存额外的信息。 12345git tag version1.0.0git tag -a v2.2.2 -m &quot;description info of v2.2.2&quot;git tag -l &quot;v1*&quot;git tag --listgit tag --delets version1.0.0 .gitignore有时我们在项目中创建了一个临时文件来验证一些想法，因此我们并不希望这个文件被追踪。 创建 .gitignore 并在里面添加不希望被追踪的文件路径就能做到这点。 12345# dir 不需要提交的目录/node_modules# log 不需要提交的任意包含后缀名为log的文件*.log 远程仓库将本地仓库push到远程仓库首先我们需要将本地的仓库和远程仓库建立联系。 1git remote add origin your-remote-repository.git 在这里，origin 是为远程仓库起名，方便在上传的时候使用。同时 origin 也是默认的仓库名。当然，一个git本地仓库能够与多个远程仓库相关联，如git、gitee、gitlab等，因此可以给这些仓库取不同的名字。 完成关联后，下列命令能将本地仓库上传至远程： 1git push origin main 配置ssh key如果github仓库是public，那么所做的修改能够直接push上去。如果是private，那么需要进行一些额外的配置工作。 sshssh = secure shell 两点传输的过程中会对原始信息进行加密。常用的加密方法为RSA，包含私钥和公钥两个部分。但是这两个秘钥都可以用linux命令行工具 ssh-keygen 获取 (位于 ~/.ssh) 目录下。然后将公钥配置在github和账户中。 命令 clip &lt; id_rsa.pub 能够将内容复制到剪贴板上 github冲浪打开一个项目中具体的文件，raw会给出纯文本形式的代码，blame能提供精确到行的编辑信息，history能够显示每次commit。 Issue类似于一个TODO，多人合作时，类似你导给你该论文。 fork：合作开发远程操作点击 (别人的) 仓库页面上的fork按钮，就能够在自己的账户上获得一份该仓库的副本。 当我们为这个项目添加了额外的特性之后，我们在github的仓库中按下Pull request按钮进入预览页面后，再按下Create pull request就能够向原作者发起合并的请求。 本地操作命令 git clone 能够获得一份本地的版本。之后就能像本地仓库一样用 add、commit 进行管理，并通过 push 上传至 (自己的) 远程仓库。 但是如果想要和原作者的main分支合并，仍然需要回到github的仓库页面点击Pull request发起合并请求。 branch一般来说，main/master上一般保存稳定版，而进一步的开发工作一般都放在不同的分支上进行，等到所有的测试都完成再合并会main/master分支上。 12345678# 创建新的分支git branch &quot;a-new-branch&quot;# 显示所有的分支和当前所处于的分支git branch# 跳转到新的分支上git checkout a-new-branch# 上传到远程仓库的新分支git push orgin a-new-branch Workflow一个项目的workflow大致会分为一下几个阶段： 文件未被追踪 git开始追踪文件，但文件尚未被修改 git追踪到文件的修改 Staged/Indexed Commited：能够被追溯 Untracked State在编写项目时我们会创建种种文件：源代码、临时文件…而它们在初始时都不会被git追溯。因此，此时做出的所有改动，git都不会记录。 git status 对这类文件的描述是untracked files。 Tracking new files (staged state)命令 git add 会将文件从untracked状态转移到这个状态 (状态1转移到状态4)。 Staging modified files状态2的含义是文件内容与上一次commit的内容保持一致。 git status 不会显示该文件的信息。 如果此时对文件内容做出了修改，那么 git status 会显示该文件changes not staged for commit (状态2转移到状态3)。 进一步使用命令 git add 就能从状态3转移到状态4。 同时处于两个状态的文件如果一个文件在一次commit之后又add几次后，然后还有没有被add的修改信息，那么一个文件就会同时出于staged和unstaged状态 (状态3和状态4)。在staged area保存了上一次add之后的文件内容，在unstaged area保存了文件最新的内容。 Commit/Snapshotcommit之后会生成一个SHA-I值来标记这次commit，并能够从未来的版本回溯到这个版本。 Skipping staging areagit commit -a 能够将还没有add的文件也进入commit状态。 Branch and mergegit checkout -b 能够创建分支并跳转到新分支上。 我们现在可能正在一个dev分支上进行开发，并且还没有完成，而现在我们发现了一个bug需要修复。 那么可选的方案之一是回到上一次commit，然后打开一个新的isuue分支进行修复。 这篇博客 (https://www.liaoxuefeng.com/wiki/896043488029600/900388704535136) 里给出了一个基于 git stash 的方法 修复后的issue分支能够和其它分支merge。 Merge123456# 刚在issue分支修完buggit checkout master# 合并git merge issue# 删除issuegit branch -d issue merge背后的操作是master分支“向前”移动了一次，原来的issue成为了新的master。 但是现在master也只是修完了bug，和dev版本的关系并非父子节点而是兄弟节点。 12345678# 刚在dev分支开发完新功能git checkout master# 合并git merge dev# 查看现在的分支由哪些节点合并git log -1# 删除原本的devgit branch -d dev 尽管在命令上看不出什么差别，但是背后的操作却有区别。与亲代节点之间的直接替换不同，兄弟节点之间的合并会创建一个公共的子节点作为新的master节点。 冲突处理假设现在有一个文件 feature.py，在master分支上有以下内容： 123print(&quot;Hello&quot;)print(&quot;World&quot;)print(&quot;!&quot;) 随后在当前master分支创建一个issue分支 (兄弟)，并对 feature.py 内容做出修改并提交： 123print(&quot;Hello&quot;)print(&quot;Universe&quot;)print(&quot;!&quot;) 这个时候回到master分支又对 feature.py 做出修改并提交： 123print(&quot;Hello&quot;)print(&quot;Cosmos&quot;)print(&quot;!&quot;) 这个时候master与issue合并就会发生冲突——因为issue分支对同一个文件进行了修改。这个时候git cmd对分支的显示从 master 变成了 master|MERGING。打开冲突的文件 feature.py 能够看见不同分支下冲突的行。 进入冲突的文件，调整文件内容，删掉所有的分隔符，然后add又commit，即可恢复到 master。 其它零碎知识增补git statusvscode (和git集成) 打开git仓库后，进行开发工作时文件上会出现 M 等表示状态的字母。 M 在上一次add的基础上进行了修改 ?? 未追踪 A 一个新的加入staging area的文件 这些状态可以用 git status --short/git status -s 看到。 git log显示所有的commit信息。通过 -p 选项能够看到每次commit之间的变化。更详细的可以用 -stat 选项看。 1234# 最近三次的commitgit log -p -3# 过去三周的commitgit log --since=3.weeks git aliases类似Linux的 alias 命令。 1git config --global alias.&lt;alias-command&gt; &lt;actual-command&gt; 从git中删除文件即使将文件通过 rm 命令删除，使用 git ls-files 会发现该文件仍然被git追踪。但是再add一次就能让git停止追踪。 不过直接用 git rm 能够更直接达到相同效果。 在git中移动文件同样地，使用 mv 后再add一次就能够记录这样的变化。 直接用 git mv 能够达到相同的效果。","link":"/2023/10/06/git/Git-Essential/"},{"title":"Paper Writing","text":"论文写作规范本博客内容主要从《Science Research Writing: For Non-Native Speakers of English》中摘录并整理。 规范地撰写一篇论文是为了有效的传递信息。通过花费几秒钟阅读标题，读者应该能够获得一些信息；通过花费几十秒阅读Abstract，读者能够获得更多的一些信息；通过花费几分钟阅读Introduction/Conclusion，读者应该又能得到一些信息。论文中的每句话都应该能够传达出有效的信息。 撰写Introduction尽管论文是为了发表自己在实验中使用的方法与结果，但是一个Introduction却不能直接这样入手;方法和结果应该属于Methodology和Result这样的report section。 Introduction应该像一个漏斗一样：将话题从一个开放的话题过渡到自己工作的那一个点上。 主要语法与写作技巧 Tense pairs signalling language passive/activate use paragraphing Tense piars：不同时态表达的倾向性一般现在时vs.现在进行时一般现在时表达了一个长久的状态，而现在进行时则表达了一个临时的状态。因此一般现在时用来表达一个已经被广泛接受的结论或事实。但是所谓“广泛接受”的标准因人而异，最保险的方法是在使用一般现在时的句子中加上文献引用——毕竟能够发表出去的工作肯定也得到了部分人的承认。 类似地，在描述结果的时候也有一般现在时和一般过去时的抉择： We found that the pressure increased as the temperature rose, which indicated that temperature played a significant role in the process. We found that the pressure increases as the temperature rises, which indicates that temperature plays a significant role in the process. 毫无疑问，当我们用一般现在时描述我们的结果时显得我们对结果更加自信：我们描述的是一个能够被广泛接受的事实；而使用一般过去时则只是说明在实验限定的条件下产生了这样的结果。 一般过去时vs.现在完成时一般过去时表达了过去发生的事情并不影响现在的状态，现在完成时表明过去发生的事情对现在的状态持续产生影响。 I lived in Tokyo for five years…, (but I don’t live there anymore.) I have lived in Tokyo for five years…, ( and I still live there NOW.) Signalling language：连接句子在撰写论文时，可能从上一个句子到下一个句子中间，我们花费了10分钟来构思内容，然后才动笔。但是我们的读者看完上一个句子后却会立即看向下一个句子，如果没有良好的衔接，那么有可能读者会看的云里雾里。 重叠通过内容重叠对句子进行衔接： The pattern of inflammation during an asthma attack is diff erent from that seen in stable asthma. In stable asthma the total number of inflammatory cells does not increase. 这种通过重叠的衔接又派生除了三种形式：代词、分号和非限制定语从句。 使用代词进行衔接： Many researchers have suggested ways of reducing cost without affecting the quality of the image. These methods rely on data structures built during a preprocessing step. 使用分号进行衔接： The procedure for testing whether components are operationally safe usually takes many hours; this means that tests are rarely repeated. 使用非限制定语从句进行衔接： It has received much attention over the past few decades due to its biodegradable properties, which off er important economic benefits. 衔接词除了重叠之外，在句子间添加衔接词来表明两个句子之间递进关系 (therefore)、转折关系 (however) 也是常用的手段。如果作者没有通过衔接词来表达下一个句子的功能，那么读者处理这些信息就会很困难。e.g. 没有加上however，那么读者就会疑惑为什么上个句子在肯定某个事物，到了下个句子就开始否定，从而质疑整个段落内容。 一直使用however，therefore当然会令人感到单调，所以衔接词的积累也很重要。 表示原因：The experiment was unsuccessful ________ the measuring instruments were inaccurate. due to (the fact that) on account of (the fact that) in view of (the fact that) as because since since除了表示原因以外还可以引导时间状语，在可能产生歧义时替换掉 所有的衔接词最好都放在句首 表示结果：The measuring instruments were calibrated accurately, ________ the experiment was successful. which is why as a result (of which) therefore consquently hence so 表示转折或者差异：British students are all vegetarians, __________ Norwegian students eat meat every day. on the other hand by contrast however whereas but while on the contrary和conversely除了表示转折以外，还蕴含了“其反面才是正确的”含义，因此不能用来衔接给出的例句 while也能引导时间状语，所以注意不要在可能引起混淆的时候使用 表示出乎意料： _______ it was difficult, a solution was eventually found. _______ the difficulty, a solution was eventually found. It was difficult; ________ a solution was eventually found. 在这三种情况下分别可以用： a b c Although Even though Though Despite In spite of Regardless of Notwithstanding nevertheless however yet nonetheless even so still和anyway也能在这个使用情境下客串，但是这两个词也蕴含了更多信息 表示并列：We used a batch processing system because it was more effective; ___________ it was faster. in addition in the second place (etc.) what is more apart from that/which moreover furthermore also secondly besides也能表达类似的意思，但是它应该用在更有说服力的上下文中 被动语态和主动语态在论文中，we只能用来表示自己的研究团队，而绝不能表示宽泛的人类整体。如果想要指代一个广泛的人类群体，那么应该使用被动语态：It is known/thought that … 但是在学位论文中，因为没有共同署名的团队，所以不能用we。但是用I也是不能被接受的，此时应该使用This article/The present paper来表达自己的观点。 被动语态相较于主动语态的缺点在于表达观点的主体并没有被明示，所以类似于This article/The present paper这样的表述更不容易引起混淆，更适合放在Introduction中。 分段分段面临着两类主要的错误：1) 段落由零散的短句构成，或只是独立句子；2) 段落过长。 阅读的技巧在阅读一本推理小说的时候，如果提前看了最后一页，那么这本小说对读者的吸引力会迅速降低；但是如果坚持看完也能提高读者的阅读速度：因为读者知道了哪些信息是可以忽略的。 阅读论文同样也是如此，在面临一篇长文时，先浏览一遍获取文章的主题及关键内容的位置能够在正式阅读时更快进入主题。 阅读标题：对文章的内容有一个预期 看作者的名字和单位：对文件的价值有一个预期 检查数据：通过数据辅助理解文章内容 看摘要：获得文章的工作和结论 快速浏览第一个段落 快速浏览每个段落的第一句话 浏览每个图表及它们的标题 阅读最后一段 利用浏览的技巧辅助写作读者拥有这样的阅读习惯，那么我们当然能够在文章做出相应的设计。以第六条为例，在段落起始句交代这个段落的主要内容，其它的句子都用来支撑首句的观点。当内容偏离首句时，分段。 构建一个写作模型 介绍这个话题 (topic) 的重要性，e.g. much study in recent years (接现在完成时)或者a major role are common here (接一般现在时) 介绍这个重要的东西是什么/相关背景信息，从最可能被读者知道的背景入手，然后深入；另一方面，在这里也能有引用文献，但是最好是大佬的文章或者结论被广泛接受的文章 指出已有工作面临的挑战、问题的来源，但不是真正开始讲述自己的工作；收缩话题范围 开始以文献综述的方式从研究面切入研究点；文献可以按照三种顺序陈列：发表时间顺序、方法类型和通用-&gt;特定应用情景 指出现有工作的不足，并开始说明自己文章涉及的工作 对自己工作的方法和结果分别简单描述 书上将这几点进一步归纳为了四点： 明确研究的重要性/提供背景信息/陈述当前研究方向的热门关注点 给出关于这个话题的文献综述 指出现有工作的不足/说明自己解决的问题/提出在文章中将要验证的命题 概述这篇文章的方法与结论 我个人在分析Introduction结构时，对于长篇幅我更喜欢自己的六点分类，对于短篇幅书上的四点分类更好 词汇本书作者根据他自己的四点对提供的词组进行了分类。由于内容比较丰富，建议直接阅读原文。 撰写Methodology如前文提到的，Methodology是report的一部分。大部分出版商都会发布它们的Guide for Authors，并且都会有这样的一句话： The Methodology should contain suffi cient detail for readers to replicate the work done and obtain similar results. 虽然这个章节的目标是让其他人能够复现实验并得到相近的结果，但这并不意味着要在这一节像流水账一样地把做的事情全部记录下来。 对于一个开始着手第一篇论文的学生而言，之前的报告都是写给老师看的——一个比本人更懂这个话题的人。因此这样的报告主要是说明自己是否完成了老师布置的任务。 但是，撰写论文 (在理论上) 是让别人从自己这里学到东西。论文里提到的东西，对于别人来说可能是一个新方法，因此除了让别人能够复现结果以外，还要让别人能够接受这个新的方法。","link":"/2023/10/27/PaperWriting/Paper-Writing/"},{"title":"Kaleidoscope","text":"出于学习和工作需要，我将从学第三节开始的Kaleidoscope教程。第一节和第二节从原理上来说比较容易，但是实现起来比较繁琐，因此直接略过。 一份Kaleidoscope代码样例： 12345def fib(x) if x &lt; 3 then 1 else fib(x-1)+fib(x-2) 在Kaleidoscope中，数据类型只有double，所以 ExprAST 和函数的参数都没有记录类型信息。 Code generation setup相关组件每个表达式都能被赋给一个SSA变量，在份教程中，SSA变量以 codegen 方法的形式生成。 123456789101112131415161718192021222324252627282930313233343536373839404142434445class ExprAST { public: virtual ~ExprAST() = default; virtual Value *codegen() = 0;};class NumberASTExpr: public ExprAST {public: NumberExprAST(double Val): Val(Val) {} Value *codegen() override;private: double Val;};class VariableExprAST : public ExprAST {public: VariableExprAST(const std::string &amp;Name) : Name(Name) {} Value *codegen() override;private: std::string Name;};class BinaryExprAST : public ExprAST {public: BinaryExprAST(char Op, std::unique_ptr&lt;ExprAST&gt; LHS, std::unique_ptr&lt;ExprAST&gt; RHS) : Op(Op), LHS(std::move(LHS)), RHS(std::move(RHS)) {} Value *codegen() override;private: char Op; std::unique_ptr&lt;ExprAST&gt; LHS, RHS;};class CallExprAST : public ExprAST {public: CallExprAST(const std::string &amp;Callee, std::vector&lt;std::unique_ptr&lt;ExprAST&gt;&gt; Args) : Callee(Callee), Args(std::move(Args)) {} Value *codegen() override;private: std::string Callee; std::vector&lt;std::unique_ptr&lt;ExprAST&gt;&gt; Args;}; Q1：为什么SSA变量都是以裸指针的形式返回，而 ExprAST 都是以智能指针返回？ 接下来需要准备一些必要的数据结构，方便起见，它们都被声明为全局变量。 123456789101112131415161718192021222324#include &quot;llvm/ADT/APFloat.h&quot;#include &quot;llvm/ADT/STLExtras.h&quot;#include &quot;llvm/IR/BasicBlock.h&quot;#include &quot;llvm/IR/Constants.h&quot;#include &quot;llvm/IR/DerivedTypes.h&quot;#include &quot;llvm/IR/Function.h&quot;#include &quot;llvm/IR/IRBuilder.h&quot;#include &quot;llvm/IR/LLVMContext.h&quot;#include &quot;llvm/IR/Module.h&quot;#include &quot;llvm/IR/Type.h&quot;#include &quot;llvm/IR/Verifier.h&quot;#include &lt;algorithm&gt;#include &lt;cctype&gt;#include &lt;cstdio&gt;#include &lt;cstdlib&gt;#include &lt;map&gt;#include &lt;memory&gt;#include &lt;string&gt;#include &lt;vector&gt;static std::unique_ptr&lt;LLVMContext&gt; TheContext;static std::unique_ptr&lt;IRBuilder&lt;&gt;&gt; Builder(TheContext);static std::unique_ptr&lt;Module&gt; TheModule;static std::map&lt;std::string, Value *&gt; NamedValues; LLVMContext 中包含了LLVM的一些核心数据结构，如类型信息和符号表 IRBuilder 能够追踪IR文件/Module 的位置信息，并能够插入新的指令 Module 是LLVM IR的顶级结构，保存了解析文件中所有的IR NamedValues 需要追踪当前作用域中的定义的变量，记录代表它们的LLVM IR value A1：在上面的数据结构中，除了 NameValues 会保存 Value 指针，Module 保存IR时也会隐式地保存 Value 指针，所以应该使用裸指针作为返回值。 表达式的生成常量123Value *NumberExprAST::codegen() { return ConstantFP::get(*TheContext, APFloat(Val));} ConstantFP 是LLVM IR的数字常量，具体的值保存在 APFloat 的内部。因为在LLVM IR中所有的常量都使用一份资源，所以API使用的风格是 foo::get(...)而不是 new foo(...) 或者 foo::Create(...)。APFloat 含义为Arbitrary Precision Float，类似的数据结构都定义在$LLVM_TOP/llvm/include/llvm/ADT 目录中。使用正确的数据结构非常重要，这将会决定生成代码的内存开销和性能，内容可以参考https://www.llvm.org/docs/ProgrammersManual.html#picking-the-right-data-structure-for-a-task。 变量123456Value *VariableExprAST::codegen() { Value *V = NamedValues[Name]; if (!V) LogErrorV(&quot;Unknown variable name&quot;); return V;} 在这里我们假设变量的IR已经生成，其值已经生成并保存在 NamedValues 中。不过因为Kaleidoscope的简单性，只有函数的参数才会被保存在 NamedValues 中。不过在后面的章节中，还有循环索引的循环本地变量会被加入。 二元表达式12345678910111213141516171819202122Value *BinaryExprAST::codegen() { Value *L = LHS-&gt;codegen(); Value *R = RHS-&gt;codegen(); if (!L || !R) return nullptr; switch (Op) { case '+': return Builder-&gt;CreateFAdd(L, R, &quot;addtmp&quot;); case '-': return Builder-&gt;CreateFSub(L, R, &quot;subtmp&quot;); case '*': return Builder-&gt;CreateFMul(L, R, &quot;multmp&quot;); case '&lt;': L = Builder-&gt;CreateFCmpULT(L, R, &quot;cmptmp&quot;); // Convert bool 0/1 to double 0.0 or 1.0 return Builder-&gt;CreateUIToFP(L, Type::getDoubleTy(*TheContext), &quot;booltmp&quot;); default: return LogErrorV(&quot;invalid binary operator&quot;); }} 这里我们递归地生成了代码，但是 Builder 会为我们自动追踪代码的位置，因此我们只需要决定生成的代码的类型和操作数。如果我们生成了多个 addtmp 类型表达式，LLVM会自动添加数字后缀来保持命名的唯一性。 LLVM的 fcmp 指令的结果会保存在一个1位整型中。但是Kaleidoscope中只有浮点数，所以我们希望结果是0.0或者1.0，因此使用了 uitofp 转换类型 (使用 sitofp 会生成0.0和-0.1)。 (函数) 调用表达式1234567891011121314151617181920Value *CallExprAST::codegen() { // Look up the name in the global module table. Function *CalleeF = TheModule-&gt;getFunction(Callee); if (!CalleeF) { return LogErrorV(&quot;Unknown function referenced&quot;); } // If argument mismatch error. if (CalleeF-&gt;arg_size() != Args.size()) { return LogErrorV(&quot;Incorrect # arguments passed&quot;); } std::vector&lt;Value *&gt; ArgsV; for (unsigned i = 0, e = Args.size(); i != e; ++i) { ArgsV.push_back(Args[i]-&gt;codegen()); if (!ArgsV.back()) return nullptr; } return Builder-&gt;CreateCall(CalleeF, ArgsV, &quot;calltmp&quot;);}; 调用函数的第一步肯定是查表。Kaleidoscope并不能动态地创建函数，所以只能从全局的符号表中进行查找。因为LLVM与C语言的调用规范一致，所以标准库中的函数，如 sin 能够被直接调用。 扩展现有的表达式…将LLVM IR作为一门语言学习，学习里面的数据结构能够将Kaleidoscope扩展。教程网址：https://llvm.org/docs/LangRef.html 函数的生成1234567891011121314151617181920212223class PrototypeAST {public: PrototypeAST(const std::string &amp;Name, std::vector&lt;std::string&gt; Args) : Name(Name), Args(std::move(Args)) {} Function *codegen(); const std::string &amp;getName() const { return Name; }private: std::string Name; std::vector&lt;std::string&gt; Args;};class FunctionAST {public: FunctionAST(std::unique_ptr&lt;PrototypeAST&gt; Proto, std::unique_ptr&lt;ExprAST&gt; Body) : Proto(std::move(Proto)), Body(std::move(Body)) {} Function *codegen();private: std::unique_ptr&lt;PrototypeAST&gt; Proto; std::unique_ptr&lt;ExprAST&gt; Body;}; 函数原型和函数定义是区别于表达式 ExprAST 的另一类AST类型。并且 codegen 方法的实现上相较于表达式更加复杂 123456789101112131415161718Function *PrototypeAST::codegen() { // Make the function type: double (*func)(double, double) etc. std::vector&lt;Type *&gt; Doubles(Args.size(), Type::getDoubleTy(*TheContext)); FunctionType *FT = FunctionType::get(Type::getDoubleTy(*TheContext), Doubles, false); Function *F = Function::Create(FT, Function::ExternalLinkage, Name, TheModule.get()); // Set names for all arguments. unsigned Idx = 0; for (auto &amp;Arg: F-&gt;args()) { Arg.setName(Args[Idx++]); } return F;} 在LLVM IR中，所有的Type都是唯一的，所以获得一个类型信息都是用 get 方法。 在创建LLVM IR的Function对象时，ExternalLinkage 表示函数的定义可能出现在当前Module之外的地方。TheModule 是一个Module指针，传入Module本体将这个函数名注册在符号表中。为参数设置变量名并不必要，但是这样做带来的好处是使得LLVM IR也能有可读性。 Q2：这里只是构造了一个函数原型，为什么返回的却是一个完整的 Function * 呢？ 123456789101112131415161718192021222324252627282930Function *FunctionAST::codegen() { // First, check for an existing function from a previous 'extern' declaration. Function *TheFunction = TheModule-&gt;getFunction(Proto-&gt;getName()); if (!TheFunction) TheFunction = Proto-&gt;codegen(); if (!TheFunction) return nullptr; if (!TheFunction-&gt;empty()) { return (Function *)LogErrorV(&quot;Function cannot be redefined.&quot;); } // Create a new basic block to start insertion into. BasicBlock *BB = BasicBlock::Create(*TheContext, &quot;entry&quot;, TheFunction); Builder-&gt;SetInsertPointer(BB); // Record the function arguments in the NamedValues map. NamedValues.clear(); for (auto &amp;Arg: TheFunction-&gt;args()) { NamedValues[std::string(Arg.getName())] = &amp;Arg; } if (Value *RetVal = Body-&gt;codegen()) { // Finish off the function. Builder-&gt;CreateRet(RetVal); // Validate the generated code, checking for consistency. verifyFunction(*TheFunction); } return TheFunction;} 目前函数体只有一个计算返回值的表达式，直接用 Builder 创建一个ret语句即可，且只要一个基本块就足够了。verifyFunction 相当于对LLVM IR进行了一次静态检查。","link":"/2023/11/07/LLVM/Kaleidoscope/"},{"title":"2015","text":"https://llvm.org/devmtg/2015-10/#tutorials Creating an SPMD Vectorizer for OpenCL with LLVM@codeplay SPMD execution model On GPU Divide work between lanes of SIMD units (fine division) SIMD execution in lockstep On CPU Divide work between cores (coarse division) Sequential execution within a core SIMD lane: execution of one instance of a vectorized kernel SIMD width: length of parallel lanes $N$ Packet: Map 1 value of origin function to $N$ value, one per SIMD lane Vectorization vertical loops within a kernel horizental compute multiple work at the same time does not depend on intra special code patterns SPMD vectorizier Implementation Level: IR or MI?IR更加通用，但是不能用platform-specific特性；MachineInstr则相反。 同时实现：在IR层进行变换，生成CFG元数据，然后利用这些数据在后端进行MI-level预测。 Implementing a SPMD vectorizer pipeline design analysis Uniform value analysis (UVA) Divergence analysis SIDM width analysis … Packetization overviewFunctionality: $F \\stackrel{N}{\\rightarrow}VF_N$. uniform instructions can remain scalar, executed once per work-group dependso on UVA to know which instructions to vectorize Scalarization overview eliminate vector operations from source function vector types used likely to be narrower than the native SIDM width Control flow conversion overview lineraizes functions that have divergent control flow: conversions from control flow to data flow single program counter per SIMD group Main steps: divergence analysis generate masks freeze loop live variables apply masks convert phi nodes CFG linerization Polly - Optimistic Loop Nest Optimizations with Schedule Trees@ETH Models123for (i = 0; i &lt;= n; i++) for (j = 0; j &lt;= i; j++) S(i, j); $$\\begin{align*}&amp;\\mathcal{I}_S = { S(i, j) | 0 \\leq i \\leq n \\wedge 0 \\leq j \\leq i }\\ &amp;\\Theta_S = { S(i, j) \\rightarrow (i, j) }\\end{align*}$$ After interchange 123for (i = 0; i &lt;= n; i++) for (j = 0; j &lt;= i; j++) S(j, i); $$\\begin{align*}&amp;\\mathcal{I}_S = { S(i, j) | 0 \\leq i \\leq n \\wedge 0 \\leq j \\leq i }\\ &amp;\\Theta_S = { S(i, j) \\rightarrow (j, i) }\\end{align*}$$ The complete Polyhederal model: Iteration Space: set of all statement instances${ S(i, j) | 0 \\leq i, j \\leq n }$ScopStmt::getDomain() Schedule: Execution time${ S(i, j) \\rightarrow (i, j) }$ScopStmt::getSchedule() Access Relation: Memory read/write${ S(i, j) \\rightarrow A(i, j); S(i, j) \\rightarrow A(i, j+1) }$MemoryAccess::getRelation() 通过这些数据，我们能够计算： 数据依赖分析 访问的内存空间 Schedule trees","link":"/2023/12/01/LLVMDeveloperMeeting/2015/"},{"title":"2017","text":"https://llvm.org/devmtg/2017-03/ https://llvm.org/devmtg/2017-10/ Introduction to LLVM12345678910111213141516# compilationclang++ file.cpp# generate IRclang++ -S -emit-llvm file.cpp# run IRlli file.ll# generate binary form .bc of IRllvm-as file.ll# generate assembly from .bcllc file.bc# query availible targetsllc file.bc -mcpu=help# opt as analysis toolopt file.ll --time-passes# link two or more bitcode file into one filellvm-link file1.ll file2.ll -S -o output.ll Passes of LLVMAccording to granularity: module pass call graph pass function pass basic block pass … According to functionality: analysis pass transform pass Writing a function passSource code see here. 编写的pass放在 $LLVM_TOP/llvm/lib/Transforms/Hello 中。因为这个目录本来就包含于LLVM中，所以一切修改完成后只要在build目录下make即可。完成后在 build/lib 下能找到 LLVMHello.so。 Run the pass with opt12opt -load LLVMHello.so -hello &lt; hello.bc &gt; /dev/nullopt -load LLVMHello.so -hello &lt; hello.ll &gt; /dev/null LLVM还能输出图片形式的CFG 1opt -dot-cfg-only file.ll &gt; /dev/null 入手LLVM的建议 打开doxygen文档 grep --include=&quot;*.cpp&quot; -nr &quot;getInstructions()&quot; 来查询某一个函数的用法 Dynamic analysisInject code to moniter or change behaviou of codes. Write hook or profiling code Generate IR for hook Find the code to modify Time for module pass create a stub iterate the module make modification 这些都是基于 llvm-link 进行。 Weak Memory Concurrency in C/C++11 and LLVMARM Code Size OptimisationsSPIR-V infrastructure and its place in the LLVM ecosystem@ARM SPIR-V structure SPIR-V capabilities Memory model &amp; addressing model Entry point of kernels/shaders Difference between LLVM and SPIR-V Structured control flow Vulkan shaders require structure control flow OpenCL requires reducible control flow LLVM can produce irreducible control flow Reliance on metadata OepnCL relies on metadata to express semantics SPIR-V represents those as SPIR-V opcodes Uniform control flow SPIR-V has native opcodes to represent barrier operation and cross work-group operations LLVM introduce convergence function attribute to represent a similar concept Composible types Tooling (NOT official) spirv-opt spirv-assembler spirv-dis spirv-val spirv-cfg SPIRV-LLVM converter Bringing link-time optimization to the embedded world: (Thin)LTO with Linker Scriptslld: A Fast, Simple, and Portable LinkerWriting Great Machine Schedulers@ARM Instruction scheduling in LLVM “Legacy scheduler”: ScheduleDAGRRList Brings instruction DAG into a lineaer order of MIs “Newer”: MachineScheduler 目前主要的调度都在基本块内进行；全局调度仍然是一个等待解决的问题。 Pre-RA (Register Allocation) scheduling提前进行指令调度能够影响指令的活跃区间，从而减少寄存器占用，减少溢出操作。 RA这个时候可能会引入“读后写”假依赖关系。 Post RA scheduling根据资源约束、延迟进行调度。 GenericScheduler::tryCandidate多种方式设计调度策略： Top-down Bottom-up Bidirectional (default) tryCandidate 能根据启发式从中选取最好的一个策略。 physical register copies register pressure (excess and critical pressure) acyclic latency cluster resgister pressure (current max) latency source order Modelling pipeline for machine scheduler ScheduleDAGMI Scheduler TargetSchedModel Describe a machine model: For target: difines operand categories (SchedReadWrite), e.g. ARMSchedule.td associates categories with actual instructions, e.g. ARMInstrInfo.td For sub-target: defines description of pipeline and resources, e.g. ARMScheduleR52.td, def CortexR52Model : ShcedMachineModel {...} associates categories with resource and latencies, e.g. ARMScheduleR52.td, def AP2UnitALU: ... (resource consumed by writers), def : WriteRes&lt;WriteALU, [AP2UnitALU]&gt; {...} (associate resources and latency) TableGen debug12llvm-tblgen --debug-only=subtarget-emitter --print-records -I=$LLVM_TOP/llvm/include ...llc -enable-misched -debug-only=machine-scheduler Modeling for more specific hardware featureSubtarget override of specific opcodes define a new SchedWrite, named attached resource map list of opcodes to the SchedWrite 12345def PWriteSALU: SchedWriteRes&lt;[APUnitALU]&gt; { let Latency=4;}def : InsrRW&lt;[PWriteSALU, ReadALU], instregex &quot;CLZ&quot;&gt;; Customizing the MachineSchedulerCustomize scheduling policy Implement overrideSchedPolicy in subtarget Customize MachineSchedStrategy implementation Implement MachineSchedStrategy Register new strategy for target createMachineScheduler DAG mutationsThese allow adding scheduling constraints: Weak edges (cluster, artificial) Adjust dependence using target-specific knowledge Implemenmt DAG mutation (ScheduleDAGMutation) Register DAG mutation (createMachineScheduler) Welcome to the back-end: The LLVM machine representation@Apple LLVM Machine IR (MIR): Machine specific instructions Tasks Resource allocation Lowering ABI, exception handling, debug info, … Optimization: peephole, instruction/block scheduling … Tighten constraints pass pipeline Basics Writing an LLVM target Implement TargetMachine interface Code generation pipeline Pass manager setup TargetPassConfig Override the methods to add/remove/replace passes insertPass and substitutePass are also useful Instructions class MachineInstruction (MI) Opcode Pointer to Machine Basic Block Operand array Debugging location Operands class MachineOperand (MOP) Register &amp; register mask Immediates … Opecode class MCInstrDesc Flags (side effect, transformation hint, …) Basic blocks class MachineBasicBlock (MBB) Double linked list of instructions Numbered Arrays with predecessor/successor blocks with execution frenquency Functions class MachineFunction (MF) Double linked list of basic blocks Pointers to IR Function, TargetMahchine, MCContext, … State MachineResisterInfo, MachineFrameInfo, MachineConstantPoop, MachineJumpTableInfo Develop tips Produce .ll then use llc 12clang -S -O1 -emit-llvm a.c -o a.llllc a.ll Enable debug output 1llc -debug ... Debug output for passes foo and bar 1llc -debug-only=foo,bar ... Driven with clang 12clang -mllvm -debug-only=foo,bar ...clang -mllvm -print-machineinstrs ... Testing: MIR file format Stop after pass isel and write .mir file 1llc -stop-after=isel a.ll -o a.mir Load .mir file, run pass, write .mir file 1llc -run-pass=machine-shceduler a.mir -o a_scheduled.mir Load .mir file nad start code generation pipeline after pass isel 12llc -start-after=isel a.mir -o a.sllc -start-before=isel a.mir -o a.s Both -start-before and -start-after often fails Check a MIR whether is valid1llc -verify-machineinstrs ... Register allocationPhysical registers Defined by target typedef uint16_t MCPhysReg MachineRegisterInfo maintains list of uses and definitions per register Register classes are sets of registers Register constraints modeled with classes Virtual registers Managed by MachineRegisterInfo Both virtual and physical registers stored in unsigned MachineRegisterInfo::isVirtualRegister(Reg) v.s MachineRegisterInfo:isPhysicalResgister(Reg) Register == 0: No register used Representation with register flags12345; X86 rotate left%EDI&lt;def,tied1&gt; = ROL32rCL %EDI&lt;kill,tied0&gt;m %EFLAGS&lt;imp-def&gt;, %CL&lt;imp-use&gt;; equal to x86 assemblyroll %cl, %edi imp: implicite, not emitted tied: same register for Def+Use 12; X86 XOR/Zero register%EAX&lt;def,tied1&gt; = XOR32rr %EAX&lt;undef, tied0&gt;, %EAX&lt;undef&gt;, %EFLAGS&lt;imp-def&gt; undef: register value doesn’t matter 123; X86 Set 0/1%vreg0&lt;def&gt; = MOV32r0 ...%vreg0:sub_8bit&lt;def&gt; = SETLr %EFLAGS&lt;imp-use&gt; subregindex: read/write part of a virtual register (anatomy to the relation between RAX/EAX/AX/AL/AH) Liveness indicator flags: dead and kill. 1CALL &lt;ga:@func&gt;, &lt;regmask %LR, %FP, %X19, %X20, ...&gt;, ... regmask: preserves %LR, %FP, %X19, %X20, clobber every other registers Liveness tracking Linearize program SlotIndexes maintains numbering of instructions Slots per instructions Register allocation tuning XXXRegisterInfo.td: adjust allocation order 12def GR32: RegisterClass&lt;&quot;X86&quot;, [i32], 32, (add EAX, ECX, EDX, ...)&gt; Set register class allocation priority 1234// Tuple of 2 32bit registersdef VReg_64 : RegisterClass&lt;&quot;AMDGPU&quot;, [i64], 32, (add VGPR_64)&gt; { let AllocationPriority = 2;} Hinting 1234class TargetRegisterInfo { // ... virtual void getRegAllocationHints(unsigned VirtReg, ArrayRef&lt;MCPhysReg Order, SmallVectorImpl&lt;MCPhysReg&gt; &amp;Hints, /*...*/);} Liveness tracking after register allocation Use LiveRegUnits/LivePhysRegs to compute liveness for instructions inside a block Prolog and epilog insertion pass123456class TargetFrameLowering { //... virtual void emitPrologue(MachineFunction &amp;MF, MachineBasicBlock &amp;MBB); virtual void emitEpilogue(MachineFunction &amp;MF, MachineBasicBlock &amp;MBB); virtual void determineCalleeSaves(MachineFunction &amp;MF, BitVector &amp;SavedRegs, /*...*/); virtual void processFunctionBeforeFrameFinalized(MachineFunction &amp;MF, /*...*/);} Setup call frames, setup stack frame Save/Restore callee saved registers resolve frame indexes register scavenging Last step of prolog epilog insertion simulate liveness in basic block, allocate virtual registers execute spills and reloadsRegScavenger::addScavengingFrameIndex(int FrameIndex) 1234567STRi12 %R1, &lt;fi#2&gt;, 0, ... ^ frame index, currently a placeholderSTRi12 %R1, %SP, 4104, ... ^ resolved frame index%verg0&lt;def&gt; = ADDri %SP, 4096, ...STRi12 %R1, %vreg0, 8, ... ^ may introduce temporary register","link":"/2023/11/30/LLVMDeveloperMeeting/2017/"},{"title":"2018","text":"https://llvm.org/devmtg/2018-04/ https://llvm.org/devmtg/2018-10/ Global code completion and architecture of clangdPorting Function merging pass to thinltoUnderstanding the performance of code using LLVM’s Machine Code Analyzer (llvm-mca)Implementing an OpenCL compiler for CPU in LLVMLoop Transformations in LLVM: The Good, the Bad, and the UglyMemory Tagging, how it improves C++ memory safety, and what does it mean for compiler optimizationsRevisiting Loop Fusion, and its place in the loop transformation frameworkHow to use LLVM to optimize your parallel programsLLVM backend development by example (RISC-V)","link":"/2023/12/01/LLVMDeveloperMeeting/2018/"},{"title":"2016","text":"https://llvm.org/devmtg/2016-03/ New LLD linker for ELFA closer look at ARM code sizeA journey of OpenCL 2.0 development in Clang@ARM C++ on Accelerators: Supporting Single-Source SYCL and HSA Programming Models Using Clang","link":"/2023/12/01/LLVMDeveloperMeeting/2016/"},{"title":"2020","text":"Code Size Compiler Optimizations and TechniquesCIL : Common MLIR Dialect for C/C++ and FortranEverything I know about debugging LLVMLLVM in a Bare Metal EnvironmentUnderstanding Changes made by a Pass in the Opt PipelineMLIR Tutorial","link":"/2023/12/01/LLVMDeveloperMeeting/2020/"},{"title":"2019","text":"MLIR: Multi-Level Intermediate Representation for Compiler InfrastructureWhy new compiler infrastructure?Swift: A higher level language Extra optimizations like closure optimization and reference counting optimization are needed LLVM IR are too low level to support that Have to introduce SIL IR CIL IR for modern Clang AST MIR IR for Rust AST Julia IR for Julia AST … MLIR Similar to LLVM IR Type system is extensible MLIR operations: opcode and location info everything an instruction has (oprands, attributes, …) MLIR Dialects Families of defined operations Set of defined operations Custom parser, printer, verifier Entirely custom type system Customization hooks An exmapleDeclarative Op definitions: Specified using TableGen Dialect can create own hierarchies Specify op properties Name input and output operands Document along with the op More than definition: Tranform the defined opertion into another mlir-opt mlir-translate - test data structure translations MLIR + Clang CIL: a high-level IR for Clang OpenMP dialect … Handling massive concurrency: Development of a programming model for GPU and CPUSYCL compiler: zero-cost abstraction and type safety for heterogeneous computingLoop Fusion, Loop Distribution and their Place in the Loop Optimization PipelineTutorial: Building a Compiler with MLIRA toy language123456def foo(a, b, c) { var c = a*b; print(transpose(c)); var d&lt;2, 4&gt; = v * foo(c); return d;} MLIR is all you need for lowering: Toy AST - MLIR dialect TIR - MLIR dialect LLVM IR - MLIR dialect PrimerOperation, no instruction表示 transpose 函数： 12%0 = &quot;toy.transpose&quot;(%arg1) : (!toy&lt;&quot;array&lt;2, 3&gt;&quot;&gt; -&gt; !toy&lt;&quot;array&lt;3, 2&gt;&quot;&gt; loc(&quot;test/codegen.toy&quot;:3:14)) 对应的MLIR源代码为： 12345678910111213Operation *creteTransposeOp(FuncBuilder *builder, MLIRContext *ctx, Value *input_array, Location location) { // bundle our custom type in a `toy` dialect auto toyDialect = Identifier::get(&quot;toy&quot;, ctx); // create custom type for array&lt;3, 2&gt; auto type = OpaqueType::get(toyDialect, &quot;array&lt;3, 2&gt;&quot;, ctx); // Fill in the `OperationState` with the required fields. OperationState result(ctx, location, &quot;toy.transpose&quot;); results.type.push_back(type); // return type; result.operands.push_back(input_value); // arguments Operation *newTransposeOp = builder-&gt;createOperation(result); return newTransposeOp;} A MLIR dialect includes: A prefix (toy) A list of custom types, each its C++ class A list of operations and C++ class implementation: Verify for operation invariants Semantics (has-no-effects, constant-foldingm CSE-allowed, …) Possible custom parser and assembly printer Passes: analysis, transformations, and dialect conversions High-level transformation123def no_op(b) { return transpose(transpose(b))} 这里实际上无事发生，但是clang中解析出的依赖分析并不能消除这个无效操作。 123456789101112131415161718192021struct SimplifyRedundantTranspose: public RewritePattern { // register pattern to match every toy.transpose in the IR SimplifyRedundantTranspose(MLIRContext *ctx): RewritePattern(TransposeOp::getOperationName(), /* benefit = */ 1, context) {} PatternMatchResult matchAndRewrite(Operation *op, PatternRewriter &amp;rewriter) const override { // directly cast current operation TransposeOp transpose = op-&gt;cast&lt;TransposeOp&gt;(); // look through the input mlir::Value *transposeInput = transpose.getOperand(); mlir::Operation *transposeInputInst = transposeInput-&gt;getDefiningOp(); // Input is defined by another transpose, match it! TransposeOp transposeInputOp = dyn_cast_or_null&lt;TransposeOp&gt;(transposeInput); if (!transposeInputOp) return matchFailure; // rewrite and performe replacement rewriter.replaceOp(op, { transposeInputOp.getOperand() }, { transposeInputOp }); return matchSuccess(); }}; 这个定义也能够用TableGen进行表达，而且比较简单。 Lowering dialect to LLVMConvert to the standard dialect for codegen or any other dialect: Function signature conversion Type conversion Operation conversion Building an LLVM-based tool: lessons learnedLLVM IR Tutorial - Phis, GEPs and other things, oh my!@Intel LLVM IR RISC-like Target infoIR123target datalayout = &quot;e-m:e-i64:64-f80:128-n8:16:32:64-S128&quot;target triple = &quot;x86_64-unknown-linux-gnu&quot; Data layout: “little endian-ELF mangling-ABI alignment of i64-?-Native interger widths-?” Target: “Architecture-vendor-system-ABI” Baisc program Types everywhere NO implicit conversions opt -verify input.ll 用来检查LLVM IR中类型是否正确 Instructions have many variants CFG 因分支指令产生 br ret 每个基本块都由名字 不一定是显式的，如 %0 也能作为名字，且变量不能重复使用这个名字 打印一个CFG： 1234# Don't include instructions per blockopt -analysis -dot-cfg-only input.ll# Include instrcutionsopt -analysis -dot-cfg input.ll 一个for循环12345678define i32 @foo(i32 %val){entry: ...check_for_condition: ...for body: ...} 数组变量： IR12%i.addr = alloca i32store i32 2, i32* %i.addr 数组： IR123%array = global [10 x i32]// get element pointer instruction%new_ptr = getelementptr i32, i32* %array, i32 1 这里的指针是i32类型。 GEP操作IR123@a_gv = global [6 x i8] zeroinitilizer%new_ptr = getelementptr [6 x 18], [6 x i8]* @a_gv, i32 1%elem_pt = getelementptr [6 x i8], [6 x i8]* @a_gv, i32 0, i32 0 GEP NEVER load from memory. 这里的指针是一个数组类型。 两者之间的区别是，最后的偏移量每个单位的距离由基本类型执行，第一个 new_ptr 相当于 array[1]，第二个 new_ptr 相当于 a_gv[7]。 elem_pt 从 @a_gv 的0号 [6 x i8] 的分组中取出0号元素。 Aggregate typeIR123%MyStruct = type &lt;{ i8, i32, [3 x i32] }&gt;@a_gv = global %MyStruct { i8 99, i32 17, [i32 1, i32 2, i32 3] }%new_ptr = getelementptr %MyStruct*, %MyStruct* a_gv, i32 0, i32 2, i32 1 全局变量 使用 @ 开始而不是 % global keyword @gv = global i8 42 @gv = constant i8 42 Hot Cold Splitting Optimization Pass In LLVMWriting Loop Optimizations in LLVM@IBM TermsLoop representation: Preheader: A single edge to the header of the loop from outside of the loop Header: Single entry point to the loop that dominates all other blocks in the loop Exiting block: The block within the loop that has successors outside of the loop; if multiple blocks have such successors, this is NULL Latch: Block that contains the branch back to the loop header Exit block: The successor block of this loop. Loop closed SSA form循环中所有的使用的变量都是在循环内部定义的，这使得phi函数只能在循环的出口处被定义。 llvm::formLCSSA Rotated Loops Covert a loop into a do/while style loop Canonicalize loop latch to have a single predecessor When the compiler cannot prove loop body will excute &gt;=1, insert a guard It also inserts a loop epilogue, that will be excuted once after the body is finished executing 123456int A[100];int B[100];void example() { for (int i = 0; i &lt; 100; ++i) A[i] = i;} Loop pipeline Pipeline builder Passes enabled by switch (UnrollAndJam) Added passes, but do nothing bu default (LoopVectorize, LoopUnroll) Passes added in EP callbacks (Polly) Passes never added by pass builder Transformation order follows pass pipeline Eixpoint within LoopPassManager using Updater Non-loop passes in-between Some passes are FunctionPasses Loop pass v.s. function passConsider a FunctionPass first: Better maintained No LoopPassManager needed May require adding function analyses by proxy No requirement to preserve DominatorTree, LoopAnalysis, LoopSimplify, LCSSA Control over loop processing order / reprocessing behaviour Reasons to write a LoopPass: Apply multiple passes on same loop before processing nest i.a. Improved locality Share reprocessing behaviour with other loop passes Add pass at the Loop EP Callbacks Analysis used by other loop passes Demo: Basic loop optimization pass using new pass managerStep1: Basic loop optimization template进入网页点开Files changed LoopOptTutorial.h 和 LoopOptTutorial.cpp 共同创建了一个编译遍目前这个编译遍只是打印了哪些循环被传入了这个pass 对 LoopPassBuilder.cpp、PassRegistry.def 的修改将这个新编写的pass在管理器中注册 对 CMakeLists.txt 的修改让这个Pass被添加进项目中 simple.ll 和 loop_nest.ll 是测试样例 Step2: Select/Filter candidate loops 在Pass中增加了对Loop的检查，是否能够进行优化 Step3: Add code to split a candidate loop比较重要的成员函数： splitLoopInHalf：对满足条件的循环进行分裂 cloneLoop：复制一个循环 computeSplitPoint：计算分割点 Step4: Use DomTreeUpdater to update the dominator tree变换后的代码需要能够插入会原本的代码中进行更新。 Step5: Use STATISTICS and OpmizationRemarkEmitter to report outcome OptimizationRemarkAnalysis Dependence graphs Theory: Deendence Garphs and Compiler Optimizations (1981), D.J. Kuch et al. The Program Dependence Graph and Its Use in Optimizations (1987) J. Ferrante et al. Dependence graph types: Data Dependence Graph (DDG) Program Dependence Graph (PDG): also consider control flow An overview of LLVM","link":"/2023/12/01/LLVMDeveloperMeeting/2019/"},{"title":"2021","text":"FPL: A Presburger Library in MLIREnabling Interactive C++ with ClangDeconstructing the Myth: “Only real coders contribute to LLVM!”? - TakeawaysExtending LLVM’s optimization repertoire to build a highly optimizing compilerSPIR-V support in LLVM and Clang@Khronos group Similar to LLVM IR, BUT DIFFERENT! Core specifications, defined by the Khronos SPIR-V group Environment specifications, defined by the client API Can apply more restrictions to core specifications Extended instruction sets Extra instructions a client API can define Current state llvm-spirv text.bc -o test.spv spirv-link, spirv-opt, spirv-val from https://github.com/KhronosGroup/SPIRV-Toolsspirv-link -o app.spv test.spv Architecting out-of-tree LLVM projects using cmake","link":"/2023/12/01/LLVMDeveloperMeeting/2021/"},{"title":"2023","text":"MLIR Dialect Design@(Modular, Nvidia) Dialect procides contracts over the semantics of their ops, atributues, and types Type system is less malleable than operations MLIR compiler components： importer：从AST，ML编译器的图、bytecode等格式读取程序 funnel：将多种输入转换为统一的表示形式 legalizer &amp; optimizer specializer：将通用MLIR向目标平台特化 exporter：将MLIR表示转换为外部系统需要的格式，如LLVM IR 比如，tosa 属于legalizer的范畴；linalg, affine, scf 等属于optimizer的范畴；omp 属于specializer的范畴；llvm 属于funnel的范畴。 Extensible and Composable Dataflow Analysis in MLIRUsing MLIR to Optimize Basic Linear Algebraic SubprogramsMachineScheduler - fine grain resource allocation using resource intervalsPractical Global Merge Function with ThinLTOmlir-meminfo : A Memory Model for MLIRA whirlwind tour of the LLVM optimizerDeveloping BOLT pass","link":"/2023/12/01/LLVMDeveloperMeeting/2023/"},{"title":"2022","text":"Precise Polyhedral Analyses For MLIR using the FPL Presburger LibraryHow to write a new compiler driver? The LLVM Flang perspectivePaths towards unifying LLVM and MLIRHeterogeneous Debug Metadata in LLVMWhat does it take to run LLVM Buildbots?VAST: MLIR for program analysis of C/C++SPIR-V Backend in LLVM: Upstream and Beyond@Intel SPIR-V LLVM translator is a production-ready bi-direction “bridge” between LLVM IR and SPIR-V. SPIR-V is much closer to LLVM IR than to MIR Instruction Selection Relying on TabelGen as much as possible Type information folding No “real” registers in SPIR-V llvm-dialects: bringing dialects to the LLVM IR substrate","link":"/2023/12/01/LLVMDeveloperMeeting/2022/"},{"title":"CMake basics","text":"背景CMake本身并不是构建工具，而是构建工具生成器，是C++的工业标准之一。 历史原因，C++的包/库管理机制实在太落后了。 一个最基本的由CMake管理的C++项目模板的目录树如下所示： 12345.├── build├── CMakeLists.txt└── src └── main.cpp 在这样的一个目录树结构下，一组可能的用于构建的命令 1234567891011mkdir build# approach 1cd buildcmake ..cmake --build .# approach 2cmake -S . -B buildcd buildmake 在项目的根目录/主项目中会有一个顶层CMakeLists.txt文件。这个文件所在的目录在使用 cmake 进行配置 (configuration) 时需要作为 -S 选项的参数。在这个阶段，CMake会解析依赖项并生成构建指令，如Makefile或者ninja.build。之后再调用相关工具即可完成项目的构建。 一个最小的 CMakeLists.txt1234567891011cmake_minimum_required(VERSION 3.20)project( &quot;ToyProject&quot; VERSION 0.0 DESCRIPTION &quot;A mini CMake project&quot; LANGUAGES CXX)add_executable(toy)target_sources(toy PRIVATE src/main.cpp) cmake_minimum_required(VERSION 3.20) 选定CMake版本，在使用低版本时报错 project 描述项目的名称、版本号、描述信息、语言等基础信息 add_executable 告诉CMake我们要构建一个可执行文件 target_sources 指定可执行文件的源文件，并且通过 PRIVATE 限制了 main.cpp 仅对可执行文件 toy 可见 CMake的常见选项 -G 选择构建工具 Makefile ninja Visual Studio solution (.sln) … Source folder (-S) and Build folder (-B) source folder为顶级 CMakeLists.txt 所在的目录 build folder通常就叫 build，并且是 .gitignore 中的常客 当配置完成之后，build 中会出现与源目录中对应的文件结构，且每个子目录中都会生成一个 CMakeFiles 目录来记录构建时所需的信息。 CMake文件CMake的语法基于关键字和空白符分割的参数。类似于 set() 这样的叫命令。 projectCmake使用 project 对依赖库、可执行文件和测试等进行管理。根据语法规则，一个 CMakeLists.txt 文件中只能指定一个项目，因此不同的项目应该放在不同的目录中。 123456project( &quot;ToyProject&quot; VERSION 0.0 DESCRIPTION &quot;A mini CMake project&quot; LANGUAGES CXX) &quot;ToyProject&quot; 会被保存进变量 PROJECT_NAME。它表示当前项目名称。作为整个项目中的主项目，它也会被保存在 CMAKE_PROJECT_NAME 中。随着CMake的更新，变量的种类得到了丰富，如3.21版本中添加了 PROJECT_IS_TIO_LEVEL 变量来确定当前项目是否位于顶层目录中。 变量 (Variable)变量是CMake的核心，能够使用 set 和 unset 定义或者删除。其存在形式为字符串。 12set(VAR &quot;42&quot;)unset(VAR) 根据代码规范，变量最好全部使用大写字母和下划线命名。 访问变量时需要使用 ${}，如 ${VAR}。 变量拥有以下几类作用域： Function scope：函数内set的变量仅在函数体内可见 Directory scope：子目录 (子项目) 可见父目录中的变量 Persistent cache：在多次运行中可见 通过向 set() 中加入选项 PARENT_SCOPE 能够使子目录的变量在父目录中可见。 列表 (List)set() 能通过下列两种方式创建列表： 12set(LST abc def ghi)set(LST &quot;abc;def;ghi&quot;) 通过 list() 能够对列表进行一系列操作。 123list(FIND LST abc ABC_INDEX)list(GET LST ${ABC_INDEX} ABC)list(APPEND LST &quot;xyz&quot;) 缓存变量 (cached variable) 和选项 (option)为了提升多次构建的速度，CMake会将部分变量保存在 CMakeCache.txt。即使不去手动修改这个文件，它也会成为大量bug的来源。 TODO: 好像对于一般配置来说没啥用，这部分暂时先不细看了。 对于特殊的布尔类型的缓存变量，CMake提供了命令 option 令一个变量只有 ON 或者 OFF 两种值，默认为 OFF。有些类似于C中靠 -D&lt;MACRO&gt; 启动的宏编译选项，CMake中靠 -D&lt;VAR&gt;=ON 启用。CMakeDependentOption 模块提供命令来构建选项间的依赖关系。 123option(MINI_PROJ_OPT &quot;An example for our project&quot; OFF)include(CMakeDependentOption)cmake_dependent_option(PRINT_SWITCH &quot;print a message if ON&quot; ON MINI_PROJ_OPT ON) option 中的字符串起说明作用 include 加载CMake模块 如果 MINI_PROJ_OPT 为真，那么 PRINT_SWITCH 才会被置为真；后面的变量全是判定条件 性质 (Property)性质是与特殊对象关联的值。 TODO：略过。 循环 (loop) 和条件 (condition)1234# unary conditionif (DEFINED VAR)# binary testif (VAR STREQUAL &quot;FOO&quot;) 表示条件的一元关键字： COMMAND：VAR 是否为一个命令 EXISTS：VAR 表示的文件或者路径是否存在 DEFINED：VAR 是否为一个定义过的变量 IS_DIRECTORY IS_SYMLINK：VAR 是否为一个符号链接 IS_ABSOLUTE：VAR 是否为一个绝对路径 二元测试的关键字： LESS, GREATER, EQUAL, LESS_EQUAL, GREATER_EQUAL：比较数字值 STRLESS, STREQUAL, STRGREATER, STRLESS_EQUAL, STRGREATER_EQUAL：比较字面量 MATCHES：正则表达式匹配 版本号 … CMake也有 for 循环和 while 循环之分。 12345678910111213141516# while loopset(VAR 0)while(VAR LESS &quot;5&quot;) message(STATUS &quot;My VAT is '${VAR}'&quot;) math(EXPR VAR &quot;${VAR}+1&quot;)endwhile()# range-based loopforeach(ITEM IN LISTS MYLIST) # do something with ${ITEM}endforeach()# for loopforeach(ITEM RANGE 0 10) # do something with ${ITEM}endforeach() 函数 (function)123456function(foo ARG1) # do somethingendfunction()# invoke foo with parameter barfoo(&quot;bar&quot;) 宏 (macro)函数和宏的关系与C一致。用 macro() 和 endmacro() 定义。 目标 (target)创建目标需要使用以下命令： add_executable add_library add_custom_target 目标间可以指定依赖关系来调整构建顺序。 目标能够附加性质来改变其可见性： PRIVATE PUBLIC INTERFACE 生成器表达式 (generator expression)生成器表达式的基本形式为 $&lt;OPERATOR:VALUE&gt;，可以将其视为内联的 if 语句。下面例子给出了当编译器为GCC、Clang或者Apple Clang时添加编译选项 -Wall 添加到 my_target： 1234target_compile_options( my_target PRIVATE &quot;$&lt;$&lt;CXX_COMPILER_ID:GNU,Clang,AppleClang&gt;:-Wall&gt;&quot;) 构建类型 Debug：所有assert全部启动，相当于设置了 -O0 -g Release：相当于 -O3 -DNDEBUG RelWithDebInfo：取消断言但保留debug信息，相当于 -O2 -g -DNDEBUG MinSizeRel：针对二进制代码体积优化，相当于 -Os -DNDEBUG","link":"/2024/01/02/CMAKE/1-Basics/"},{"title":"CMake Interaction","text":"生成构建命令通常命令格式如下： 1234cmake -G [Ninja,&quot;Unix Makefiles&quot;] \\ -S &lt;project_root&gt; \\ -B &lt;build_path&gt; \\ -DCMAKE_INSTALL_PREFIX=&lt;install_path&gt; 其它常见选项有： 设置编译器 -DCMAKE_&lt;Lang&gt;_COMPILER=&lt;path&gt; 传入编译选项 -DCMAKE_&lt;Lang&gt;_FLAGS 查看缓存的CMake变量1cmake -LAH ./build 构建程序1cmake --build &lt;build_dir&gt; 只编译特定target --target &quot;&lt;target_name&gt;&quot; 移除上次编译的产物重新编译 --clean-first 产看CMake真正调用的命令 --verbose 并行编译 --parallel 安装项目基础命令为 1cmake --install &lt;build_dir&gt; 对二进制代码的strip编译二进制文件时，在最终的文件中可能会保存一些调试用的信息，而这些信息对于执行文件来说是没有的。 在安装阶段中可以添加 --strip 选项将这些信息和真正有用的代码分离，并可能在让体积的代码缩小。","link":"/2024/02/26/CMAKE/2-Interaction/"},{"title":"C++17 STL Solution","text":"STL Containersstd::vector以 $O(1)$ 的复杂度在没有排序的 vector 中删除元素事实上，正常的删除操作的复杂度依然是 $O(n)$。 123456vector&lt;int&gt; v {1, 2, 3, 2, 5, 2, 6, 2, 4, 8};{ const auto new_end (remove(begin(v), end(v), 2)); v.erase(new_end, end(v));} remove 函数移出元素是通过移位完成的：遇见需要删除的元素，将其后面一个元素搬运过来，并返回一个迭代器。因此在 remove 上的时间开销就是 $O(n)$。 1234567891011/* A possible implementation of remove. */template&lt;class ForwardIt, class T&gt;ForwardIt remove(ForwardIt first, ForwardIt last, const T&amp; value){ first = std::find(first, last, value); if (first != last) for (ForwardIt i = first; ++i != last;) if (!(*i == value)) *first++ = std::move(*i); return first;} 优化但是，如果不需要维护 vector 中的元素的顺序，我们则能够进行一定的特化使之复杂度降为 $O(1)$。因为原本复杂度为 $O(n)$ 的一个核心原因是为了填补前面元素的空缺，因此，直接把最后一个元素换位到删除的元素的位置即可。 1234567891011121314151617template &lt;typename T&gt;void quick_remove_at(std::vector&lt;T&gt; &amp;v, std::size_t idx) { if (idx &lt; v.size()) { v.at(idx) = std::move(v.back()); v.pop_back(); } }template &lt;typename T&gt;void quick_remove_at(std::vector&lt;T&gt; &amp;v, typename std::vector&lt;T&gt;::iterator it) { if (it != std::end(v)) { *it = std::move(v.back()); v.pop_back(); }} IteratorsLambda ExpressionsSTL Algorithm BasicsAdvanced Use of STL AlgorithmStrings, Stream Classes, and Regular ExpressionsUtility ClassesParallelism and Concurrency","link":"/2023/10/23/CPPBasics/C-17-STL-Solution/"},{"title":"Modern CPP (C++20) Review","text":"浏览器上的C++编译器 (可代码共享)TODO： Literals And Constantconstexprconstexpr 在C++11中加入标准，能够将一些计算工作从二进制文件执行期间卸载到编译期间进行，从而避免每次程序执行时都执行相同的运算。 constexpr 可以像变量一样被赋值。将 constexpr 作为返回值类型的函数同样要在编译时得到计算结果。但是在赋值时，从汇编代码来看，需要给 constexpr 的变量赋值才会在编译时计算结果，否则就像普通函数一样。 想要强制函数在编译时完成计算结果，需要使用关键字 consteval。 constinit作为类似 const 的修饰符，要求被修饰的变量必须在编译期间就完成初始化任务。既然要求了在编译期间完成，所以该修饰符只能对全局变量 (main 作用域之外) 使用才不会报错。 这个关键字的引入主要是为了避免初始化顺序带来的问题。 使用变量对 constinit 类型的变量初始化时，也应当使用 constinit 的变量。 StringRaw Literal String12345string todo {R&quot;(do homeworkplay paino...)&quot;}; 使用原始字面量的好处在于在写路径时可以不用关心如 \\ 是否需要转义。 如果原始字面量内部有 &quot;( 或者 )&quot;，那么可以通过 R&quot;---(&lt;raw ltr&gt;)---&quot; 这样添加若干短横线来变更起止标识。 string_viewstring_view 类似于 string 的浅复制版本，但是，如果后续对原始字符串进行修改，string_view 无法反映这些变化。其成员只有一个指针和一个长度，对 string_view 的一切修改只是在挪动指针 (头) 或者长度 (尾)，并且也不会对越界访问进行检查。 string_view 初始化时需要提供指针和字符串长度。对于字面量而言，其长度能够静态确定，所以不需要显式提供；对于 string，其长度能够用 size 方法确定；对于不是以 \\0 为结尾的 char 数组 (指针形式) 而言，则需要用手动传入。 1234567string_view sv {&quot;Hello&quot;};char *s_ptr { &quot;Hello&quot; };string_view sv {s_ptr};char s_ptr[] {'H', 'e', 'l', 'l', 'o'};string_view sv {s_ptr, std::size(s_ptr)}; string_view 就好像一个观察 string 的窗户 函数将 reference 作为返回值这种函数的返回值通常是其某个参数，函数返回的无非就是那个参数的引用。 可选返回值以字符串查找这类工作为例，成功时返回索引，失败时返回-1，这种函数的返回值就被叫做optional。 1234567int find_c(string &amp;str, char c) { if (...) { return idx; } else { return -1; } } 或者在参数中传入操作成功与否 1int find_c(string &amp;str, char c, bool &amp;success); std::optional初始化一个 std::optional 就像对其模板参数类型参数一样。访问其值的时候可以通过方法 value 获得。如果没有被赋值的话，std::optional 的值被置为 std::nullopt。方法 has_value 能够判定 std::optional 变量是否被赋值。 除此之外，在参数中也可以使用 std::optional 来检查参数的值。下面的例子相当于给 c 设置了一个默认参数。 1234std::optional&lt;int&gt; find_c(std::string &amp;str, std::optional&lt;char&gt; c) { char char_to_find = c.value_or('z'); ...} 匿名函数匿名函数 (lambda表达式) 的基础语法如下： 1[ capture-list ] ( params ) mutable(optional) exception(optional) attribute(optional) -&gt; ret(optional) { body }; 捕获列表不同于Python的闭包机制，C++匿名函数中能够使用的外部变量需要依靠捕获列表来指定。 捕获方式有两种：1) 按值捕获；2) 按引用捕获。 按值捕获有一个很奇妙的性质，就是捕获的变量会在匿名函数的定义的时候在作用域内增加一个复制了值的副本，导致外部变量后续更新时内部的副本不会变化。所以最好是按引用捕获。 1234int var = 3;auto func = [var](){ std::cout &lt;&lt; var &lt;&lt; std::endl; };var = 42;func(); 在这个例子中，func 的输出仍然是3。 捕获列表有两种特殊的形式，分别是 [=] 和 [&amp;]，前者表示将当前作用域内所有的变量都按值捕获——在一个复杂的文件中这个复制开销可能相当离谱。 当然，在不命名的情况下匿名函数也是可以使用的： 1[](int var) { cout &lt;&lt; var &lt;&lt; endl; } (3); inline 关键字inline 只会给编译器一个提示，并不能决定一个函数是否真的能够被内联。编译器只会对“简单的”函数进行内联，但是这个“简单”的标准实在有些模糊，需要进一步研究。 突然想到的一个问题，一个函数在循环中没有被内联会不会因为跳转指令的插入影响处理器的硬件流水调度呢 decltype 关键字decltype 的能力是进行类型的计算。 123int a;double b;decltype(a&gt;b ? a : b) c; 相比于 auto，decltype 能够显式地告诉程序员类型是如何推导出来的。 Template12template &lt;typaname T&gt;T maximum(T a, T, b) { return a&gt;b ? a : b; } C++模板函数在编译时会根据遇见的调用实例中的参数类型来生成具体的实现，因此C++模板不会缩减代码体积，但是减轻了程序员重载函数的负担。 在使用时，模板参数是能够显式或隐式地指定，如下： 12maximum&lt;int&gt;(a, b);maximum(a, b); 模板特化1234567891011template &lt;typename T&gt;T &amp;maximum(T &amp;a, T &amp;b) { return a&gt;b ? a : b; }// template specializationtemplate &lt;&gt;const char *maximum&lt;const char *&gt;(const char *a, const char *b){ return (std::strcmp(a, b) &gt; 0) ? a : b;} 编译器对模板和重载的选择12345678910111213141516171819// templatetemplate &lt;typename T&gt;T maximum(T a, T b){ return a&gt;b ? a : b;}// raw overloadconst char *maximum(const char *a, const char *b){ return (std::strcmp(a, b) &gt; 0) ? a : b;}// overload through templatetemplate &lt;typename T&gt;T *maximum(T *a, T *b) { return *a&gt;*b ? a : b; } 匹配的顺序如下：直接匹配 (2) -&gt; 根据是指针/变量分别匹配 (3)/(1) -&gt; 剩下的那个。 多个模板参数12345template &lt;typename ReT, typename T, typename P&gt;ReT maximum(T a, P b){ return a&gt;b ? a : b;} 这种情况下必须传入至少一个模板参数来指定 ReT 的类型，这是因为编译器无法静态地推断出 ReT 类型，导致无法生成相应的模板实例。 但是 auto 却能够根据自己的规则在编译时静态自动推断。auto 在这里的规则是根据 return 语句的内容选择 T 和 P 中较大的类型作为推断出的参数。因此在函数调用之前应当把实现给出，方便编译器使用 auto 进行类型推断。 12345template &lt;typename T, typename P&gt;auto maximum(T a, P b){ return a&gt;b ? a : b;} 这段例子给出了没有给出实现就用 auto 导致编译时报错的例子： 12345678910111213141516171819/* * Compile error */template &lt;class T, class P&gt;auto maximum(T a, P b);int main(){ int a = 1; double b = 3; auto m = maximum(a, b);}template &lt;class T, class P&gt;auto maximum(T a, P b){ return a&gt;b ? a : b;} 那么在这里使用 decltype 可以吗？答案是否定的。 12345678910111213template &lt;class T, class P&gt;decltype(a&gt;b ? a : b) maximum(T a, P b) ^ ^{ return a&gt;b ? a : b;}// Equal totemplate &lt;class T, class P&gt;decltype(auto) maximum(T a, P b){ return a&gt;b ? a : b;} 变量 a 和 b 的类型在参数列表中才会被推导出来，而 decltype 先于这两个变量的类型推断出现，导致会出现编译报错。 如果坚持使用 decltype 仍然是有补救措施的。通过trailing return type (后置返回类型) 能够得到下列的写法： 12345template &lt;class T, class P&gt;auto maximum(T a, P b) -&gt; decltype(a&gt;b ? a : b){ return a&gt;b ? a : b;} 这里 auto 只是起到了一个占位符的作用而不参与返回类型的推断中。这样的写法也解决了前文描述的定义和调用的顺序的问题： 123456789101112131415161718/* * Work */template &lt;class T, class P&gt;auto maximum(T a, P b) -&gt; decltype(a&gt;b ? a : b);int main(){ int a = 1; double b = 3; auto m = maximum(a, b);}template &lt;class T, class P&gt;auto maximum(T a, P b) -&gt; decltype(a&gt;b ? a : b){ return a&gt;b ? a : b;} 模板参数：不仅仅是类型除了类型以外，一般的值 (如 int) 也能作为参数传入模板中。 123456789template &lt;int threshold, typename T&gt;bool isValid(T collection[], size_t size){ T sum{}; for (size_t i = 0; i &lt; size; i++&gt;) { sum += collection[i]; } return sum&gt;threshold ? true : false;} 但是不管怎么说，模板里的内容需要编译时能够确定，因此不能够作为一般的参数列表的替代品。另一方面，非类型的模板参数收到了很大的限制，在C++20中这个限制得到了放松，但是在C++17及以前的标准中只有少量类型如 int 的值才能作为模板参数。 模板和匿名函数在C++20及以后的标准中，模板能够作用域匿名函数。 1auto func = []&lt;typename T&gt;(T a, T b) -&gt; T { return a+b; }; Type traits“A mechanism to query information about a (templated) type at compile time.” 123456#include &lt;type_traits&gt;// if type is int, the value will be truestd::is_integral&lt; type &gt;::value// Equal tostd::is_integral_v&lt; type &gt; 与 constexpr 结合在编译时消除分支12345678910template &lt;typename T&gt;void func(T t){ if constexpr(std::is_integral_v&lt;T&gt;) func_for_int(); else if constexpr(std::is_floating_point_v&lt;T&gt;) func_for_fp(); else static_assert(std::is_integral_v&lt;T&gt; || std::is_floating_point_v&lt;T&gt;, &quot;Arguments should be int or float&quot;);} 不过这种写法能不能消除这段代码的分支呢？ 123456789101112131415161718// a segment from lldMain of lld auto link = [&amp;args]() { Flavor f = parseFlavor(args); if (f == Gnu &amp;&amp; isPETarget(args)) return mingw::link; else if (f == Gnu) return elf::link; else if (f == WinLink) return coff::link; else if (f == Darwin) return macho::link; else if (f == Wasm) return lld::wasm::link; else die(&quot;lld is a generic driver.\\n&quot; &quot;Invoke ld.lld (Unix), ld64.lld (macOS), lld-link (Windows), wasm-ld&quot; &quot; (WebAssembly) instead&quot;);} (); C++20 ConceptC++模板为语言增加了泛型的能力，但是随之而来的问题也很明显：1) 模板参数没有成功匹配时的报错信息难以理解；2) 匹配的逻辑无法显式地由程序员指定，与编译器对模板的实现 (通常是SIFNAE机制) 耦合在一起；3) … Concept能够对模板参数进行限制，让模板以更安全更好用的方式运作起来，是C++20中最重要的四个特性之一。应用concept的写法相当的多，主要是以下五种： 12345678910111213141516171819202122232425template &lt;typename T&gt;requires std::integral&lt;T&gt;T add(T a, T b) { return a+b; }// Equal totemplate &lt;std::integral T&gt;T add(T a, T b) { return a+b; }// Equal to auto add(std::integral auto a, std::integral auto b) { return a+b;}// Equal totemplate &lt;typename T&gt;T add(T a, T b) requires std::integral&lt;T&gt; { return a+b; }// type trait also worktemplate &lt;typename T&gt;requires std::is_integral_v&lt;T&gt;T add(T a, T b) { return a+b; } requires 是C++关键字，引出了一个concept子句。当concept得到满足时，这个函数才会编译通过。 从上面的例子中不难看出，concept对于 auto 同样具有效力，其应用不仅局限于模板参数上 自定义concept这些自定义的concept反映出了一种鸭子类型的设计哲学——concept是一个能做某一些事情的类型集合。 1234567891011121314template &lt;typename T&gt;concept MyIntegral = std::is_integral_v&lt;T&gt;;template &lt;typename T&gt;concept Multipliable = requires (T a, T b) { a*b;};template &lt;typneame T&gt;concept Incrementable = requires (T a) { a+=1; ++a; a++;}; Concept除了上述的这些简单形式 (simple requirement) 以外，还有嵌套请求 (nested requirement) 和复合请求 (compound requirement)。 Nested requirement1234template &lt;typename T&gt;concept TinyType = requires (T t) { sizeof(T) &lt;= 4;} 在这个 requires 中，只会检查类型 T 在语法上能不能让 sizeof(T) &lt;= 4 成立，而不是要求一个类型大小不超过4字节。如果要限制一个类型大小不超过4字节，应该用下列嵌套 requires 写法： 12345template &lt;typename T&gt;concept TinyType = requires (T t) { sizeof(T) &lt;= 4; requires sizeof(T) &lt;= 4;} Compound requirement1234template &lt;typename T&gt;concept Addable = requires (T a, T b) { {a+b} noexcept -&gt; std::convertible_to&lt;int&gt;;} 组合concept在定义模板函数时，concept之间能够用逻辑运算符进行组合。不过这个写法是否有一些丑陋？ 12345678910111213141516template &lt;typename T&gt;concept TinyType = requires (T t) { sizeof(T) &lt;= 4; requires sizeof(T) &lt;= 4;}template &lt;typename T&gt;T func(T t)requires std::integral&lt;T&gt; &amp;&amp; requires (T t) { sizeof(T) &lt;= 4; requires sizeof(T) &lt;= 4; }{ ...} Class默认构造函数1234class MyClass {public: Myclass() = default;} 设置默认初始化函数为 default 能够保留在实例初始化时不传入参数 (连括号都不跟) 也能初始化的能力。 构造函数和析构函数的调用时机1234MyClass mc1(&quot;mc1&quot;);MyClass mc2(&quot;mc2&quot;);MyClass mc3(&quot;mc3&quot;);MyClass mc4(&quot;mc4&quot;); 其调用顺序如下所示： 12345678Constructor of mc1Constructor of mc2Constructor of mc3Constructor of mc4Destructor of mc4Destructor of mc3Destructor of mc2Destructor of mc1 这里构造函数调用的顺序是显而易见的，那么析构函数又是什么情况？虽然说，析构函数是在“生命周期”结束时调用，但是这个时间点又是如何断定的呢？ C++对于生命周期结束的判定是在一个作用域结束时判定的 (而不是数据流分析中那种精确到指令的分析，毕竟前端可不会进行数据流分析)，因此如果某个对象资源开销较大，通常会放在一个单独的代码块中 ({} 包围的) 使之能够及时将资源释放掉。同时，示例中的对象的创建是放在栈上的，所以根据后进先出，mc4 的析构函数最早被调用。 一个对象的大小只会统计成员变量的大小，成员函数会被单独编译。 const 对象在类这个层次来讲，加不加 const 关键字会产生不同的类型。下列给出的代码因为非法类型转换不能正确地运行，clang产生错误信息：error: binding reference of type 'MyClass' to value of type 'const MyClass' drops 'const' qualifier (clang的错误信息更加清晰)。 12const MyClass mc1(1);MyClass &amp;mc2 = mc1; 这种类型不匹配导致的一个严重的后果是：非 const 成员函数是不能被调用的。Python编写方法时都要显式地给出 self 参数；而C++中，this 参数的指定是编译器自动完成的；也就是说，当非 const 成员函数被调用时，this 只是一个 MyClass *，不能由 const Myclass 进行合法的赋值。这就是错误产生的原因。 structured bindings这个特性在C++17中加入。 1234struct Point { double x; double y };Point p {1.1, 2.2};auto [a, b] = p; initializer list v.s. member-wise initialize12345678910// initializer listPoint::Point(double x, double y) : x(x), y(y) {}// member-wise initializePoint::Point(double x, double y){ this-&gt;x = x; this-&gt;y = y;} 当代码执行进入构造函数的构造体时，其实对象已经创建完成了。而initializer list能够在创建对象的时期伴随对象创建的完成而完成 (this 已经能够使用)。不过使用initializer时，变量的顺序很重要。Point p {1.1, 2.2}; 也是在使用initializer list进行初始化 (顺序同样重要)。更详细的请参考 std::initializer_list。 总之，使用initializer list好处多多，只是暂时懒得整理了 initializer list的用法1234567struct Component { double x; double y; double z;};Component c1 {.x = 1.1, .z = 2.2}; 像数组或者类或者结构体这样的多元素的类型被统称为aggregate，它们都可以用 {} 初始化 类型转换 (explictt构造函数)12345678class Square {public: Square() = default; explicit Square(double s) { size = s; } int size;};double foo(Square &amp;s) { return s.size; } 此时 foo(11.4) 也是能够正常运行的，因为编译器会尝试用 explicit 修饰的那个构造函数创建对象，从而完成了类型转换。 静态成员变量静态成员被类的所有实例共享。那么显而易见地，静态成员的初始化也是独立于实例初始化而进行的 (out of line)。 123456class Point {public: static size_t point_cnt;};size_t Point::point_cnt {0}; 但是却不能像成员函数那样在类型声明时直接初始化 (inline)。 12345// Invalidclass Point {public: static size_t point_cnt = 0;}; inline 静态成员变量如果在成员变量前加上关键字 inline，那么就可以按照inline的方式初始化。 12345// Validclass Point {public: inline static size_t point_cnt = 0;}; const 静态成员变量除了关键字 inline 之外，关键字 const 也能让inline初始化不会报错。但是只局限于 int 和 enum 类型，其它的任何类型都不行。 static 成员变量初始化顺序存在不确定性，因此一个 static 成员变量的初始化不要依赖于另一个成员变量 静态成员函数静态成员函数同样独立于实例存在，所以它也不能访问除静态成员变量以外的成员变量。 嵌套的类1234class Outer {private: class Inner { ... };}; 智能指针使用智能指针需要头文件 memory。 unique_ptr1234std::unique_ptr&lt;Point&gt; p {1.1, 2.2};// Equal tostd::unique_ptr&lt;Point&gt; p = std::make_unique&lt;Point&gt;(1.1, 2.2); 但是 unique_ptr 不能被复制，那么在不是按照引用传参时，如果该类型作为函数参数则需要使用移动语义，并且在函数结束后被销毁。另一种方式是通过 make_unique 创建一个临时变量给函数使用。 不过如果试图在函数中返回一个在函数内创建的 unique_ptr 则是可行的。因为编译器对这种情况做出了调整，返回的不是副本而是一个类似引用/右值 (移动语义) 的对象，具体实现方式由编译器自己决定。 更准确的说，按照标准范式设计的STL库组件都进行了类似的实现 shared_ptrshared_ptr 指向对象的销毁发生在引用计数归零的时候。除了离开作用域后自动降低一个引用计数，还可以通过方法 reset 手动降低引用计数。 weak_ptr没有实现 -&gt; 和 * 运算符，这意味着无法使用 weak_ptr 读取或修改对象内的数据。通过方法 lock 能够获得一个 shared_ptr 从而使用 weak_ptr。 运算符重载完整的C++运算可以查看C++ Operator Precedence和operator overloading。 一元运算符 (unary) 二元运算符 (binary) 不管怎么说，C++重载运算符的水十分的深，建议多学习《Effective C++》。 作为成员函数的运算符重载123456class Point {public: Point operator+(const Point &amp;right) const { return Point(x+right.x, y+right.y); }}; 作为非成员的运算符重载1234567class Point { friend Point operator+ (const Point &amp;lft, const Point &amp;rgt); };inline Point operator+(const Point &amp;lft, const Point &amp;rgt) { return Point(x+right.x, y+right.y);} 对于编译器而言，所谓的运算符本质是这样的： 1234567p1 + p2;// Equal top1.operator+(p2);// Equal tooperator+(p1, p2); 下标运算符 []下标运算符其实是一个二元运算符。但是它特殊在必须以成员函数的形式实现。另一方面，下标操作符在读写时都会用到，所以返回一个引用还是一个变量值得稍微思考一下。 12345678class Point {public: // read only double operator[](size_t index) { assert((index == 0) || (index == 1)); return (index == 0) ? x : y; }}; 12345678910111213class Point {public: // read and write double &amp;operator[](size_t index) { assert((index == 0) || (index == 1)); return (index == 0) ? x : y; } const double &amp;operator[](size_t index) const { assert((index == 0) || (index == 1)); return (index == 0) ? x : y; }}; Stream insertion &lt;&lt;123456789class Point {public: friend std::ostream &amp;operator&lt;&lt;(std::ostream &amp;os, const Point &amp;point);};inline std::ostream &amp;operator&lt;&lt;(std::ostream &amp;os, const Point &amp;point) { os &lt;&lt; &quot;Point [ x: &quot; &lt;&lt; point.x &lt;&lt; &quot;, y : &quot; &lt;&lt; point.y &lt;&lt; &quot; ]&quot; &lt;&lt; std::endl; return os;} 成员函数的写法如下： 123456789101112131415#include &lt;iostream&gt;class Point {public: std::ostream&amp; operator&lt;&lt;(std::ostream&amp; os) { os &lt;&lt; &quot;(&quot; &lt;&lt; x &lt;&lt; &quot;, &quot; &lt;&lt; y &lt;&lt; &quot;)&quot;; return os; }};int main(){ Point p(1.1, 2.2); p &lt;&lt; std::cout;} 可以看见这种成员函数的写法在使用的时候非常狗血，因为 std::cout 是 &lt;&lt; 的第二个操作数。 定制类型转换比起使用 explicit 构造函数，通过重载类型转换能够减少编译器的不明确行为。 12345678910111213class Number {public: Number() = default; Number(int value): value(value) {} explicit operator double() const { return static_cast&lt;double&gt;(value); } explicit operator Point() const { return Point(static_cast&lt;double&gt;(value), 0.0f); }}; 二元运算符中的隐式转换这个问题的来源是，C++中如果一个二元运算符以成员函数的形式重载，那么左操作数 (调用方法的实例自身) 不会发生隐式类型转换。 123Number num {10};num+5; // okay5+num; // error ++ 运算符++ 放在操作数的前和后要用不同的方式重载： 1234567891011class Point {public: // prefix void operator++() { x++; y++; } // postfix void operator++(int) { Point tmp(*this); ++(*this); return tmp; }}; 后缀 ++ 的参数 int 就是拿来占位的 (dummy parameter)。 仿函数 (functor)本质上是对 () 运算符的重载。 关系/逻辑运算std::rel_ops 名称空间因为该名称空间的存在，所以只用实现 operator== 和 operator&lt; 就能够在动完成 != 等其它逻辑运算符的实现。使用该性质需要头文件 utility。 Three way comparison operartor &lt;=&gt;一次性判定两个对象是之间是大于、小于还是等于。 123int v1, v2;auto result = (v1 &lt;=&gt; v2); 尽管v1和v2都是 int，但是 result 并不是 int，只是能够和字面量0进行比较，通过该结果和0的序关系反映 v1 和 v2 的序关系。其具体类型为下面三种之一。 std::strong_ordering对相等的判定有唯一的标准，如 int。两个对象之间必然在 &lt;、&gt; 和 == 中有且仅有一个关系为真。 std::weak_ordering对相等判定可以由多个标准。两个对象之间必然在 &lt;、&gt; 和 == 中有且仅有一个关系为真。 std::partial_ordering偏序关系。前面两种都是全序关系。 默认的运算符重载1234class Item {public: bool operator ==(const Item &amp;rhs) const = default;}; 这样默认生成的方法会将成员变量逐个比较。 &lt;=&gt; 也能有类似的 default 实现，并且以该运算符为基础，编译器还能衍生出 &lt; 等运算符。 重载 &lt;=&gt; 运算符12345678910std::partial_ordering Point::operator&lt;=&gt;(const Point &amp;rhs) const { if (length() &gt; rhs.length()) return std::partial_ordering::greater; else if (length() == rhs.length()) return std::partial_ordering::equivalent; else if (length() &lt; rhs.length()) return std::partial_ordering::less; else return std::partial_ordering::unordered;} weak_ordering 的例子这里对相等关系的判定实现了两次。 123456789101112131415161718class ComparableString {public: ComparableString(const std::string &amp;str):m_str{str} {} std::weak_ordering operator &lt;=&gt;(const ComparableString &amp;rhs) const { if (m_str.size() == rhs.m_str.size()) { return std::weak_ordering::equivalent; } else if (m_str.size() &gt; rhs.m_str.size()) { return std::weak_ordering::greater; } else { return std:weak_ordering::less; } } bool operator ==(const ComparableString &amp;rhs) const { return m_str.size() == rhs.m_str.size(); }}; Summary If you want equality, and the default member wise lexicographical comparison is ok foryour design, then default the == operator, the compiler will generate the != for you If you want custom == , then set up your own non default operator== , and the compilerwill use that to synthesize the != for you If you want ordering (&gt;,&gt;=,&lt;,&lt;=), and default member wise, lexicographical comparisonis ok for your design, then default the &lt;=&gt; operator. The compiler will give you a freeoperator == . &lt;=&gt; will be used to generate the &gt;,&lt;=,&lt;,&lt;= operators and the == operatorused to generate the != operator If you want ordering, and default member wise lexicographical comparison doesn’twork for you, then you need to overload your own non default &lt;=&gt; operator. If you dothis, the compiler won’t generate a == operator for you though, you’ll need to put thatin yourself. The compiler will use these to generate all the 6 comparison operator 继承派生类能够直接访问基类中公开的成员，但不能直接访问私有成员。友元同理。 protected对于类自身，其行为类似于 private。但是在继承时能够被派生类访问。 弄清楚下列事实对理解多重继承有帮助 以 public 继承：所有成员访问等级不变 以 protected 继承：public 变成 protected 以 private 继承：所有成员都变成了 private 1class Gamer: public Person {}; 多态 (Polymorphism)所谓的多态就是通过基类指针或者引用来管理派生类的技术。 Managing derived objectes in memory through base pointers or references and getting the right method called on the base pointer or reference. 123class Shape {};class Oval: public Shape {};class Circle: public: Oval {}; 这三个类都可以作为下列函数的参数。 123void draw_shape(Shape *shape_ptr) { shape_ptr-&gt;draw();} 这里调用的方法 draw 都是 Shape 中的实现。这依靠继承中的静态绑定 (static binding) 特性实现。 其实C++中编译过程中，成员变量和成员函数都不是放在一起的，关键在于隐藏的 this 指针是什么类型就调用谁的方法 通过多态，我们甚至能够把这三中不同但又继承关系的类塞进同一个数组 Shape *shape_collection[] {&amp;shape1, &amp;oval1, &amp;circle1}。 虚函数虚函数提供了动态绑定的机制，使得我们能够对子类中的方法重新实现，从而在多态中使得派生类能够调用自己的新实现。 需要注意的是，因为调用的函数在运行时确定，所以会产生额外的时间开销。 通过与关键字 override 一起使用，表明这个方法是对基类方法的覆盖，能够避免拼写错误之类的问题。 1virtual void Circle::draw() const override {...} Slicing转换为基类后，所有的成员方法与成员变量都会被截取到和基类一样的程度。在派生类中新定义的成员变量在转换为基类后都无法被访问。 继承中的 static 成员static 成员被所有的实例共享，不仅如此，它们还被所有的派生类共享。但是派生类可以对原本的 static 成员进行覆盖，且不会影响基类中对应的成员。 final specifier1234class Oval: public Shape {public: void draw() const override final {...}}; 这里 final 的作用是在 Oval 的派生类中，方法 draw 不能被覆盖。 1class Circle final: public Oval {}; 这样使用 final 直接禁止 Circle 继续派生出其它的类。 final 和 override 都不是关键字，但是最好把它们当做关键字 You can do something doesn’t mean you should. virtual 析构函数1234class Shape {public: virtual ~Shape() {}}; 主要是为了避免使用多态的过程中，因为slice等原因资源没有被彻底释放的问题。 不要在构造函数和析构函数内部使用多态 (virtual) 函数 dynamic_cast在运行时，将基类的指针或者引用转换为派生类的指针或引用。这使得基类能够使用派生类中的非多态方法。 不过这个转换既有失败可能性，又发生在运行时，所以需要检查转换结果。但是C++只有空指针，没有空引用，所以转换时最好只转换指针方便进行检查。 突然想起来Clang AST里面的节点全是用的基类，想要查询信息都要使用 dynamic_cast 转换到对应类型来获取信息 typeid() 运算符123456// get the typenametypeid(int).name()// check typeint a;if (typeid(a) == typeid(int)) {} 对于多态而言，typeid() 对指针会返回静态绑定的类型 (基类)，而对解引用的指针或对象本身则会返回动态类型 (派生类)。 异常处理在进行错误检查时，我们有 static_assert, assert 和 std::cout。但是C++提供了异常处理特性使这个过程更加简便。 123456try { ... throw 0;} catch (int ex) {} throw 出来的对象可以被 catch 捕捉，并进入对应块中进行错误处理。如果 throw 的对象没有被任何 catch 块捕捉到就会引发程序崩溃 (本质是调用 exception 库中的 std::terminate()，而这个函数又会进一步调用 cstdio 中的 std:abort())。 throw 出来的对象必须要有复制构造函数 异常机制使得我们能够从错误中恢复并继续运行的机会，而不是直接被 assert 宣布死刑。 异常会被执行路径上最近的 block 块捕捉，即使 try 和 block 分别位于不同的函数中。 多态的异常类1234class Except {};class Warning: public Except {};class Error: public Except {};... noexcept 修饰符用该修饰符修饰的函数不允许异常外溢 (被函数体外部的 catch 块捕捉)。 这个修饰符在析构函数上很常见。如果出现了异常就退出的话，可能会导致资源没有彻底被释放干净，与析构函数的设计意图相矛盾。 标准异常库标准库 exception 中提供了三类基本异常类型 logic_error invalid_argument length_error out_of_range runtime_error overflow_error underflow_error others bad_alloc bad_cast 一般情况下使用方式如下： 1234567Shape s1;try { // conversion of a reference cause std::bad_cast Circle c1 {dynamic_cast&lt;Shape &amp;&gt;(s1)};} catch (std::exception &amp;ex) { std::cout &lt;&lt; ex.what() &lt;&lt; std::endl;} 如何从标准异常类 std::exception 中派生自己的异常类，需要实现虚函数 const char *what() const noexcept override {}。 123456789class MyErr: public std::exception {public: MyErr(int a): std::exception(), m_a(a) {} virtual const char *what() const noexcept override { return &quot;This is my_err&quot;; }private: int m_a {};}; 类模板这为实现多种类型的容器提供了语言的基础。 1234567891011template &lt;typename T&gt;class BoxContainer {public: BoxContainer&lt;T&gt;() = default; ~BoxContainer&lt;T&gt;(); void operator +=(const BoxContainer&lt;T&gt; &amp;oprand);};template &lt;typename T&gt;BoxContainer&lt;T&gt;::operator +=(const BoxContainer&lt;T&gt; &amp;oprand) {...} 在gcc 11、clang 12和msvc 2019及更高版本中，构造函数可以不用模板形式，即 BoxContainer() = default; 也能通过编译 非类型模板参数 (NTTP) 一般只有 int、size_t 这种简单类型。即使采用下列写法也不能绕开。 12template &lt;typename T, T threshold&gt;class Point {}; 但是每变更一个模板参数，编译器就会多创建一个新的模板实例。情况严重时会产生编译膨胀。 模板特化12345678template &lt;&gt;class Adder &lt;char *&gt; {public: Adder() {} char *add(char *a, char *b);};char *Adder&lt;char *&gt;::add(char *a, char *b) {} 对特定的方法特化12345678template &lt;typename T = int&gt;class Container {public: T get_max() const { ... }};template &lt;&gt; inlineconst char* BoxContainer&lt;const char *&gt;::get_max() const { ... } 模板类的友元1234template &lt;typename T&gt;class Container { friend std::ostream &amp;operator &lt;&lt; (std:ostreams &amp;, const Container&lt;T&gt; &amp;);}; 模板类和concept每个方法都要跟上类中规定的concept，有附加concept能加在函数定义之后。 12345678910111213template &lt;typename T&gt;requires std::is_default_constructible_v&lt;T&gt;class Container {};template &lt;typename T&gt;requires std::is_default_constructible_v&lt;T&gt;Container&lt;T&gt;::Container() {}template &lt;typename T&gt;requires std::is_default_constructible_v&lt;T&gt;Container&lt;T&gt;::Container(size_t capacity) requires std::copyable&lt;T&gt;{} 移动语义左值 (lvalue) 和右值 (rvalue)左值指的是在使用后仍然占据了一个地址的变量。 右值通常是临时变量，只会短暂地存在，并在系统不再需要之后立即销毁。 右值引用通过右值引用，能够延伸右值的生命周期，便于程序员进行额外的操作。 123int *res = &amp;(42 + 24); // errorint &amp;&amp;res = 42+24; // extends the lifetime of temporary result 但是右值引用在完成资源转移后需要手动销毁 (如移动构造函数)。 std::move左值也能够通过 std::move 转换为右值引用。 Move only type取消复制构造函数，而只保留移动构造函数的类。 123456template &lt;typename T&gt;class MyClass {public: MyClass&lt;T&gt;(const MyClass&lt;T&gt; &amp;src) = delete; MyClass(MyClass &amp;&amp;src);}; 在模板类中，移动构造函数不用跟 &lt;T&gt; 函数作为一等对象函数指针1234567double adder(double a, double b) { return a+b; }// the followings are all equivelentdouble (*f_ptr) (double, double) = &amp;adder;double (*f_ptr) (double, double) = adder;double (*f_ptr) (double, double) {adder} ;double (*f_ptr) (double, double) {&amp;adder}; 回调 (callback) 函数作为其它函数参数的函数。 函数指针别名函数指针的长度过长，会显著地影响可读性。因此C++的别名也支持了函数指针 (含模板函数)。 但是函数别名不能用 typedef 定义。 12345using myFunc = bool (*) (const int &amp;a, const int &amp;b);// template function aliastemplate &lt;typename T&gt;using cmp_T = bool (*)(const T&amp;, const T&amp;); 仿函数 (functor)重载了 () 运算符的类。 头文件 functional 中也定义了一些仿函数。 12345std::plus&lt;int&gt; adder;std::minus&lt;int&gt; substracter;std::greater&lt;int&gt; comp_greater;adder(10, 7); lambda表达式？仿函数！12int res = [] (int x, int y) { return x+y; } (4, 2);int res = [] (int x, int y) -&gt; int { return x+y; } (4, 2); 在调用这个lambda表达式的时候，C++会生成一个仿函数。在caprture list中捕获的变量都会成为这个仿函数的成员变量。 12345678910111213class RandName424242 {public: auto operator ()(int x, int y) const { return x+y; }};class RandName424242 {public: int operator ()(int x, int y) const { return x+y; }}; std::function1std::function&lt;char(const char&amp;)&gt; foo; 这里 foo 能接受任何返回类型为 char，参数类型为 const char &amp; 的函数的赋值等操作。至此，C++将函数视为了一等公民。 STL算法到了C++20标准后，STL算法库中的算法实现大致可以分为两类：1) Legacy algorithm：基于迭代器实现；2) Range algorithm：基于range语法实现，能够直接在容器上操作。 12std::vector&lt;int&gt; vec {1, 2, 3};std::ranges::sort(v); 比起在这里写一大堆笔记，更好的方法是用到的时候上网查cpp reference。 C++20 Range LibraryRange algorithm迭代器模式作为一种广泛应用在C++中的设计模式，其强大显然不证自明。然而作为程序员，在使用基于迭代器的算法时，最直接能感受到的一个问题是：使用起来太麻烦。查找一个元素是否在数组中，python可以写成： 1if elem in collections: ... 而C++中则需要写成： 1if (find(begin(collections), end(collections), elem) != end(collections)) {} 而使用 std::ranges 中算法实现则可以简化为： 1if (ranges::find(collections, elem) != end(collections)) {} Projection1class Point {}; 如果我们对 Point 类重载了 &lt;=&gt; 运算符，那么就可以用标准库中的仿函数 std::less&lt;&gt;() 产生一个序关系；不然就要加上一个lambda表达式作为projection。 123456std::ranges::sort(collections, std::less&lt;&gt;{}, [](auto const &amp;elem) { return elem.value;});// Equivlent tostd::ranges::sort(collections, std::less&lt;&gt;{}, &amp;MyClass::value); View and Range Adaptors一个view是一个无主的range，提供了一个观察数据的窗口，能够 以很低的代码复制并作为参数传入函数。 123std::vector vec {1, 2, 3, 4, 5, 6};auto evens = [] (int i) { return (i%2) == 0; };std::ranges::filter_view v_evens = std::ranges::filter_view(vec, evens); // No computation 其对于元素的检查发生在要查看view中的元素时。 可以理解为一种lazy的数据结构 View composition and pipe operator因为view本身不进行任何计算，所以可以利用这种思想构建一条多阶段计算的流水线，来进行图像处理一类的计算任务。 和Halide好像的想法 123std::vector&lt;int&gt; vec {1, 2, 3, 4, 5, 6};auto even = [] (int n) { return n % 2 == 0; };auto my_view = std::views::transform(std::views::filter(vec, even), [](auto n) { return n*n; }); 不过这种写法终究是太复杂了，所以C++提供了管道运算符。 1auto my_view = vec | std::views::filter(even) | std::views::transform([](auto n) { return n*n; }); Range factories用来创建views。 为自定义的容器添加迭代器通过为自定义的容器添加迭代器，能够使之与algorithm库和与ranges相关的语法兼容。 不同的函数对于迭代器的实现要求不同： std::find -&gt; input iterator std::fill -&gt; forward iterator std::reverse -&gt; bidirectional iterator std::sort -&gt; random access iterator 一般C++中涉及以下迭代器的设计，从低级到高级依次排序为： input iterator output iterator forward iterator bidirectional iterator random access iterator contiguous iterator (C++20) 前提条件 容器是一个模板类 容器定义迭代器类型 容器定义了 begin 和 end 方法并正确地返回了语义要求的迭代器 迭代器重载了算法中需要的运算 1234567891011121314151617181920template &lt;typename T&gt;requires std::is_default_constructible_v&lt;T&gt;class MyContainer { class Iterator { public: using iterator_category = std::input_iterator_tag; using difference_type = std::ptrdiff_t; using value_type = T; using pointer_type = T*; using reference_type = T&amp;; /* and operator overload */ // ... private: pointer_type m_ptr; }; Iterator begin() { return Iterator(&amp;my_list[0]); } Iterator end() { return Iterator(&amp;my_list[my_size]); }}; 定义input iteratorinput iterator只能单向向前移动，不能修改引用的元素。 12345678910111213141516171819202122class Iterator {public: // type aliases ... Iterator() = default; Iterator(pointer_type ptr) : m_ptr(ptr) {} reference_type operator *() const { return *m_ptr; } pointer_type operator -&gt;() { return m_ptr; } Iterator &amp;operator ++() { m_ptr++; return *this; } Iterator operator ++() { Iterator tmp = *this; ++(*this); return tmp; } friend bool opertoar ==(...) {...} friend bool opertoar !=(...) {...}private: pointer_type m_ptr;}; 定义output iterator和input iterator类似，但是对引用的对象有写的权力。 和input iteator在实现上的区别是 operator * 能够支持写操作。 定义forward iterator倘若迭代器位于正确的区间中，则能够正确地对内容进行读写。但只能前向移动。 定义bidirectional iterator有forward iterator的全部功能，并且能后向单步移动 operator --。 定义random access iterator拥有birectional iterator的全部能力，且能够通过 operator +/operator - 跳转固定步长而不仅仅局限于单步移动。 特有的方法有： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859Iterator &amp;operator +=(const different_type offset) { m_ptr += offset; return *this;}Iterator operator+(const different_type offset) const { Iterator tmp = *this; return tmp += offset;}Iterator operator -=(const different_type offset){ m_ptr -= offset; return *this;}Iterator operator-(const different_type offset) const{ Iterator tmp = *tmp; return tmp -= offset;}different_type operator -(const Iterator &amp;right) const{ return m_ptr - right.m_ptr;}reference_type operator [](const difference_type offset) const{ return *(*this+offset)l}bool operator &lt;(const Iterator &amp;right) const { return m_ptr &lt; right.m_ptr;}bool operator &gt;(const Iterator &amp;right) const{ return m_ptr &gt; right.m_ptr;}bool operator &lt;=(const Iterator &amp;right) const{ return !(*this &gt; right);}bool operator &gt;=(const Iterator &amp;right) const{ return !(*this &lt; right);}friend Iterator operator +(const difference_type offset, const Iterator &amp;it){ Iterator tmp = it; return tmp += offset;} const 迭代器主要的区别取类型别名时换成 const 类型。 1234567891011121314151617class ConstIterator {public: // ... using pointer_type = const T*; using reference_type = const T&amp;; // ...};Iterator begin() { ... }Iterator end() { ... }// pick up for const containersConstIterator begin() const { ... }ConstIterator end() const { ... }ConstIterator cbegin() const { ... }ConstIterator cend() const { ... } 裸指针作为迭代器也不是不行 协程 (Coroutines) (C++20)用于创建异步代码使得其能够更容易被使用。 能够被调用 能够返回一些东西 能够暂停和继续 第一印象和Python的生成器一样 1234567891011121314generator&lt;int&gt; generateNum(){ co_yield 10; // return 10 and pause co_yield 20; // the entry of 2nd call co_yield 30;}coro[int] func2() { int start {1}; while (true) { co_yield start; }} 关键字 co_yield：暂停执行并返回一个值 co_return：结束协程 co_await：暂停执行 如果函数定义中出现了上述关键字，那么它就是一个协程。 如果使用协程进行赋值，那么协程并不会立即开始执行，而是将计算过程赋值给变量。 12345678910111213core[int] do_work() { cout &lt;&lt; &quot;#1&quot; &lt;&lt; endl; co_await std::suspend_always {}; cout &lt;&lt; &quot;#2&quot; &lt;&lt; endl; co_await std::suspend_always {}; cout &lt;&lt; &quot;#3&quot; &lt;&lt; endl; co_await std::suspend_always {};}...auto task = do_work(); // lazy computation, freeze on the entrytask.resume(); // print #1... C++20 coroutine infrastructure promise type coroutine handle awaiter 一个标准的协程类型应该包含以下内容： 1234567891011121314151617struct CoreType { struct promiseType { CoreType get_return_object() { return CoreType(this); } std::suspend_always initialSuspend() { return {}; } std::suspend_always finalSuspend() noexcept { return {}; } void unhandledException() noexcept { std::rethrow_exception(std::current_exception()); } void return_void() {} }; CoreType(promise_type *p) : m_handle(std::coroutine_handle&lt;promise_type&gt;::from_promise(*p)) {} ~CoreType() { m_handle.destroy(); } std::coroutine_handle&lt;promise_type&gt; m_handle;}; 话说这种 rethrow 机制是不是异步代码都统一的异常处理方式啊，SYCL也是这种 但是C++标准库中并没有提供完整的协程类型，但是有望在C++23标准中得到支持，或者使用第三方库。 Modules使用 include 预处理指令面临以下问题： 编译速度 ODR冲突 引用顺序 … Module形式下，库的实现的后缀为 .ixx，意味interface，以此为基础创建一个BMI (Binary Module Interface)，供程序员以 import 的方式引用。","link":"/2023/08/25/CPPBasics/Modern-CPP-C-20-Review/"},{"title":"CPP Template Variable","text":"变量模板12345template &lt;typename T&gt;T v {};v_i&lt;int&gt;;v_d&lt;double&gt;; 两个模板的实例之间没有任何联系，变量模板自然也是如此。v_i 和 v_d 的地址应该是不同的。 在使用变量模板的过程中，必须跟随一对 &lt;&gt; 表示这是一个模板，即便带上了默认参数。 1234template &lt;typename T = int&gt;T v {};int b = v&lt;&gt;; 可变模板参数12template &lt;std::size_t... value&gt;constexpr std::size_t array[] { value... }; 类静态数据成员模板123456789101112class MyClass {public: template &lt;typename T&gt; static const T foo;};template &lt;typename T&gt;const T MyClass::foo = {};int main() { int v = MyClass::foo&lt;int&gt;;} 如果在类内部定义静态成员则需要加上 inline 关键字。 变量模板分文件和函数模板、类模板一样，通常写法也会导致链接时错误。 变量模板和元编程息息相关，在元编程中应用的类型特征相关组件中，带 _v 后缀的版本都是变量模板。","link":"/2024/02/16/CPPTemplate/3-%E5%8F%98%E9%87%8F%E6%A8%A1%E6%9D%BF/"},{"title":"CPP Function Template","text":"函数模板1234template &lt;typename T&gt;T max(T a, T b) { return a &gt; b ? a : b;} T 的类型通过编译器推导。 实例化使用编译器 -S 选项生成汇编文件之后，可以看见文件中什么都没有。这是因为只有在模板实例化之后才会生成实际的函数定义。 隐式实例化1int main() { max(1, 2); } 显式实例化1int main() { max&lt;int&gt;(1, 2); } 此时不会发生类型推导。 ADL (实参依赖查找) 和模板冲突在名称空间 std 中，也有一个 max。 即使没有使用 using namespace std;，进行如下模板推导时会产生不明确： 123int main() { max&lt;std::string&gt;(&quot;hello&quot;s, &quot;1&quot;s);} ADL机制会因为 string 属于 std 而在该名称空间中查找 max。 此时需要通过名称空间解析运算符来进行限制。 1234int main() { ::max&lt;std::string&gt;(&quot;hello&quot;s, &quot;1&quot;s); std::max(&quot;hello&quot;s, &quot;1&quot;s);} 万能引用 (转发引用) 和引用折叠12345678template &lt;typename T&gt;void f(T &amp;&amp;t) {}int main() { int a = 42; f(a); // f&lt;int &amp;&gt;(int &amp;) f(42);// f&lt;int&gt;(int &amp;&amp;) } 万能引用 T &amp;&amp; 在接收左值表达式时，类型被推导为左值引用；否则推导为右值引用。 考虑下列引用折叠的情况： 12345678910template &lt;class T&gt;constexpr T&amp;&amp; forward(T &amp;arg) noexcept { return static_cast&lt;T&amp;&amp;&gt;(arg);}int main() { ::forward&lt;int&gt;(...); ::forward&lt;int&amp;&gt;(...); ::forward&lt;int&amp;&amp;&gt;(...);} 当 T 为 int 时，T&amp;&amp; 毫无疑问是 int&amp;&amp; 当 T 为 int&amp; 时，T&amp;&amp; 显然不会是 int&amp;&amp;&amp;，多余的 &amp; 按照规则被折叠为 int&amp;；T&amp; 仍然为 T&amp; 当 T 为 int&amp;&amp; 时，T&amp;&amp; 显然不会是 int&amp;&amp;&amp;&amp;，多余的 &amp; 按照规则被折叠为 int &amp;&amp;；T&amp; 仍然为 T&amp; 这些结论通过查看汇编代码能够验证，反而使用 typeid 看不出什么有用的信息。 typeid(int) == typeid(int &amp;)，以及 typeid(int) == typeid(int &amp;&amp;) 的布尔值均为 true。 模板参数推导的发展：从模板函数返回值看现打算通过C++模板对下列函数进行泛化： 123int max(int a, int b) { return a &gt; b ? a : b;} 在比较早期的写法中，返回类型需要按照下列方式确定： 12345template &lt;class T1, class T2, class RT = decltype(true:T1{}, T2{})&gt;RT max(const T1 &amp;a, const T2 &amp;b) { return a &gt; b ? a : b;} 进入C++11以后，通过 auto 占位符和后置返回值类型可以写成： 12345template &lt;class T1, class T2&gt;auto max(const T1 &amp;a, const T2 &amp;b) -&gt; decltype(true?a : b) { return a &gt; b ? a : b;} 除了推导三目运算符的返回类型以外，还可以使用标准库设施 common_type_t 来计算 12345template &lt;class T1, class T2&gt;auto max(const T1 &amp;a, const T2 &amp;b) -&gt; std::common_type_t&lt;T1, T2&gt; { return a &gt; b ? a : b;} 该设施甚至在可变参数模板中应用。 进入C++14后，编译器能够自动推导返回类型，只用保留一个 auto 占位符： 1234template &lt;class T1, class T2&gt;auto max(const T1 &amp;a, const T2 &amp;b) { return a &gt; b ? a : b;} 进入C++20以后，引入简写函数模板，变成下面这个样子： 123auto max(const auto &amp;a, const auto &amp;b) { return a &gt; b ? a : b;} 根据C++14标准，auto 默认为无引用、无限定符 (e.g. const)。将返回类型写为 decltype(auto) 可以使其变成带引用的类型。 值得注意的是，简写函数模板会隐式地对ADL进行处理，比如在 1max(&quot;hello&quot;s, &quot;world&quot;s); max 会自动被选定为标准库中的版本，而不是像之前报出不明确行为的错误。 非模板函数 v.s. 特化模板函数 v.s. 非特化模板函数匹配的优先级为非模板函数 &gt; 特化模板函数 &gt; 非特化模板函数。相关术语为重载决议。 可变参数模板C语言中有 va_list 提供对函数的可变参数的支持；但是在C++中，可变参数只能用模板来实现。 C++14形参包语法如下： 12template &lt;typename... Args&gt;void foo(Args... args) { ... } Args 是类型形参包，保存了所有实参的类型 args 是函数形参包，保存了所有被接收的实参 形参包展开不妨设上述的 foo 中会使用到下列函数： 12void ciallo(double *C, double *A, double *B);void ciallo(double C, double A, double B); 在函数体中为了使用函数形参包需要进行形参包展开，foo 函数体如下： 12345678910template &lt;typename... Args&gt;void foo(Args... args) { ciallo(args...); ciallo(&amp;args...)}int main() { double a, b, c; foo(a, b, c);} ciallo(args...) 对应于没有指针的版本 ciallo(&amp;args...) 对形参包中的每个实参都进行了取地址操作，对应于带指针的版本 这是因为 args 在编译器的视角会被展开为按逗号分隔的模式实例。 模式在类型形参包以外的地方，... 前面的内容都表示一种模式，在 args 的位置放入一个实参，然后和下一个模式之间用逗号分隔。 12345678template &lt;typename... Args&gt;void test(Args... args) { double begin = timer(); foo(std::forward(args)...); double end = timer();}test(C, A, B, M, N, K); 在这里，foo 进行模式展开后为 1foo(std::forward(C), std::forward(A), std::forward(B), std::forward(M), std::forward(N), std::forward(K)); 另一个例子是 1234template &lt;typename... Args&gt;void myPrint(Args&amp;... args) { int _[] { (std::cout &lt;&lt; args &lt;&lt; &quot; &quot;)... };} Args&amp;... 的模式表示 T1&amp;, T2&amp;, ...，因此这里接收的都是引用 第三行展开后为一系列由逗号分隔的 (...), (...)，因此能逐个打印参数 获取形参包的长度1for (int i = 0; i &lt; sizeof...(args); ++i) 模板分文件模板份文件时容易报错的原因在于模板实例化：只有使用了才能生成实例。 不妨设目录结构为 1234.├── MyLib.h├── MyLib.cpp├── main.cpp 借助LLVM IR可以发现，对模板实例化后，其声明实际是保存在 main.cpp 对应的模块中，因此 MyLib.cpp 中的函数实现根本没有实例化！真正参与编译的模块中只能看见一个函数声明而没有实现。 在这样的写法下，MyLib.cpp 是可有可无的。因此，模板声明及其实现通常直接放在 .h 或者 .hpp 文件中，后者表示该文件中保存着模板。","link":"/2024/02/13/CPPTemplate/1-%E5%87%BD%E6%95%B0%E6%A8%A1%E6%9D%BF/"},{"title":"CPP Class Template","text":"类模板和函数模板不同，类模板只能显式实例化。在C++17以后，通过CTAD能够通过初始化列表中的参数类型完成对模板参数的推导。 12std::vector&lt;int&gt; vec {1};std::vector vec {1}; 用户定义的推导指引12345678template&lt;typename T&gt;class Foo { Foo(T v): t{v} {}private: T t;};Foo(int) -&gt; Foo&lt;size_t&gt;; 当 T 实际被推导为 int 时，我们希望被推导为 size_t。 在标准库 array 中存在的一个用法 (简化)： 1234567template &lt;class Ty, std::size_t size&gt;struct array { Ty _ar[size];};template &lt;typename T, typename... Args&gt;array(T t, Args...) -&gt; array&lt;T, sizeof...(Args)+1&gt;; 此时，即使没有初始化函数，array 也能进行初始化。 模板模板形参在模板的参数中放进另外一个模板类需要这样的特殊处理——还是模板实例化的锅。 1234567template &lt;template &lt;typename T&gt; class T&gt;struct Container {};template &lt;typename T&gt;struct Item_t {};Container&lt;Item_t&gt; c; class 之前的那一串 template 指代了 Item_t 的模板声明 (复制过来)，在 Container 中由 T 指代 模板模板形参包12template&lt;template&lt;typename T&gt; class... T&gt;struct Container {}; 成员函数模板我们一般不认为下列成员函数为成员函数模板： 12345template &lt;typename T&gt;class MyClass {public: void foo(T) {}}; 成员函数间的模板推断const 方法只能使用同为 const 的方法作为推导对象： 123456789101112class Lexer { ... bool is(TokenKind K) const { return Kind == K; } bool isOneOf(TokenKind K1, TokenKind K2) const { return is(K1) || is(K2); } template &lt;typename... Ts&gt; bool isOneOf(TokenKind K1, TokenKind K2, Ts... Ks) const { return is(K1) || isOneOf(K2, Ks...); } ...} 如果前一个 isOneOf 没有加上 const 修饰，那么形参包展开时就无法匹配到仅有两个参数的 isOneOf 实现。 类模板的成员函数模板123456template &lt;typename T&gt;class MyClass {public: template &lt;typename... Args&gt; void f(Args... args) {}}; 类模板的模板形参没有被使用到。 类模板分文件不实例化的模板类不会生成任何代码，包括成员函数。实例化后的模板类会生成在 main.cpp 对应的模块中，只包含了声明；而实现却没有得到实例化。 因此在分文件时，像 12template &lt;typename T&gt;void MyClass&lt;T&gt;::foo() {} 这样的定义会因为实例化的原因产生链接错误。对应的 .cpp 文件事实上没有任何意义。","link":"/2024/02/15/CPPTemplate/2-%E7%B1%BB%E6%A8%A1%E6%9D%BF/"},{"title":"CPP Template Speicialized","text":"全特化模板全特化是模板的显式实例化的方式之一。 函数模板全特化123456789template &lt;typename T1, typename T2&gt;auto f(const T1 &amp;a,const T2 &amp;b) { return a+b;}template&lt;&gt;auto f&lt;double, double&gt;(const double &amp;a,const double &amp;b) { return a-b;} 第一个模板被称为主函数模板 第二个模板被称为全特化 全特化的 &lt;...&gt; 可以省略 类模板全特化类模板全特化语法与函数模板全特化类似，除了 &lt;...&gt; 不能省略。 实例化的相关问题123456789template &lt;typename T&gt;void foo(const T &amp;) {}using namespace string_literal;void ciallo() { foo(&quot;asd&quot;s); }template &lt;&gt;void foo&lt;std::string&gt;(const std::string &amp;) {} ciallo 调用 foo 时进行了隐式实例化，导致后面进行全特化时出现了冲突，会导致报错。 声明和不完整类型只有声明没有定义的模板特化时一个不完整类型，拥有指针但是其余数据成员和函数成员不一定被正确实例化。 12345678template &lt;typename T&gt;class Foo;template &lt;&gt;class Foo&lt;int&gt;;Foo&lt;int&gt; *f_p; // validFoo&lt;int&gt; f_p; // illegal for incomplete object 修饰符和实例化1234567template &lt;typename T&gt;int foo(const T &amp;_) { return 1; }template&lt;&gt;constexpr int foo&lt;int&gt;(int _) { return 1; }constexpr auto n = f&lt;int&gt;(114514); 这段代码能够编译通过，是因为在模板特化中使用了 constexpr。其它类型会使用主模板实例化，所以不能赋值给 constexpr。 类模板成员的特化12345template &lt;typename T&gt;struct A { template &lt;typename U&gt; struct B {};}; 特化类模板123456template &lt;&gt;struct A&lt;void&gt; { void foo();};void A::foo() {} 特化后的 A 没有主模板中的任何成员，也算是有别于类继承的一点。 特化类内成员123456789template &lt;&gt;template &lt;typename U&gt;struct A&lt;void&gt;::B { void foo();}template &lt;&gt;template &lt;typename U&gt;void A&lt;void&gt;::B&lt;U&gt;::foo() {} 这个特化本质上是对类内成员 B 进行特化。 非类模板的成员特化1234struct X { template &lt;typename T&gt; void foo(const T&amp;);}; 12345678910struct X { template &lt;typename T&gt; void foo(const T&amp;); template&lt;&gt; void foo&lt;int&gt;(const int &amp;) {};};template&lt;&gt;void X::foo&lt;double&gt;(const double &amp;) {}; 偏特化对于几个类似的特性进行统一的特化，如 int *、double * 等。因此，只有类模板和变量模板能够偏特化。 变量模板偏特化在写偏特化时，模板形参需要被保留。 12345template &lt;typename T&gt;const char *s = &quot;s&quot;;template &lt;typename T&gt;const char *s&lt;T*&gt; = &quot;pointer&quot;; 在这个偏特化中，对所有指针类型进行偏特化。 多模板变量偏特化12345template &lt;class T1, class T2&gt;const char *s = &quot;?&quot;;template &lt;class T1&gt;const char *s&lt;T1, void&gt; = &quot;?, void&quot;; 即使对于 T1 没有进行任何修饰，这也是一个偏特化。 type_trait 的 is_same 实现123456789101112template &lt;class, class&gt;struct is_same { static constexpr bool value = false;};template &lt;class T&gt;struct is_same&lt;T, T&gt; { static constexpr bool value = true;};template &lt;class T1, class T2&gt;inline constexpr bool is_same_v = is_same&lt;T1, T2&gt;::value;","link":"/2024/02/19/CPPTemplate/4-%E6%A8%A1%E6%9D%BF%E7%89%B9%E5%8C%96/"},{"title":"6-Fold Expression","text":"折叠表达式本质上是对形参包展开使用的简化，该特性在C++17引入。 1234template &lt;typename ...Args&gt;void print(const Arg &amp;... args) { int _[] { (cout &lt;&lt; args &lt;&lt; &quot; &quot;, 0)... };} 这个写法并不好，因为为了打印所有参数，我们不得不声明一个没用且令人困惑的数组，并使用 0 作为整个逗号表达式的值。 逗号表达式又称顺序求值运算符，按照顺序依次求值，且整个表达最终返回值为最后计算的表达式的值 一元右折叠表达式1(E &lt;operator&gt; ...) 括号是折叠表达式的一部分 E 对应于上述示例中的 cout &lt;&lt; args &lt;&lt; &quot; &quot; 运算符对应于 , 利用折叠表达式，上述例子可以被写成 1234template &lt;typename... Args&gt;void print(const Args &amp;... args) { ((cout &lt;&lt; args &lt;&lt; ' '), ...);} 其对应的展开形式为 1(E1 &lt;op&gt; (... (EN-1 &lt;op&gt; EN))) 左折叠右折叠和左折叠的区别在于 ... 的位置。其语法为 1(... &lt;operator&gt; E) 类似地，其对应的展开形式为 1(((E1 &lt;op&gt; E1) &lt;op&gt; E2 ...) &lt;op&gt; EN) 所以上述例子的左折叠形式为： 1234template &lt;typename... Args&gt;void print(const Args &amp;... args) { (..., (cout &lt;&lt; args &lt;&lt; ' '));} 注意事项因为上述示例中的运算符是逗号运算符，所以对输出没有影响。但是在下面的例子中，结果可是不同的。 12345678910template &lt;int... I&gt;constexpr int v_right = (I - ...);template &lt;int... I&gt;constexpr int v_left = (... - I);int main() { cout &lt;&lt; v_right&lt;4, 5, 6&gt; &lt;&lt; '\\n'; cout &lt;&lt; v_left&lt;4, 5, 6&gt; &lt;&lt; '\\n';} 二元折叠表达式右折叠1(E &lt;op&gt; ... &lt;op&gt; I) 对应的展开形式为 1(E1 &lt;op&gt; (... &lt;op&gt; (EN-1 &lt;op&gt; (EN &lt;op&gt; I)))) 左折叠同理，... 出现在 E 的左边。 示例1234template &lt;typename... Args&gt;void print(Args &amp;&amp;... args) { (cout &lt;&lt; ... &lt;&lt; args) &lt;&lt; &quot;\\n&quot;;} 这是一个二元左折叠","link":"/2024/03/08/CPPTemplate/6-%E6%8A%98%E5%8F%A0%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%92%8C%E5%8F%82%E6%95%B0%E5%8C%85%E5%B1%95%E5%BC%80/"},{"title":"Instantiation and Sperate Template Definition","text":"显式实例化1234template &lt;typename T&gt;void f(T) {}template void f&lt;int&gt;(int); 此时即使没有真正使用函数模板 f，也会有一个 int 版本的代码实现。 实例化和模板分文件类的完整定义，不包含成员函数的定义。因此，即使类中的方法没有实现，类的对象也能正常实例化，只是会在调用方法的时候产生链接时错误。 123456template &lt;typename T&gt;struct X { void foo();};int main() { X x; } 因此，通过显式实例化在其它文件中定义方法的具体实现是可行的。 模板导出动态库1234567#include &quot;MyTemplate.h&quot;template &lt;typename T&gt;void f(T) {}/// export to MS dlltemplate __declspec(dllexport) void f&lt;int&gt;(int);","link":"/2024/03/05/CPPTemplate/5-%E5%AE%9E%E4%BE%8B%E5%8C%96/"},{"title":"7-Dependent names","text":"待决名以下类型都是待决类型： 模板参数 未特化的成员 未特化的类模板的嵌套类/枚举类型 带cv修饰的待决类型 由待决类型构成的复合类型 由待决类型构成的数据 … cppreference.com Dependent names剩下的类型都看不懂了 简而言之，待决是因为依赖于 (dependent) 模板参数。 消除歧义符 typename 此 typename 非模板类型模板参数的 typename；只是C++的关键字复用 1234567891011template &lt;typename T&gt;const T::type f(const T&amp;) { return 0; }struct Foo { using type = int;};int main() { Foo x; f(x);} Foo 中为 int 引入了别名 type 这段代码会出现一个警告信息，来源于 T::type 之前没有加上歧义消除符 typename。 这是因为，T::type 不被视为一个类型，除非用 typename 修饰，或者在 T 内部的定义中用 typedef 设置为类型，或者直接就是基类。T::type 的真实类型取决于模板形参，且实例化的目标为 f。 更复杂的例子1234567891011int p = 1;template &lt;typename T&gt;void foo(const std::vector&lt;T&gt; &amp;v) { typename std::vector&lt;T&gt;::const_iterator it = v.begin(); std::vector&lt;T&gt;::const_iterator * p; typedef typename std::vector&lt;T&gt;::const_iterator iter_t; iter_t *p2;} 所有的 std::vector&lt;T&gt;::const_iterator 都是待决名 std::vector&lt;T&gt;::const_iterator * p; 能通过编译，但是 * 不会为解析为指针，而是乘法运算符 消除歧义符 template123456789101112131415template &lt;typename T&gt;struct S { template &lt;typename U&gt; void foo() {}};template &lt;typename T&gt;void bar() { S&lt;T&gt; s; s.foo&lt;T&gt;();}int main() { bar&lt;int&gt;();} s.foo&lt;T&gt; (); 会报错 显然 s.foo&lt;T&gt; 取决于模板参数 T，所以是待决名。正确的写法是用 template 消除歧义： 1s.template foo&lt;T&gt;(); 不是待决名的类成员在访问时也可以加上 typename 或者 template 绑定规则非待决名非待决名在模板定义点向前查找并绑定，且不会因为后续代码的信息而发生改变。 12345678double g(double) { return 42; }template &lt;typename T&gt;class Foo { void func() { g(1); }};int g(int) { return 1; } Foo:func 中的 g 绑定为 double 类型的版本 待决名12345678910111213void f() { cout &lt;&lt; &quot;Global\\n&quot;; }template &lt;class T&gt;struct X { void f() const { cout &lt;&lt; &quot;X\\n&quot;; }}template &lt;class T&gt;struct Y : X&lt;T&gt; { void t1() const { this-&gt;f(); } void t2() const { f(); }}; t1 绑定了基类 X 中的 f t2 绑定了全局的 f 两种绑定方式是因为C++存在两种标识符查找方式 有限定查找 带作用域解析符 无限定查找 不带作用域解析符，this-&gt;f() 也应用该规则 现在类内查找，然后找全局 尽管 t1 和 t2 都应用无限定查找规则，但是 this-&gt;f() 作为待决名，其查找会推迟到模板参数被确定时 (父模板已经被实例化为具体类型)；而非待决名会立即进行查找。 this 也是一个待决名，在语法树中 this 对应的语法节点为 CXXThisExpr，类型为 Y&lt;T&gt; *，所以是待决名","link":"/2024/03/09/CPPTemplate/7-%E5%BE%85%E5%86%B3%E5%90%8D/"},{"title":"8-SFINAE","text":"概念SFINAE = Substitution Failure Is Not An Error 这是函数模板重载决议中的一个规则：模板形参在替换为显式指定的类型或者推导类型失败时，只会从重载集中丢弃这个特化，而非产生编译错误。当没有重载集中没有可用的模板后，产生找不到可用函数的错误。 模板参数会发生两次代换： 模板实参推导前：用显式指定的模板实参进行代换 模板实参推导后：对推导出的实参和默认项获得的实现进行替换 如果所有模板形参都显示指定，则不会发生第二次代换。 SFINAE错误/硬错误代换过程中产生的副作用，如额外的模板实例化等，就会产生硬错误。 用途对运算符重载的要求1234template &lt;typename T, typename _T = decltype(T{} + T{})&gt;auto add(const T &amp;c1 const T &amp;c2) { return c1 + c2;} 提前用SFINAE让模板替换失败能够减少不必要的实例化。但是缺点是写法上不好看。 后置返回值类型也能有类似的效果。 标准库对SFINAE的支持std::enable_ifstd::enable_if 对模板参数是否满足某些类型进行检查。下列例子中，要求模板参数是同类型 12template &lt;class Ty, Args... args&gt;array(Type, Args...) -&gt; array&lt;enable_if_t&lt;(is_same_v&lt;Type, Args&gt; &amp;&amp; ...), Type&gt;, sizeof...(Args)+1&gt;; 使用一个折叠表达式对所有参数的类型进行判定 std::enable_if 和 std::enable_if_t 可能实现如下： 12345678910// enable_iftemplate &lt;bool B, class T = void&gt;struct enable_if {};template &lt;class T&gt;struct enable_if&lt;true, T&gt; { typedef T type; }// enable_if_ttemplate &lt;bool B, class T = void&gt;using enable_if_t = enable_if&lt;B, T&gt;::type; std::void_t12template &lt;class ...&gt;using void_t = void; 将任意序列映射到 void 类型 模板元编程中用于检测不完整类型 在不用 requires 的情况下充当起了需求的垃圾桶的角色 12345template &lt;typename T, typename SFINAE= void_t&lt;decltype&lt;T{} + T{}&gt;, typename T::type, decltype&lt;T::value&gt;&gt;&gt;auto add(const T &amp;t1, const T &amp;t2) { return t1::value + t2::value;} std::declval12345template &lt;typename T, typename SFINAE= void_t&lt;declval&lt;T&gt;() + declval&lt;T&gt;(), ... &gt;&gt;auto add(const T &amp;t1, const T &amp;t2) { return t1::value + t2::value;} 此时，T 不支持默认构造函数也能进行检查了 declval 将类型 T 转换为引用类型 T &amp;&amp;，可以不经过构造而使用成员函数。仅能在不求值语境下使用，对定义没有要求。 偏特化中的SFINAE1234567891011121314151617// main templatetemplate &lt;typename T, typename T2 = void&gt;struct X { static void foo() { cout &lt;&lt; &quot;Main template\\n&quot;; }};// partial specilizationtemplate &lt;typename T, std::void_t&lt;typename T::type&gt;&gt; X { using type = typename T::type; static void foo() { cout &lt;&lt; &quot;Partial specialization\\n&quot;; }};struct Foo { using type = int; };int main() { X&lt;Foo&gt;::foo(); } 通过SFINAE的加持，模板偏特化不在局限于特定的类型，能够做出更复杂的要求。","link":"/2024/03/25/CPPTemplate/8-SFINAE/"},{"title":"9-Require and concept","text":"requiresRequires是C++20引入的特性。因为requires的出现，SFINAE变成了过时、难看的写法。 示例：要求模板参数支持 operator+SFINAE1234template &lt;typename T, typename = std::void_t&lt;decltype(std::declval&lt;T&gt;() + std::declval&lt;T&gt;())&gt;&gt;T add(const T &amp;v1, const T &amp;v2) { return v1 + v2;} requires使用 requires 需要先定义一个concept。 123456789template &lt;typename T&gt;concept Addable = requires(T a) { a + a;};template &lt;Addable T&gt;auto add(const T &amp;v1, const T &amp;v2) { return v1 + v2;} Concept是一个谓词，在编译时求值，即 constexpr bool。 1constexpr bool v = Addable&lt;int&gt;; 使用一个编译期可求值的布尔表达式定义 concept： 12template &lt;typename T&gt;concept Int = std::is_same_v&lt;T, int&gt;; concept 的定义也能内联进 requires 表达式中： 12345template &lt;typename T&gt;requires requires(T a) { a+a; }auto add(const T &amp;v1, const T &amp;v2) { return v1 + v2;} 两个 requires 表示不同的意思 第二个 requires 是require表达式，一个能编译期产生布尔类型的表达式 第一个 requires 是reuquire子句 标准库里的设施12345#include &lt;concepts&gt;auto max(const std::integral auto &amp;a, const std::integral auto &amp;b) { return a &gt; b ? a : b;} concept 能够放在 auto 的前面 也可以写成 12345template &lt;typename T&gt; requires(std::is_same_v&lt;T, int&gt;)T max(const T &amp;a, const T &amp;b) { return a &gt; b ? a : b;} 简单 requires 表达式123456789template &lt;typename T, class U&gt;concept Swappable = reuqires(T &amp;&amp;t, U &amp;&amp;u) { swap(std::forward&lt;T&gt;(t), std::forward&lt;U&gt;(u)); }namespace foo {struct X {};void swap(X &amp;, X &amp;) {}} 特别地，在这个例子中表现了 requires 表达式在替换过程用到了ADL，自动选择同意名称空间内的 swap。 复合 requires 表达式12345template &lt;typename T&gt;concept C = requires(T x) { {*x}-&gt;std::convertible_to&lt;typename T::inner&gt;; {x.~T()} noexcept;}; *x 是合法的 嵌套类型/类型别名 T::inner 存在 *x 能够隐式转换到 T::inner 析构函数不抛出异常 嵌套 requires 表达式1234template &lt;typename T&gt;concept C = requires(T) { requires std::is_same_v&lt;T, int&gt;;}; requires 要求后面的表达式为 true 才能成立","link":"/2024/04/03/CPPTemplate/9-Require%E5%92%8Cconcept/"},{"title":"1 LLVM Overview","text":"获取LLVM在类Linux系统上，获取代码的命令很简单： 1git clone https://github.com/llvm/llvm-project.git 代码体积在2GB以上。 在windows系统上，如果不想突然冒出来一个奇怪的错误，然后用 dos2unix 处理报错文件，那么记得加上选项： 12git clone --config core.autocrlf=false \\ https://github.com/llvm/llvm-project.git 安装选项","link":"/2024/02/29/LLVM/1-LLVMOverview/"},{"title":"APPENDIX A: The headers of LLVM","text":"前端llvm/ADT/StringRef.hllvm::StringRef 封装了C风格字符串和它的长度，包含一个指针和长度，只占了两个字长。 llvm/ADT/SmallVector.hllvm::SmallVector 在元素数量不多时使用栈分配内存 (用模板参数指定)，如果添加了参数数目大于阈值，将和 std::vector 没有差别。 llvm/Support/raw_ostream定义了LLVM的输出流： outs errs nulls 代码生成llvm/ADT/Twine.hllvm::Twine 在生成中间代码表示时，变量名的生成经常需要进行字符串拼接。Twine 内部包含一个二叉树结构，表示需要拼接的字符串，并将拼接过程延迟到真正使用为止，避免中间字符串的生成。 llvm/ADT/StringMap.hllvm::StringMap 是一个为字符串为key特化的字典类型，键类型默认为字符串，所以模板里面只用指定值的类型。 llvm/IR/LLVMContext.h编译器什么都知道，但编译器什么都不告诉你；llvm::Context 就是编译器中间代码生成阶段的大脑。 llvm/IR/IRBuilder.hllvm::IRBuilder 职责有两个，其一是创建IR指令，其二是记录插入IR指令的位置。其两个模板参数分别用来指定创建常量的工具类 ConstantFolder 和插入工具Inserter。但是使用默认的模板参数已经足够应对绝大多数的使用场景。 类型系统llvm/IR/Instructions.h基本数据类型都使用该头文件中提供的 Type 获取。 llvm/IR/Constants.h包括了常量的创建工具。 llvm/IR/DerivedTypes.h包括了创建指针，函数类型等复合类型的工具。 llvm/IR/GlobalVariable.h包含创建全局变量的工具。 如果要创建全局常量，那么就先创建一个全局变量，然后用 setConstant 方法设置为全局常量。 驱动llvm/Support/CommandLine.h链接时参数上述库在链接时使用的库包括 libLLVMSupport.so, libLLVMCore.so 等。 还有要加上 -fno-rtti 选项，不然总会报一些奇怪的链接时错误。","link":"/2024/03/12/LLVM/APPENDIX-A%20The-headers%20of%20LLVM/"},{"title":"LLVM Tuning","text":"LLVM中有用的编译选项编译遍相关 -Rpass=.* 打印所有生效的优化遍，并标记在源代码中对应的位置 编译过程中资源消耗 -fproc-stat-report，每行显示下列数据： 工具名 生成的文件 消耗的时间 用户态消耗的时间 内存峰值开销 调试LLVM IR通过 -Xclang 传入额外的选项能够提升LLVM IR的可读性： -discard-value-names 一些中间变量的赋值被删除了，但是这样反而能够突出代码的重点部分 但也会抛弃源程序中的变量名，降低可读性 -disable-free 删掉中间表示自动释放内存的代码，使其整体更加简短 不用 -Xclang 传入的选项： -fno-discard-value-names 与 -discard-value-names 效果相反，是clang默认选项","link":"/2024/03/04/LLVM/LLVM-tuning/"},{"title":"MLIR Basic Concepts","text":"前言MLIR可以被视为一个数据流图，其中的节点被称为operation，边被称为value。Operation包含于block，而block又被包含于region。不过operation本身又能够包含region，如定义函数的operation。这样形成了一个层次化的结构。 本教程自底向上地介绍MLIR的搭建过程，按照从Op-&gt;Block-&gt;Function-&gt;Module的顺序介绍语法及在代码中会使用到的工具。 相关概念都能够在MLIR LangRef中找到最权威的解释。关于环境搭建可以参考这篇文档。 Operation (a.k.a. Op) In MLIR, everything is about Operations, not Instructions: we put the emphasis to distinguish from the LLVM view. 文法结构Op的EBNF语法如下所示： 1234567891011121314operation ::= op-result-list? (generic-operation | custom-operation) trailing-location?generic-operation ::= string-literal `(` value-use-list? `)` successor-list? dictionary-properties? region-list? dictionary-attribute? `:` function-typecustom-operation ::= bare-id custom-operation-formatop-result-list ::= op-result (`,` op-result)* `=`op-result ::= value-id (`:` integer-literal)?successor-list ::= `[` successor (`,` successor)* `]`successor ::= caret-id (`:` block-arg-list)?dictionary-properties ::= `&lt;` dictionary-attribute `&gt;`region-list ::= `(` region (`,` region)* `)`dictionary-attribute ::= `{` (attribute-entry (`,` attribute-entry)*)? `}`trailing-location ::= `loc` `(` location `)` 12345%res:2 = mydialect.morph(%arg0#3) { some.attribute = true, other_attribute = 1.5 } : (!mydialect&lt;&quot;custom_type&quot;&gt;) -&gt; (!mydialect&lt;&quot;other_type&quot;&gt;, !mydialect&lt;&quot;other_type&quot;&gt;) loc(callsite(&quot;foo&quot; at &quot;mysource.cc&quot;:10:8)) 从语法角度来说： %res:2 = 对应了 op-result-list mydialect.morph ... -&gt; ... 对应了 generic-operation loc(...) 对应了 trailing-location 从含义角度来说： %res:2：Op的计算结果，2表示返回值的数量 mydialect.morph：方言及内部的操作 (%arg0#3) { some.attribute = true, other_attribute = 1.5 }：参数、属性 (!mydialect&lt;&quot;custom_type&quot;&gt;) -&gt; (!mydialect&lt;&quot;other_type&quot;&gt;, !mydialect&lt;&quot;other_type&quot;&gt;)：函数签名类型 (语法结构中的function-type) loc(callsite(&quot;foo&quot; at &quot;mysource.cc&quot;:10:8))：位置信息 虽然文档中给出的generic Op语法如此复杂，但是custom Op却会简单很多，如 arith.addi： 1operation ::= `arith.addi` $lhs `,` $rhs attr-dict `:` type($result) 1%c = arith.addi %a, %b : i32 从custom Op转换为generic Op可以使用工具 mlir-opt --mlir-print-op-generic 进行转换。 接下来需要弄清楚的概念来自于 generatic-operation： 固有属性 (property) 可变属性 (attribute) PropertyProperty是直接保存在operation class内的额外数据成员，包含了某些语义并能通过interface accessor等方法暴露给其余Op。 Property和inherent attribute息息相关，这是因为property有专门的存储区域。 Property能够被序列化为attribute来打印出来。 Attribute12345dictionary-attribute ::= `{` (attribute-entry (`,` attribute-entry)*)? `}`attribute-entry ::= (bare-id | string-literal) `=` attribute-valueattribute-value ::= attribute-alias | dialect-attribute | builtin-attributeattribute-alias-def ::= `#` alias-name `=` attribute-valueattribute-alias ::= `#` alias-name Attribute为Op提供了除了保存value本身以外信息的机制，从而进行高层次的分析。另一方面，Op的结果——value——并不能够保存常量 (编译时已知的量)，所以常量值必须以attribute的形式保存。这在 arith.ConstOp 中可见一斑： 1operation ::= `arith.constant` attr-dict $value 1%a = arith.constant 4: i32 4 : i32 共同构成了 $value。 Attribute能够为分为两类： Inherent attribute：存在于Op的定义中，它们的名字中不会带有dialect前缀；保存在property storage中 Discardable attribute：名字中带有dialect前缀；保存在top-level dictionary中 Type和attribute因为Op分为custom和generic两类，所以在这样的两套系统下type和attribute的边界变得模糊。下列例子中，我们使用 mlir-opt 将custom Op向generic Op转换，函数的type变成了property被保存在了Op中。 1234func.func @test(%a: i32, %b: i32) -&gt; i32 { %c = arith.addi %a, %b : i32 func.return %c : i32} 1234567&quot;builtin.module&quot;() ({ &quot;func.func&quot;() &lt;{function_type = (i32, i32) -&gt; i32, sym_name = &quot;test&quot;}&gt; ({ ^bb0(%arg0: i32, %arg1: i32): %0 = &quot;arith.addi&quot;(%arg0, %arg1) : (i32, i32) -&gt; i32 &quot;func.return&quot;(%0) : (i32) -&gt; () }) : () -&gt; ()}) : () -&gt; () 构建工具和LLVM IR类似，MLIR提供了builder来获取类型和attribute、构建Op。 12345678910111213141516#include &lt;mlir/IR/Builders.h&gt; // for OpBuilder#include &lt;mlir/IR/MLIRContext.h&gt; // for MLIRContext#include &lt;mlir/Dialect/Arith/IR/Arith.h&gt; // for addiint main(){ mlir::MLIRContext ctx; ctx.loadDialect&lt;mlir::arith::ArithDialect&gt;(); mlir::OpBuilder builder(&amp;ctx); auto a = builder.create&lt;arith::ConstantOp&gt;(builder.getUnknownLoc(), i32, builder.getI32IntegerAttr(4)); auto b = builder.create&lt;arith::ConstantOp&gt;(builder.getUnknownLoc(), i32, builder.getI32IntegerAttr(2)); auto addi = builder.create&lt;arith::AddIOp&gt;(builder.getUnknownLoc(), a.getResult(), b.getResult());} Context 包含了大量的辅助数据结构，在Moudle中使用到的dialect需要注册在里面 OpBuilder 依赖与 Context 存在 常量值在MLIR中以attribute的形式存在，所以这里创建常量时以attribute的形式传入值 如果不想再Op中加入位置信息，使用 builder.getUnknownLoc() 来缺省位置信息，这个信息仅用于调试，而非指定Op插入的位置 Op外面是block，block外面是function，function外面是module，没有外面的层次就无法确定 builder 插入Op的为主，因此这里仅仅是创建了指令，并没有真正插入MLIR中 Result是Op中作为出边的value 所有编译期常量都是用 getXXX 创建，反之则是 create。 Type system12345678910111213141516171819202122232425262728293031323334type ::= type-alias | dialect-type | builtin-typetype-list-no-parens ::= type (`,` type)*type-list-parens ::= `(` `)` | `(` type-list-no-parens `)`// This is a common way to refer to a value with a specified type.ssa-use-and-type ::= ssa-use `:` typessa-use ::= value-use// Non-empty list of names and types.ssa-use-and-type-list ::= ssa-use-and-type (`,` ssa-use-and-type)*function-type ::= (type | type-list-parens) `-&gt;` (type | type-list-parens)// type aliastype-alias-def ::= `!` alias-name `=` typetype-alias ::= `!` alias-name// dialect typedialect-namespace ::= bare-iddialect-type ::= `!` (opaque-dialect-type | pretty-dialect-type)opaque-dialect-type ::= dialect-namespace dialect-type-bodypretty-dialect-type ::= dialect-namespace `.` pretty-dialect-type-lead-ident dialect-type-body?pretty-dialect-type-lead-ident ::= `[A-Za-z][A-Za-z0-9._]*`dialect-type-body ::= `&lt;` dialect-type-contents+ `&gt;`dialect-type-contents ::= dialect-type-body | `(` dialect-type-contents+ `)` | `[` dialect-type-contents+ `]` | `{` dialect-type-contents+ `}` | [^\\[&lt;({\\]&gt;)}\\0]+ Builtin type全部定义在builtin dialect中，参考文档。 Type alias1234567!avx_m128 = vector&lt;4 x f32&gt;// Using the original type.&quot;foo&quot;(%x) : vector&lt;4 x f32&gt; -&gt; ()// Using the type alias.&quot;foo&quot;(%x) : !avx_m128 -&gt; () ! 开头的就是类型别名。 Dialect typeOpaque form12345678// A tensorflow string type.!tf&lt;string&gt;// A type with complex components.!foo&lt;something&lt;abcd&gt;&gt;// An even more complex type.!foo&lt;&quot;a123^^^&quot; + bar&gt; !dialect&lt;type&gt; 表示位于 dialect 名称空间内的类型。 Pretty form12345// A tensorflow string type.!tf.string// A type with complex components.!foo.something&lt;abcd&gt; RegionBlockBlock是一个Op列表。与SSA中的基本块类似，MLIR block在大部分情况下以控制流转移指令作为结束。基本块位于MLIR region中，这是传统SSA中间表示中没有的形式。利用region，MLIR取消了phi节点而使用块参数来传递值。 12345678910block ::= block-label operation+block-label ::= block-id block-arg-list? `:`block-id ::= caret-idcaret-id ::= `^` suffix-idvalue-id-and-type ::= value-id `:` type// Non-empty list of names and types.value-id-and-type-list ::= value-id-and-type (`,` value-id-and-type)*block-arg-list ::= `(` value-id-and-type-list? `)` 12345678910111213141516171819202122func.func @simple(i64, i1) -&gt; i64 {^bb0(%a: i64, %cond: i1): // Code dominated by ^bb0 may refer to %a cf.cond_br %cond, ^bb1, ^bb2^bb1: cf.br ^bb3(%a: i64) // Branch passes %a as the argument^bb2: %b = arith.addi %a, %a : i64 cf.br ^bb3(%b: i64) // Branch passes %b as the argument// ^bb3 receives an argument, named %c, from predecessors// and passes it on to bb4 along with %a. %a is referenced// directly from its defining operation and is not passed through// an argument of ^bb3.^bb3(%c: i64): cf.br ^bb4(%c, %a : i64, i64)^bb4(%d : i64, %e : i64): %0 = arith.addi %d, %e : i64 return %0 : i64 // Return is also a terminator.} Block和Op的区别在Op内定义的value在Op外时无法访问的；所以block是不能用Op表示的概念。 RegionRegion是由block构成的有序列表。MLIR中内置了两种region： SSA CFG region：描述block间的控制流 Graph region：节点间不一定存在控制流的关系 Region和block不一样，它没有名字或者地址，需要依附于Op存在，如 func.func，且自身没有type或者attribute。 12region ::= `{` entry-block? block* `}`entry-block ::= operation+ 一个entry block是一个没有label和参数的block，通常用于打开一个新的作用域出现在一个region开头的位置。 值的作用域给定region，其内部定义的值仅在这个region内可见；其外部定义的值仅能在这个值作为参数传入创建这个region的Op时才可用。 控制流和SSA CFG region在C++形式中，其所属的接口为 RegionKind::SSACFG。 123456789101112131415161718192021func.func @accelerator_compute(i64, i1) -&gt; i64 { // An SSACFG region^bb0(%a: i64, %cond: i1): // Code dominated by ^bb0 may refer to %a cf.cond_br %cond, ^bb1, ^bb2^bb1: // This def for %value does not dominate ^bb2 %value = &quot;op.convert&quot;(%a) : (i64) -&gt; i64 cf.br ^bb3(%a: i64) // Branch passes %a as the argument^bb2: accelerator.launch() { // An SSACFG region ^bb0: // Region of code nested under &quot;accelerator.launch&quot;, it can reference %a but // not %value. %new_value = &quot;accelerator.do_something&quot;(%a) : (i64) -&gt; () } // %new_value cannot be referenced outside of the region^bb3: ...} 包含多个region的Op执行一条包含region的Op时，控制流会转移到它的region上；当这个region结束时，控制流会重新回到这条Op上。如果这个Op有多个region，那么控制流会继续转移到下一个region上。 Graph region其C++中的接口为 RegionKind::Graph。 Graph region在表达不需要控制流的并发语义时十分有用，还能用来建立有向图。其主要应用场景包括表示彼此独立的线程。因此，graph region中Op和block的顺序并没有意义。 目前一个graph region中只能包含一个基本块。 12345678&quot;test.graph_region&quot;() ({ // A Graph region %1 = &quot;op1&quot;(%1, %3) : (i32, i32) -&gt; (i32) // OK: %1, %3 allowed here %2 = &quot;test.ssacfg_region&quot;() ({ %5 = &quot;op2&quot;(%1, %2, %3, %4) : (i32, i32, i32, i32) -&gt; (i32) // OK: %1, %2, %3, %4 all defined in the containing region }) : () -&gt; (i32) %3 = &quot;op2&quot;(%1, %4) : (i32, i32) -&gt; (i32) // OK: %4 allowed here %4 = &quot;op3&quot;(%1) : (i32) -&gt; (i32)}) : () -&gt; () C++ interface12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;mlir/IR/AsmState.h&gt;#include &lt;mlir/IR/Builders.h&gt;#include &lt;mlir/IR/BuiltinOps.h&gt;#include &lt;mlir/IR/MLIRContext.h&gt;#include &lt;mlir/IR/ValueRange.h&gt;#include &lt;mlir/Parser/Parser.h&gt;#include &lt;mlir/Support/FileUtilities.h&gt;#include &lt;mlir/Dialect/Func/IR/FuncOps.h&gt;#include &lt;mlir/Dialect/Arith/IR/Arith.h&gt;#include &lt;llvm/Support/raw_ostream.h&gt;using namespace mlir;int main(int argc, char **argv){ MLIRContext ctx; ctx.loadDialect&lt;func::FuncDialect, arith::ArithDialect&gt;(); OpBuilder builder(&amp;ctx); auto module = builder.create&lt;ModuleOp&gt;(builder.getUnknownLoc()); // set insert point for builder builder.setInsertionPointToEnd(module.getBody()); // create a func auto i32 = builder.getI32Type(); auto funcType = builder.getFunctionType({i32, i32}, {i32}); auto func = builder.create&lt;func::FuncOp&gt;(builder.getUnknownLoc(), &quot;foo&quot;, funcType); // create basic blocks auto entry = func.addEntryBlock(); // set insert point builder.setInsertionPointToEnd(entry); // create constant as argumengts of addi auto a = builder.create&lt;arith::ConstantOp&gt;(builder.getUnknownLoc(), i32, builder.getI32IntegerAttr(4)); auto b = builder.create&lt;arith::ConstantOp&gt;(builder.getUnknownLoc(), i32, builder.getI32IntegerAttr(2)); auto addi = builder.create&lt;arith::AddIOp&gt;(builder.getUnknownLoc(), a.getResult(), b.getResult()); // create ret to leave the func builder.create&lt;func::ReturnOp&gt;(builder.getUnknownLoc(), ValueRange({addi})); module.print(llvm::outs()); return 0;} Module在IR中是个特殊的Op，由 ModuleOp 定义，所以需要用到 builder builder.setInsertionPointToEnd(module.getBody()) 初始化指令插入的位置，否则 builder 不会插入指令 func.func Op定义了一个region，并插入一个entry block builder.setInsertionPointToEnd(entry) 调整插入的位置，否则指令会插入在函数的外面 (func.func Op的下一条指令)","link":"/2024/01/02/MLIR/1_Basics/"},{"title":"MLIR ODS","text":"Prologue最终第二章还是变成了对文档的简单总结，不过完全把细节完全展开还是太离谱了。本章重点对MLIR ODS进行学习，因为该框架在Op定义上十分重要，所有的custom Op都是以ODS的语法给出的。 Tablegen语法基础概念Tablgen本身是用来写record的。在这个基础上，record又分为abstract record和concrete record两类。 Abstract record：被称为class Concrete record：被称为record Class和record都有专有的名字，可以由程序员或者tablegen给出。每个名字都会和一组有值的field相关联。Field的具体含义并不由tablegen语法决定，而是由后端决定。 Class通常用来描述一个record的模板，并且能够进行派生；record向class传入参数来填充不同的filed。未初始化的field的值以 ? 表示。因此class的field的值通常都是 ? 而record的field大多被初始化了。 Token 注释： // /*...*/ 字面量： 二进制/十进制/十六进制数 字符串：由双引号 &quot; 包围（单行字符串）或者由 [{...}] 包围（多行） 标识符 变量名以 $ 开头 不能使用关键字作为标识符 惊叹号运算符 (bang operator) 以 ! 为开头，如 !add, !isa, … 文件引用 include ... 定义文件 #define, #ifdef, #ifndef 关键字如下： 12345assert bit bits class codedag def dump else falseforeach defm defset defvar fieldif in include int letlist multiclass string then true 类型系统 bit int 字符串 bits&lt;N&gt; list&lt;type&gt; ClassID 比如定义一个class Register，那么有 list&lt;Register&gt; 值和表达式 字面量 布尔值 未知值 ? 多位bit {1, 0, 1} 1, 0, 1 list initializer [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;] 类型说明可选 [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;] &lt;string&gt; DAG initializer 标识符 匿名record：给定class和参数列表 ClassID&lt;ArgList&gt; 运算符 语句class 定义抽象record123456789class C { bit V = true;}def X : C;def Y : C { let V = false; string Greeting = &quot;Hello!&quot;;} def 定义具体record123456789101112class FPFormat &lt;bits&lt;3&gt; val&gt; { bits&lt;3&gt; Value = val;}def NotFP : FPFormat&lt;0&gt;;def ZeroArgFP : FPFormat&lt;1&gt;;def OneArgFP : FPFormat&lt;2&gt;;def OneArgFPRW : FPFormat&lt;3&gt;;def TwoArgFP : FPFormat&lt;4&gt;;def CompareFP : FPFormat&lt;5&gt;;def CondMovFP : FPFormat&lt;6&gt;;def SpecialFP : FPFormat&lt;7&gt;; let 覆写class或者record中的field TODO: 先写了点常见的，不够再补。 定义Op定义Op所需要的class都定义在 $LLVM_ROOT/mlir/include/mlir/IR/OpBase.td 中： Op class：新的Op的定义都是从这个class中派生 Dialect class OpTrait class ins/outs marker：由后端定义的特别符号，用来引导操作数和结果的定义 TypeConstraint class：Type 是它的subclass AttrConstraint class：Attr 是它的subclass 示例1234567891011121314151617181920212223def TF_AvgPoolOp : TF_Op&lt;&quot;AvgPool&quot;, [NoMemoryEffect]&gt; { let summary = &quot;Performs average pooling on the input.&quot;; let description = [{Each entry in `output` is the mean of the corresponding size `ksize`window in `value`. }]; let arguments = (ins TF_FpTensor:$value, ConfinedAttr&lt;I64ArrayAttr, [ArrayMinCount&lt;4&gt;]&gt;:$ksize, ConfinedAttr&lt;I64ArrayAttr, [ArrayMinCount&lt;4&gt;]&gt;:$strides, TF_AnyStrAttrOf&lt;[&quot;SAME&quot;, &quot;VALID&quot;]&gt;:$padding, DefaultValuedAttr&lt;TF_ConvertDataFormatAttr, &quot;NHWC&quot;&gt;:$data_format ); let results = (outs TF_FpTensor:$output ); TF_DerivedOperandTypeAttr T = TF_DerivedOperandTypeAttr&lt;0&gt;;} 各个field含义如下： Op名称：TF_AvgPoolOp 文档信息：summary, description 参数：arguments operation：其它Op传过来的result attribute：编译时已知的常量 Natural attribute：影响Op的行为 Derived attribute：由Op内信息推断得到 是DAG类型TableGen参数，以 ins 开始，后续为 &lt;type-constraint&gt;:$&lt;operand-name&gt; 或者 &lt;attr-constraint&gt;:$&lt;attr-name&gt; operation和attribute的顺序在 arguments 中没有限制 结果：result 特指在这个Op作为出边的值 是DAG类型TableGen参数，以 outs 开始，后续为 &lt;type-constraint&gt;:$&lt;result-name&gt; 其它field可变参数 (variadic operands)语法为 Variadic&lt;...&gt;。 可选参数 (optional operands)语法为 Optional&lt;...&gt;。 可选attribute语法为 OptionalAttr&lt;...&gt;。 约束attribute添加约束条件，如 ConfinedAttr&lt;I32Attr, [IntMinValue&lt;10&gt;]&gt;。 IntMinValue&lt;N&gt;: Specifying an integer attribute to be greater than or equal to N IntMaxValue&lt;N&gt;: Specifying an integer attribute to be less than or equal to N ArrayMinCount&lt;N&gt;: Specifying an array attribute to have at least N elements IntArrayNthElemEq&lt;I, N&gt;: Specifying an integer array attribute’s I-th element to be equal to N IntArrayNthElemMinValue&lt;I, N&gt;: Specifying an integer array attribute’s I-th element to be greater than or equal to N IntArrayNthElemMaxValue&lt;I, N&gt;: Specifying an integer array attribute’s I-th element to be less than or equal to N IntArrayNthElemInRange&lt;I, M, N&gt;: Specifying an integer array attribute’s I-th element to be greater than or equal to M and less than or equal to N Region由 region 引导的dag数据类型。 1234let regions = (region &lt;region-constraint&gt;:$&lt;region-name&gt;, ...); Op successor由 successor 引导的dag数据类型。 1234let successors = (successor &lt;successor-constraint&gt;:$&lt;successor-name&gt;, ...); Op trait &amp; Op constraintsTrait和constraint都是作为Op class的参数传入。 Builder methodODS能够根据参数和返回类型生成基础的builder： 1234567891011121314151617def MyOp : ... { let arguments = (ins I32:$i32_operand, F32:$f32_operand, ..., I32Attr:$i32_attr, F32Attr:$f32_attr, ... ); let results = (outs I32:$i32_result, F32:$f32_result, ... );} 会生成如下的函数签名： 12345678910111213141516171819202122232425262728293031323334// All result-types/operands/attributes have one aggregate parameter.static void build(OpBuilder &amp;odsBuilder, OperationState &amp;odsState, TypeRange resultTypes, ValueRange operands, ArrayRef&lt;NamedAttribute&gt; attributes);// Each result-type/operand/attribute has a separate parameter. The parameters// for attributes are of mlir::Attribute types.static void build(OpBuilder &amp;odsBuilder, OperationState &amp;odsState, Type i32_result, Type f32_result, ..., Value i32_operand, Value f32_operand, ..., IntegerAttr i32_attr, FloatAttr f32_attr, ...);// Each result-type/operand/attribute has a separate parameter. The parameters// for attributes are raw values unwrapped with mlir::Attribute instances.// (Note that this builder will not always be generated. See the following// explanation for more details.)static void build(OpBuilder &amp;odsBuilder, OperationState &amp;odsState, Type i32_result, Type f32_result, ..., Value i32_operand, Value f32_operand, ..., APInt i32_attr, StringRef f32_attr, ...);// Each operand/attribute has a separate parameter but result type is aggregate.static void build(OpBuilder &amp;odsBuilder, OperationState &amp;odsState, TypeRange resultTypes, Value i32_operand, Value f32_operand, ..., IntegerAttr i32_attr, FloatAttr f32_attr, ...);// All operands/attributes have aggregate parameters.// Generated if return type can be inferred.static void build(OpBuilder &amp;odsBuilder, OperationState &amp;odsState, ValueRange operands, ArrayRef&lt;NamedAttribute&gt; attributes);// (And manually specified builders depending on the specific op.) 第一个builder的函数签名是所有Op都相同的，供 MLIRContext::create 使用 第二个和第三个builder对于编写MLIR代码比较有用 自定义builder如果上述的builder不能满足需求，则可以填充 builders field来添加定义： 1234567def MyOp : Op&lt;&quot;my_op&quot;, []&gt; { let arguments = (ins F32Attr:$attr); let builders = [ OpBuilder&lt;(ins &quot;float&quot;:$val)&gt; ];} 该field会生成如下的函数签名： 12345class MyOp : /*...*/ { /*...*/ static void build(::mlir::OpBuilder &amp;builder, ::mlir::OperationState &amp;state, float val);}; ODS中也能直接描述builder的具体实现： 123456789def MyOp : Op&lt;&quot;my_op&quot;, []&gt; { let arguments = (ins F32Attr:$attr); let builders = [ OpBuilder&lt;(ins &quot;float&quot;:$val), [{ $_state.addAttribute(&quot;attr&quot;, $_builder.getF32FloatAttr(val)); }]&gt; ];} $_builder 和 $_state 是特殊变量，对应于C++形式中的 builder 和 state 但只推荐在ODS中构建简单的builder，复杂的builder最好还是实现为C++ 为参数添加默认值需要使用 CArg 进行包装： 123456789def MyOp : Op&lt;&quot;my_op&quot;, []&gt; { let arguments = (ins F32Attr:$attr); let builders = [ OpBuilder&lt;(ins CArg&lt;&quot;float&quot;, &quot;0.5f&quot;&gt;:$val), [{ $_state.addAttribute(&quot;attr&quot;, $_builder.getF32FloatAttr(val)); }]&gt; ];} 对应的C++为： 123456789101112/// Header file.class MyOp : /*...*/ { /*...*/ static void build(::mlir::OpBuilder &amp;builder, ::mlir::OperationState &amp;state, float val = 0.5f);};/// Source file.MyOp::build(::mlir::OpBuilder &amp;builder, ::mlir::OperationState &amp;state, float val) { state.addAttribute(&quot;attr&quot;, builder.getF32FloatAttr(val));} Verifier12let hasVerifier = 1;let hasRegionVerifier = 1; // for nested operation 验证顺序： StructuralOp trait会被首先验证 verifyInvariants 会验证type/attribute 剩下的Trait和interface需要设置 verifyTrait 和 verifyWithRegion 进行验证 自定义的verifier 传递诊断信息 Note Remark Warning Error Declarative assembly format通过使用ODS中预定义的和attribute等匹配的关键字来定义Op的文本形式： 12345678def CallOp : Std_Op&lt;&quot;call&quot;, ...&gt; { let arguments = (ins FlatSymbolRefAttr:$callee, Variadic&lt;AnyType&gt;:$args); let results = (outs Variadic&lt;AnyType&gt;); let assemblyFormat = [{ $callee `(` $args `)` attr-dict `:` functional-type($args, results) }];} 保留的diective含义如下： attr-dict Represents the attribute dictionary of the operation. attr-dict-with-keyword Represents the attribute dictionary of the operation, but prefixes the dictionary with an attributes keyword. custom &lt; UserDirective &gt; ( Params ) Represents a custom directive implemented by the user in C++. See the Custom Directives section below for more details. functional-type (inputs, outputs) Formats the inputs and outputs arguments as a function type. The constraints on inputs and outputs are the same as the input of the type directive. oilist ( keyword elements | otherKeyword elements …) Represents an optional order-independent list of clauses. Each clause has a keyword and corresponding assembly format. Each clause can appear 0 or 1 time (in any order). Only literals, types and variables can be used within an oilist element. All the variables must be optional or variadic. operands Represents all of the operands of an operation. ref ( input ) Represents a reference to the a variable or directive, that must have already been resolved, that may be used as a parameter to a custom directive. Used to pass previously parsed entities to custom directives. The input may be any directive or variable, aside from functional-type and custom. regions Represents all of the regions of an operation. results Represents all of the results of an operation. successors Represents all of the successors of an operation. type ( input ) Represents the type of the given input. input must be either an operand or result variable, the operands directive, or the results directive. qualified ( type_or_attribute ) Wraps a type directive or an attribute parameter. Used to force printing the type or attribute prefixed with its dialect and mnemonic. For example the vector.multi_reduction operation has a kind attribute ; by default the declarative assembly will print: vector.multi_reduction , … but using qualified($kind) in the declarative assembly format will print it instead as: vector.multi_reduction #vector.kind, …. 可选成分1optional-group::= `(` then-elements `)` (`:` `(` else-elements `)`)? `?` then-elements 必须是一个attribute/literal/oprand/region 必须有一个参数作为anchor 作为anchor的参数以 ^ 控制这个可选的部分是否在Op中打印出来 optional group中只能出现literal/variable/custom directive/type directive 1234567def ReturnOp : ... { let arguments = (ins Variadic&lt;AnyType&gt;:$operands); // We only print the operands and types if there are a non-zero number // of operands. let assemblyFormat = &quot;attr-dict ($operands^ `:` type($operands))?&quot;;} Constraint Single-entity constraint 只对单个operand/attribute/result施加约束的 Multi-entity constraint 设置constraintConstraint由一组predicate构建： CPred：leaf predicate，包含能够返回一个布尔类型的C++表达式/函数调用/… Compound predicate 部分占位符被保留下来，转化为C++中的hook： $_builder：mlir::Builder 实例 $_op：当前所在的Op，用于访问Op的相关信息 $_self：和predicate绑定 1234567And&lt;[ CPred&lt;&quot;$_self.isa&lt;IntegerAttr&gt;()&quot;&gt;, Or&lt;[ CPred&lt;&quot;$_self.cast&lt;IntegerAttr&gt;().getType().isInteger(32)&quot;&gt;, CPred&lt;&quot;$_self.cast&lt;IntegerAttr&gt;().getType().isInteger(64)&quot;&gt; ]&gt;]&gt; 如果一个constraint比较复杂，先用C++实现，然后再tablegen中识别： 1bool HasSomeProperty(Attribute attr) { ... } 123456789def HasSomeProperty : AttrConstraint&lt;CPred&lt;&quot;HasSomeProperty($_self)&quot;&gt;, &quot;has some property&quot;&gt;;def MyOp : Op&lt;...&gt; { let arguments = (ins ... HasSomeProperty:$attr );} 定义AttributeMLIR中Attribute的本质就是编译时常量，所以有着各种类型，如 StrAttr (C++ StringAttr)。完整的attribute见ODS attribute class。","link":"/2024/01/10/MLIR/3_ODS/"},{"title":"MLIR Toy Code Reading","text":"Prologue直接看完了toy tutorial和ODS文档感觉还是有很多东西都似是而非，还是需要回到具体的代码中才能把相关的概念全都搞懂。 Chap2$INSTALL_PATH/examples/toyc-ch2 的功能显然比 toyc-ch1 功能更多，能够把AST转换为mlir代码。两个代码的目录树分别如下： 12345678910111213141516171819202122232425262728293031# ch1.├── CMakeLists.txt├── include│ └── toy│ ├── AST.h│ ├── Lexer.h│ └── Parser.h├── parser│ └── AST.cpp└── toyc.cpp# ch2.├── CMakeLists.txt├── include│ ├── CMakeLists.txt│ └── toy│ ├── AST.h│ ├── CMakeLists.txt│ ├── Dialect.h│ ├── Lexer.h│ ├── MLIRGen.h│ ├── Ops.td│ └── Parser.h├── mlir│ ├── Dialect.cpp│ └── MLIRGen.cpp├── parser│ └── AST.cpp└── toyc.cpp CMake配置注意事项 TODO: 设置编译器为clang时，编译选项 -fno-lifetime-dse 会产生冲突 rtti特性会导致链接出错，需要加上 -fno-rtti toyc.cppToy lang编译器的驱动。使用LLVM命令行工具做了一堆防止点炒饭的代码，有价值的部分就是函数 dumpMLIR。该函数首先调用 parseInputFile 将toy lang的最上层结构——Moudle——解析，并以AST的形式 std::unique_ptr&lt;MouduleAST&gt; 传回，得到一个可用于后续工作的AST。MLIR的生成交给 mlirGen 函数完成，定义在 toy/MLIR/MLIRGen.cpp 中。 MLITGen.cpp实现代码转换的功能模块叫做 MLIRGenImpl，其方法 mlirGen 负责将AST转换为mlir。从中可以看出，MLIR最高级的结构由 ModuleOp 表示，开辟了全局的region。 之后的过程就是不断遍历AST然后递归地调用 mlirGen 的不同重载来填充 ModuleOp。最后回到 toyc.cpp 中的函数 dumpMLIR，使用 ModuleOp::dump 方法打印我们得到的MLIR。 在打印MLIR代码这件事情上，还可以用 MLIRContext::print 来达到一样的目的。 核心文件 Ops.td Dialect.cpp 从tablegen到CPP从之前的教程能够看出，从 Ops.td 到CPP接口需要分别生成dialect和Op的相关文件。根据 $BUILD_PATH/tools/mlir/examples/toy/Ch2/include/toy 中的内容可以推导出相关命名规则如下： 在项目的include目录下创建存放dialect的目录，命名为dialect的名字 -gen-dialect-decls 生成的文件命名为 Dialect.h.inc -gen-dialect-defs 生成的文件命名为 Dialect.cpp.inc -gen-op-decls 生成的文件命名为 Ops.h.inc -gen-op-defs 生成的文件命名为 Ops.cpp.inc 相关文件的生成都写在了 CMakeLists.txt Ops.tdbuilder即使不填充相关filed，编译器也会自动生成三个builder，包括函数签名和实现。 Builder的定义可以只跟一个定义： 1OpBuilder&lt;(ins &quot;double&quot;:$value)&gt; 其对应的函数签名如下所示： 1static void build(::mlir::OpBuilder &amp;odsBuilder, ::mlir::OperationState &amp;odsState, double value); 具体的实现需要自己去填补。 但是当builder足够简单时，也可以把实现写入tablegen中： 123OpBuilder&lt;(ins &quot;DenseElementsAttr&quot;:$value), [{ build($_builder, $_state, value.getType(), value); }]&gt;, [{...}] 中的内容为C++代码，用来描述比较简单的builder的定义 其对应函数签名和实现如下： 123void ConstantOp::build(::mlir::OpBuilder &amp;odsBuilder, ::mlir::OperationState &amp;odsState, DenseElementsAttr value) { build(odsBuilder, odsState, value.getType(), value); } Builder实现中的一些困惑事项 ParseResult 会将 LogicalResult 的值反转，目的是让语法解析像BNF那样用 || 连接 Each of these methods returns a ParseResult. This class is a wrapper around LogicalResult that can be converted to a boolean true value on failure, or false on success. verify 中仍然使用原本的 LogicalResult Chap 3本章节的核心内容为： ToyCombine.cpp ToyCombine.td 以及在驱动 toyc.cpp 中使用passmanager对实现优化遍进行了注册。 代码变换的基本形式Tablegen中进行代码变换需要使用 Pat 进行。 123// Reshape(Reshape(x)) = Reshape(x)def ReshapeReshapeOptPattern : Pat&lt;(ReshapeOp(ReshapeOp $arg)), (ReshapeOp $arg)&gt;; NativeCodeCall在代码转换的过程中需要使用C++辅助函数时需要以 NativeCodeCall 描述： 123456// Reshape(Constant(x)) = x'def ReshapeConstant : NativeCodeCall&lt;&quot;$0.reshape(::llvm::cast&lt;ShapedType&gt;($1.getType()))&quot;&gt;;def FoldConstantReshapeOptPattern : Pat&lt; (ReshapeOp:$res (ConstantOp $arg)), (ConstantOp (ReshapeConstant $arg, $res))&gt;;","link":"/2024/01/11/MLIR/4_Toy%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB/"},{"title":"MLIR杂谈","text":"MLIR custom operation BNF和 mlir::OpBuilder::create 的关系在 OpBuilder::create 中，MLIR提供了三种重载 123456789101112131415161718192021222324Operation *OpBuilder::create(const OperationState &amp;state) { return insert(Operation::create(state));}Operation *OpBuilder::create(Location loc, StringAttr opName, ValueRange operands, TypeRange types, ArrayRef&lt;NamedAttribute&gt; attributes, BlockRange successors, MutableArrayRef&lt;std::unique_ptr&lt;Region&gt;&gt; regions) { OperationState state(loc, opName, operands, types, attributes, successors, regions); return create(state);}template &lt;typename OpTy, typename... Args&gt;OpTy create(Location location, Args &amp;&amp;...args) { OperationState state(location, getCheckRegisteredInfo&lt;OpTy&gt;(location.getContext())); OpTy::build(*this, state, std::forward&lt;Args&gt;(args)...); auto *op = create(state); auto result = dyn_cast&lt;OpTy&gt;(op); assert(result &amp;&amp; &quot;builder didn't return the right type&quot;); return result; } 目前在github搜索到使用OpBuilder构建Op的代码中，第三种 create 是用的最多的。但是这里使用了工厂模式+完美转发让代码补全无法提示到底需要哪些参数，这时候就需要自己去对应Op的 build 方法中去找了。 但是每个参数的含义还是要根据BNF去找 (以custom Op为准)。比如在 arith::ConstOp 里面，我一开始不太清楚哪个 Attr 到底是什么玩意，打开BNF才知道那是常量在MLIR中以attribute的形式存在。 编写MLIR代码用于测试MLIR本身并不是一种语言，而是一种编译设施。因此，文档中大多在描述你该如何定义自己的dialect、如何对代码进行转换，而不会像一般的编译语言一样从类型到控制指令那样逐步教你使用。另一方面，虽然MLIR为里面有的dialect提供了文档，但是确定编写一份样例中需要使用哪些dialect也是一件很麻烦的事情——因为选项实在太多了。 MLIR Op和C++ CRTPCRTP (Curiously recurring template pattern) 是C++中的一种编程技巧，用于提供静态多态的能力。该技术的大致模板如下： 1234template &lt;typename T&gt;class Base { ... };class Derived : Base&lt;Drived&gt; { ... }; 在C++中定义Op时也会用到这种技巧，其体现为： 1class ConstantOp : public mlir::Op&lt;ConstantOp, ... &gt; { ... }; 这种模式的使用对于提高MLIR框架的性能比较有帮助。 Op 和 OperationMLIR的C++接口中提供了 Op 和 Operation 两种相关的类。 从语法上讲，Operation 对应于generic Op，并不会用来直接描述某个具体的Op；Op 对应于MLIR语法中的custom Op，能够很方便地定义Op，所以定义Op时全是从 Op 继承。 从C++实现上讲，Op 的派生类很像是 Operation * 类型的智能指针，能够进行动态类型转换，但是更加便于使用，如下所示： 123456789101112void processConstantOp(mlir::Operation *operation) { ConstantOp op = llvm::dyn_cast&lt;ConstantOp&gt;(operation); // This operation is not an instance of `ConstantOp`. if (!op) return; // Get the internal operation instance wrapped by the smart pointer. mlir::Operation *internalOperation = op.getOperation(); assert(internalOperation == operation &amp;&amp; &quot;these operation instances are the same&quot;);} Round-tripRound-trip描述的是src-&gt;target-&gt;src的过程，主要用于调试自定义的MLIR是否对源代码进行了正确的建模。","link":"/2024/01/03/MLIR/999_%E6%9D%82%E8%B0%88/"},{"title":"MLIR Toy Tutorial","text":"Prologue本文档是基于MLIR Toy Tutorial上附加本人学习经验中遇到的问题及经验而成的学习笔记。 Chap1为了复现教程中的内容，在用CMake配置LLVM时需要加上选项 -DLLVM_BUILD_EXAMPLES=ON 来编译相关示例代码，能够在 $BUILD_PATH/bin 或者 $INSTALL_PATH/examples 中找到。 教程中所用的toy语言编译器文件树如下： 12345678910.├── CMakeLists.txt├── include│ └── toy│ ├── AST.h│ ├── Lexer.h│ └── Parser.h├── parser│ └── AST.cpp└── toyc.cpp 使用MLIR来扩展编译流程时，通常是在Clang AST和LLVM IR中间插入了一个层次，所以这个教程中的toy编译器仅提供了将源代码解析为AST的能力。 Toy测试用例如下，可以在 $LLVM_ROOT/mlir/test/Examples/Toy/Ch1/ast.toy 该样例： 1234567891011121314151617181920212223242526# User defined generic function that operates on unknown shaped arguments.def multiply_transpose(a, b) { return transpose(a) * transpose(b);}def main() { # Define a variable `a` with shape &lt;2, 3&gt;, initialized with the literal value. var a = [[1, 2, 3], [4, 5, 6]]; var b&lt;2, 3&gt; = [1, 2, 3, 4, 5, 6]; # This call will specialize `multiply_transpose` with &lt;2, 3&gt; for both # arguments and deduce a return type of &lt;3, 2&gt; in initialization of `c`. var c = multiply_transpose(a, b); # A second call to `multiply_transpose` with &lt;2, 3&gt; for both arguments will # reuse the previously specialized and inferred version and return &lt;3, 2&gt;. var d = multiply_transpose(b, a); # A new call with &lt;3, 2&gt; (instead of &lt;2, 3&gt;) for both dimensions will # trigger another specialization of `multiply_transpose`. var e = multiply_transpose(c, d); # Finally, calling into `multiply_transpose` with incompatible shapes # (&lt;2, 3&gt; and &lt;3, 2&gt;) will trigger a shape inference error. var f = multiply_transpose(a, c);} 打印该示例代码的命令为 1$INSTALL_PATH/examples/toyc-ch1 ast.toy Chap2MLIR的核心是Operation，简记为Op。Op具有良好的可扩展性，下列例子展示了为toy中的builtin操作 transpose 定义的Op： 1%t_tensor = &quot;toy.transpose&quot;(%tensor) {inplace = true} : (tensor&lt;2x3xf64&gt;) -&gt; tensor&lt;3x2xf64&gt; loc(&quot;example/file/path&quot;:12:1) 这里给出的是generic形式的Op，其含义如下： t_tensor：Op的resultMLIR整体被视为一张数据流图，Op是节点，而result就是Op的出边 toy.transpose：. 之前是方言，之后是Opcode方言可以被视为MLIR的名称空间 (%tensor)：操作数，满足SSA性质 {inplace=true}：attribute dictionary (tensor&lt;2x3xf64&gt;) -&gt; tensor&lt;3x2xf64&gt;：Op的参数类型和返回值类型 loc(&quot;example/file/path&quot;:12:1) 源代码中的位置信息 教程里说位置信息是需要要有的，这点在各个Op的C++ build 方法的参数中得到了体现。但是还是可以通过 builder.getUnknownLoc() 达到如传的效果。 定义toy dialect从C++定义： 1234567891011121314151617181920using m = ::mlir;class ToyDialect : public m::Dialect {public: explicit ToyDialect(m::MLIRContext *ctx); // utility accessor for dialect static llvm::StringRef getDialectNamespace() { return &quot;toy&quot;; } // call from constructor of ToyDialect used to // register attributes, operations, types, ... void initialize();};int main() { m::MLIRContext ctx; // register into context ctx.loadDialect&lt;m::toy::ToyDialect&gt;();} 从TableGene定义： 12345678910111213def Toy_Dialect : Dialect { // Equal to `ToyDialect::getDialectNamespace` let name = &quot;toy&quot;; // A short one-line summary for the dialect. let summary = &quot;A high-level dialect for toy lang&quot;; // A longer description of our dialect. let description = [{The toy lang is ... analysis and optimization.}]; // A specific CPP namespace for generating relevant files. let cppNamespace = &quot;toy&quot;} 从TableGen生成相关C++文件需要使用 mlir-tblgen： 1mlir-tblgen -gen-dialect-decls Ops.td -I ${mlir_src_root}/include/ TODO: 这里生成的文件输出在stdout中，为了在C++中引用，它应该放在哪里呢？文件名应该是什么？ 在 MLIRContext 中注册ToyDialect1context.loadDialect&lt;ToyDialect&gt;(); 定义Toy Op上述步骤定义了一个toy dialect，现在其内部还是空空如也，没有定义Op。接下来尝试定义 toy.constant Op，用来表示toy lang中的常量。 MLIR中的形式1%4 = &quot;toy.constant&quot;() { value = dense&lt;1.0&gt; : tensor&lt;2x3xf64&gt; } : () -&gt; tensor&lt;2x3xf64&gt; 没有操作数 dense 是builtin attribute，包含了一个稠密多维数组；该attribute和与名称 name 绑定在一起来表示一个常量，其类型为 tensor&lt;2x3xf64&gt; 使用C++定义123456789101112131415161718192021222324252627282930313233343536373839404142434445464748class ConstantOp : public mlir::Op&lt; /// `mlir::Op` is a CRTP class, meaning that we provide the /// derived class as a template parameter. ConstantOp, /// The ConstantOp takes zero input operands. mlir::OpTrait::ZeroOperands, /// The ConstantOp returns a single result. mlir::OpTrait::OneResult, /// We also provide a utility `getType` accessor that /// returns the TensorType of the single result. mlir::OpTraits::OneTypedResult&lt;TensorType&gt;::Impl&gt; { public: /// Inherit the constructors from the base Op class. using Op::Op; /// Provide the unique name for this operation. MLIR will use this to register /// the operation and uniquely identify it throughout the system. The name /// provided here must be prefixed by the parent dialect namespace followed /// by a `.`. static llvm::StringRef getOperationName() { return &quot;toy.constant&quot;; } /// Return the value of the constant by fetching it from the attribute. mlir::DenseElementsAttr getValue(); /// Operations may provide additional verification beyond what the attached /// traits provide. Here we will ensure that the specific invariants of the /// constant operation are upheld, for example the result type must be /// of TensorType and matches the type of the constant `value`. LogicalResult verifyInvariants(); /// Provide an interface to build this operation from a set of input values. /// This interface is used by the `builder` classes to allow for easily /// generating instances of this operation: /// mlir::OpBuilder::create&lt;ConstantOp&gt;(...) /// This method populates the given `state` that MLIR uses to create /// operations. This state is a collection of all of the discrete elements /// that an operation may contain. /// Build a constant with the given return type and `value` attribute. static void build(mlir::OpBuilder &amp;builder, mlir::OperationState &amp;state, mlir::Type result, mlir::DenseElementsAttr value); /// Build a constant and reuse the type from the given 'value'. static void build(mlir::OpBuilder &amp;builder, mlir::OperationState &amp;state, mlir::DenseElementsAttr value); /// Build a constant by broadcasting the given 'value'. static void build(mlir::OpBuilder &amp;builder, mlir::OperationState &amp;state, double value);}; Trait是一种高层次的信息，其它的还有表示参数和结果类型是否一致等；模板中除了第一参数用在CRTP之外，其它模板参数都是trait getValue 返回的是attrbute verifyInvariants 检验attrbute中保存的是不是一个tensor类型 build 提供给 OpBuilder::create 使用的构造方法 OperationState 包含各种创建Op的各种属性，如Op名称、位置信息等；这个对象很重量级，应该仅在创建时作为临时变量使用；在使用 OpBuilder::create 创建Op时，该对象由 create 自行创建 注册在 ToyDialect 中123void ToyDialect::initialize() { addOperations&lt;ConstantOp&gt;();} 使用ODS框架定义OpODS (Operation Definition Specification) 是MLIR提供的另一种定义Op的方式，使用TableGen语法。 基本框架使用ODS框架时，同样需要从 Op 中派生tablegen record。方便起见，这里先定义一个 Toy_Op 方便后续Op的定义。 1234567// Base class for toy dialect operations. This operation inherits from the base// `Op` class in OpBase.td, and provides:// * The parent dialect of the operation.// * The mnemonic for the operation, or the name without the dialect prefix.// * A list of traits for the operation.class Toy_Op&lt;string mnemonic, list&lt;Trait&gt; traits = []&gt; : Op&lt;Toy_Dialect, mnemonic, traits&gt;; mnemonic 指助记符，即Opcode/名字，与之前C++中的 ConstantOp::getOperationName 对应，但不用加上dialect的前缀 toy. Toy_Dialect 之前单独定义的dialect C++中定义时添加的trait在ODS中自动推导并加入 1def ConstantOp : Toy_Op&lt;&quot;constant&quot;&gt; {} 使用 mlir-tblgen 生成C++文件12mlir-tblgen -decls-op-defs Ops.td -I ${mlir_src_root}/include/mlir-tblgen -gen-op-decls Ops.td -I ${mlir_src_root}/include/ 参数和返回值填充 arguments 和 results 字段： 123456def ConstantOp : Toy_Op&lt;&quot;constant&quot;&gt; { // The constant operation takes an attribute as the only input. // `F64ElementsAttr` corresponds to a 64-bit floating-point ElementsAttr. let arguments = (ins F64ElementsAttr:$value); let results = (outs F64Tensor);} 添加文档添加 summary 和 description 字段： 123456789101112131415def ConstantOp : Toy_Op&lt;&quot;constant&quot;&gt; { ... // Provide a summary and description for this operation. This can be used to // auto-generate documentation of the operations within our dialect. let summary = &quot;constant operation&quot;; let description = [{ Constant operation turns a literal into an SSA value. The data is attached to the operation as an attribute. For example: %0 = &quot;toy.constant&quot;() { value = dense&lt;[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]&gt; : tensor&lt;2x3xf64&gt; } : () -&gt; tensor&lt;2x3xf64&gt; }];} 检验Op的语义设置 hasVerifier = 1 时会在头文件中生成函数签名 ::mlir::Logical verify()。 定义 buildTablegen能够自动生成一些简单的Op创建函数，剩下的创建函数则需要填充 builders 字段来生成： 123456789101112131415161718def ConstantOp : Toy_Op&lt;&quot;constant&quot;&gt; { ... // Add custom build methods for the constant operation. These methods populate // the `state` that MLIR uses to create operations, i.e. these are used when // using `builder.create&lt;ConstantOp&gt;(...)`. let builders = [ // Build a constant with a given constant tensor value. OpBuilder&lt;(ins &quot;DenseElementsAttr&quot;:$value), [{ // Call into an autogenerated `build` method. build(builder, result, value.getType(), value); }]&gt;, // Build a constant with a given constant floating-point value. This builder // creates a declaration for `ConstantOp::build` with the given parameters. OpBuilder&lt;(ins &quot;double&quot;:$value)&gt; ];} 指定MLIR代码格式在完整的实现中，$INSTALL_PATH/examples/toyc-ch2 ast.toy -emit=mlir -mlir-print-debuginfo 2&gt; codegen.mlir 能够生成MLIR的generic形式。然而这种形式阅读性不够好，通过自定义指令格式能够获得更好的可读性。 e.g. toy.print 指令在generic格式下会被打印为： 1&quot;toy.print&quot;(%5) : (tensor&lt;*xf64&gt;) -&gt; () loc(&quot;test/Examples/Toy/Ch2/codegen.toy&quot;:13:3) 然而在定义中它的格式为： 1toy.print %5 : tensor&lt;*xf64&gt; loc(...) 通过填充 assemblyFormat 和 hasAssemblyFormat 字段能够做到： 12345678910111213/// Consider a stripped definition of `toy.print` here.def PrintOp : Toy_Op&lt;&quot;print&quot;&gt; { let arguments = (ins F64Tensor:$input); // Divert the printer and parser to `parse` and `print` methods on our operation, // to be implemented in the .cpp file. More details on these methods is shown below. let hasCustomAssemblyFormat = 1; // In the following format we have two directives, `attr-dict` and `type`. // These correspond to the attribute dictionary and the type of a given // variable represectively. let assemblyFormat = &quot;$input attr-dict `:` type($input)&quot;;} asseblyFormat 字段填入的为declarative格式，主要包括下列三个部分： directives：示例中的 type literals：由 `` 包围，或者关键字 variables：在Op中注册的数据项，如操作数，结果，后继等，以 $ 开头 Dialect.h 和 Dialect.cpp该文件需要引用上述生成的文件，用来实现各种解析规则、非默认的 build 方法和 verify 方法。 MLIR相关的内容都放在了目录 mlir 下。 Summary从文档中可以看出来官方很希望我们用ODS方式来实现我们的MLIR dialect和Op。所有的dialect的文档都是用ODS格式写的。 Chap3高层次上语言专有的代码变换和编写dialect/Op一样，MLIR提供了C++和ODS两种方式来编写代码转换。核心的转换思路都是DAG-to-DAG的转换：匹配一组Op的DAG，然后用另一个DAG去替换它。 12345678910111213141516171819202122232425262728293031class MyPattern : public RewritePattern {public: /// This overload constructs a pattern that only matches operations with the /// root name of `MyOp`. MyPattern(PatternBenefit benefit, MLIRContext *context) : RewritePattern(MyOp::getOperationName(), benefit, context) {} /// This overload constructs a pattern that matches any operation type. MyPattern(PatternBenefit benefit) : RewritePattern(benefit, MatchAnyOpTypeTag()) {} /// In this section, the `match` and `rewrite` implementation is specified /// using the separate hooks. LogicalResult match(Operation *op) const override { // The `match` method returns `success()` if the pattern is a match, failure // otherwise. // ... } void rewrite(Operation *op, PatternRewriter &amp;rewriter) { // The `rewrite` method performs mutations on the IR rooted at `op` using // the provided rewriter. All mutations must go through the provided // rewriter. } /// In this section, the `match` and `rewrite` implementation is specified /// using a single hook. LogicalResult matchAndRewrite(Operation *op, PatternRewriter &amp;rewriter) { // The `matchAndRewrite` method performs both the matching and the mutation. // Note that the match must reach a successful point before IR mutation may // take place. }}; Pattern的定义需要继承 RewritePattern 构造函数的参数 benefit 是一个可以被动态计算的值，大致是用来确定变换的优先级 (TODO: 文档里说的东西我没理解) RewritePatern(MyOp&quot;&quot;getOperationName(), ...) 中指定了匹配的DAG中根Op的名称；如果不指定则需要加上 MatchAnyOpTypeTag 来匹配任何可能的pattern match 中不能进行代码变换 rewrite 中的代码变换必须用参数中的 PatternRewriter 进行；根Op必须进行以下操作之一：updated in-place、replaced或者erased match 和 rewrite 分别是匹配和重写的具体实现，但是当这两个过程中存在一些复杂的分析或者计算过程时，为了结果复用，可以将两者合并实现为 matchAndRewrite transpose(transpose(X)) -&gt; X对于张量 X 而言，连续两次转置操作等价于恒等变换，因此能够进行代码变换来消除冗余操作。 源代码形式： 123def transpose_transpose(x) { return transpose(transpose(x));} 中间表示形式： 12345toy.func @transpose_transpose(%arg0: tensor&lt;*xf64&gt;) -&gt; tensor&lt;*xf64&gt; { %0 = toy.transpose(%arg0 : tensor&lt;*xf64&gt;) to tensor&lt;*xf64&gt; %1 = toy.transpose(%0 : tensor&lt;*xf64&gt;) to tensor&lt;*xf64&gt; toy.return %1 : tensor&lt;*xf64&gt;} C++实现123456789101112131415161718192021222324252627/// Fold transpose(transpose(x)) -&gt; xstruct SimplifyRedundantTranspose : public mlir::OpRewritePattern&lt;TransposeOp&gt; { /// We register this pattern to match every toy.transpose in the IR. /// The &quot;benefit&quot; is used by the framework to order the patterns and process /// them in order of profitability. SimplifyRedundantTranspose(mlir::MLIRContext *context) : OpRewritePattern&lt;TransposeOp&gt;(context, /*benefit=*/1) {} /// This method is attempting to match a pattern and rewrite it. The rewriter /// argument is the orchestrator of the sequence of rewrites. It is expected /// to interact with it to perform any changes to the IR from here. mlir::LogicalResult matchAndRewrite(TransposeOp op, mlir::PatternRewriter &amp;rewriter) const override { // Look through the input of the current transpose. mlir::Value transposeInput = op.getOperand(); TransposeOp transposeInputOp = transposeInput.getDefiningOp&lt;TransposeOp&gt;(); // Input defined by another transpose? If not, no match. if (!transposeInputOp) return failure(); // Otherwise, we have a redundant transpose. Use the rewriter. rewriter.replaceOp(op, {transposeInputOp.getOperand()}); return success(); }}; 将根Op设置为 TransposeOp 然后判定其参数是不是也是一个 TransposeOp，即可完成判定 代码重写通过 rewriter 完成，用最内层的操作数替换 Canonicalization pass规范化pass能够应有上述的重写规则对Op进行代码变换： 12345// Register our patterns for rewrite by the Canonicalization framework.void TransposeOp::getCanonicalizationPatterns( RewritePatternSet &amp;results, MLIRContext *context) { results.add&lt;SimplifyRedundantTranspose&gt;(context);} 为了启动这个变换还需要将 TransposeOp 的 hasCanonicalizer 字段设置为1。 在MLIR pass manager中注册在驱动 toyc.cpp 中需要将上述优化遍注册： 12mlir::PassManager pm(module-&gt;getName());pm.addNestedPass&lt;mlir::toy::FuncOp&gt;(mlir::createCanonicalizerPass()); pure Op和代码删除上述pass只能清除掉一个转置操作，即没有进行对整个DAG进行替换： 1234toy.func @transpose_transpose(%arg0: tensor&lt;*xf64&gt;) -&gt; tensor&lt;*xf64&gt; { %0 = toy.transpose(%arg0 : tensor&lt;*xf64&gt;) to tensor&lt;*xf64&gt; toy.return %arg0 : tensor&lt;*xf64&gt;} 这是因为MLIR会假设所有的Op都是有副作用的，因此会保守地进行代码删除。向 TransposeOp 中添加pure trait能够将两个转置操作都消除： 1def TransposeOp : Toy_Op&lt;&quot;transpose&quot;, [Pure]&gt; {...} reshape优化对张量进行同样形状的reshape操作也是一种冗余，比如下面的例子： 123456def main() { var a&lt;2,1&gt; = [1, 2]; var b&lt;2,1&gt; = a; var c&lt;2,1&gt; = b; print(c);} 12345678910module { toy.func @main() { %0 = toy.constant dense&lt;[1.000000e+00, 2.000000e+00]&gt; : tensor&lt;2xf64&gt; %1 = toy.reshape(%0 : tensor&lt;2xf64&gt;) to tensor&lt;2x1xf64&gt; %2 = toy.reshape(%1 : tensor&lt;2x1xf64&gt;) to tensor&lt;2x1xf64&gt; %3 = toy.reshape(%2 : tensor&lt;2x1xf64&gt;) to tensor&lt;2x1xf64&gt; toy.print %3 : tensor&lt;2x1xf64&gt; toy.return }} DRR实现DRR (Table-driven Declarative Rewrite Rule) 使用tablegen描述代码的代码变换规则： 12345678class Pattern&lt; dag sourcePattern, list&lt;dag&gt; resultPatterns, list&lt;dag&gt; additionalConstraints = [], dag benefitsAdded = (addBenefit 0)&gt;;// Transpose(Tranpose(x)) = xdef TTOptPattern : Pattern&lt;(TransposeOp(TransposeOp $arg)), ($arg)&gt;; 但是在进行reshape的优化时，我们需要根据reshape的参数来确定优化是否能够执行，而不是简单进行模式匹配。下面的DRR实现了冗余reshape消除优化，增加了约束条件——当输入和输出的shape一致时进行代码变换： 1234def TypesAreIdentical : Constraint&lt;CPred&lt;&quot;$0.getType() == $1.getType()&quot;&gt;&gt;;def RedundantReshapeOptPattern : Pattern&lt; (ReshapeOp:$res $arg), (replaceWithValue $arg), [(TypesAreIdentical $res, $arg)]&gt;; 在更特殊的情况下，我们还需要对参数进行变化，这需要通过 NativeCodeCall 进行。 1234def ReshapeConstant : NativeCodeCall&lt;&quot;$0.reshape(($1.getType()).cast&lt;ShapedType&gt;())&quot;&gt;;def FoldConstantReshapeOptPattern : Pat&lt; (ReshapeOp:$res (ConstantOp $arg)), (ConstantOp (ReshapeConstant $arg, $res))&gt;; Chap4通用代码变换在MLIR中，通用pass不需要为不同的dialect分别实现。之前在编写转置优化时，getCanonicalizationPatterns 就是一个用来注册pass的hook。但是hook的可扩展性比较有限，不能满足通用优化遍的需求，因此MLIR提供了interface来支持通用pass。 内联MLIR提供了通用的inliner并允许我们将其挂载到toy dialect中，我们需要提供让inliner挂载的interface。 Dialect interface12345678910111213141516171819202122232425262728293031323334353637383940414243444546/// This class defines the interface for handling inlining with Toy operations./// We simplify inherit from the base interface class and override/// the necessary methods.struct ToyInlinerInterface : public DialectInlinerInterface { using DialectInlinerInterface::DialectInlinerInterface; /// This hook checks to see if the given callable operation is legal to inline /// into the given call. For Toy this hook can simply return true, as the Toy /// Call operation is always inlinable. bool isLegalToInline(Operation *call, Operation *callable, bool wouldBeCloned) const final { return true; } /// This hook checks to see if the given operation is legal to inline into the /// given region. For Toy this hook can simply return true, as all Toy /// operations are inlinable. bool isLegalToInline(Operation *, Region *, bool, IRMapping &amp;) const final { return true; } /// This hook cheks if the given 'src' region can be inlined into the 'dest' /// region. The regions here are the bodies of the callable functions. For /// Toy, any function can be inlined, so we simply return true. bool isLegalToInline(Region *dest, Region *src, bool wouldBeCloned, IRMapping &amp;valueMapping) const final { return true; } /// This hook is called when a terminator operation has been inlined. The only /// terminator that we have in the Toy dialect is the return /// operation(toy.return). We handle the return by replacing the values /// previously returned by the call operation with the operands of the /// return. void handleTerminator(Operation *op, MutableArrayRef&lt;Value&gt; valuesToRepl) const final { // Only &quot;toy.return&quot; needs to be handled here. auto returnOp = cast&lt;ReturnOp&gt;(op); // Replace the values directly with the return operands. assert(returnOp.getNumOperands() == valuesToRepl.size()); for (const auto &amp;it : llvm::enumerate(returnOp.getOperands())) valuesToRepl[it.index()].replaceAllUsesWith(it.value()); }}; 这部分提供了在toy lang中进行内联操作的约束条件，重载了interface提供的虚函数hook 另一方面，inliner还需要设置函数在MLIR生成过程中的可见性，因为inliner会删掉被设置为private且没有没使用的函数的定义。 123456789/// Emit a new function and add it to the MLIR module.mlir::toy::FuncOp mlirGen(FunctionAST &amp;funcAST) { ... // If this function isn't main, then set the visibility to private. if (funcAST.getProto()-&gt;getName() != &quot;main&quot;) function.setPrivate(); return function;} 在dialect中注册和Op一样，interface也要在dialect中注册才能使用： 12345void ToyDialect::initialize() { ... addInterfaces&lt;ToyInlinerInterface&gt;();} Operation interfaceToy lang中使用 toy.generic_call 表示代码函数调用，使用 toy.func 表示函数定义。通过operation interface能够让iniliner知道要对这两个Op分别是call-like和callable-like。 在 Ops.td 中需要引用interface的相关文件： 1include &quot;mlir/Interfaces/CallInterfaces.td&quot; 添加相关trait： 123456789def FuncOp : Toy_Op&lt;&quot;func&quot;, [DeclareOpInterfaceMethods&lt;CallableOpInterface&gt;]&gt; { ...}def GenericCallOp : Toy_Op&lt;&quot;generic_call&quot;, [DeclareOpInterfaceMethods&lt;CallOpInterface&gt;]&gt; { ...} DeclareOpInterfaceMethods 是ODS direcitive，能自动生成所有的方法函数签名，使我们只用提供函数的实现 1234567891011121314151617181920/// Returns the region on the function operation that is callable.Region *FuncOp::getCallableRegion() { return &amp;getBody(); }// ..../// Return the callee of the generic call operation, this is required by the/// call interface.CallInterfaceCallable GenericCallOp::getCallableForCallee() { return getAttrOfType&lt;SymbolRefAttr&gt;(&quot;callee&quot;);}/// Set the callee for the generic call operation, this is required by the call/// interface.void GenericCallOp::setCalleeFromCallable(CallInterfaceCallable callee) { (*this)-&gt;setAttr(&quot;callee&quot;, callee.get&lt;SymbolRefAttr&gt;());}/// Get the argument operands to the called function, this is required by the/// call interface.Operation::operand_range GenericCallOp::getArgOperands() { return inputs(); } 添加到pass manager中1pm.addPass(mlir::createInlinerPass()); 处理类型转换在toy lang中，即使一个张量的shape是确定的，在传入的时候也会被转换为不定形状的 tensor&lt;*xf64&gt;，为此iniliner需要显式类型转换，实现为 toy.cast： 123456789101112131415161718def CastOp : Toy_Op&lt;&quot;cast&quot;, [ DeclareOpInterfaceMethods&lt;CastOpInterface&gt;, Pure, SameOperandsAndResultShape] &gt; { let summary = &quot;shape cast operation&quot;; let description = [{ The &quot;cast&quot; operation converts a tensor from one type to an equivalent type without changing any data elements. The source and destination types must both be tensor types with the same element type. If both are ranked, then shape is required to match. The operation is invalid if converting to a mismatching constant dimension. }]; let arguments = (ins F64Tensor:$input); let results = (outs F64Tensor:$output); let assemblyFormat = &quot;$input attr-dict `:` type($input) `to` type($output)&quot;;} Trait list中添加了 CastOpInterface，提供了一些转型用的工具，如检验转型是否正确 在实现中提供检验转型是否能成功的方法： 1234567891011121314/// Returns true if the given set of input and result types are compatible with/// this cast operation. This is required by the `CastOpInterface` to verify/// this operation and provide other additional utilities.bool CastOp::areCastCompatible(TypeRange inputs, TypeRange outputs) { if (inputs.size() != 1 || outputs.size() != 1) return false; // The inputs must be Tensors with the same element type. TensorType input = inputs.front().dyn_cast&lt;TensorType&gt;(); TensorType output = outputs.front().dyn_cast&lt;TensorType&gt;(); if (!input || !output || input.getElementType() != output.getElementType()) return false; // The shape is required to match if both types are ranked. return !input.hasRank() || !output.hasRank() || input == output;} 在dialect interface重载相关hook1234567891011121314struct ToyInlinerInterface : public DialectInlinerInterface { ... /// Attempts to materialize a conversion for a type mismatch between a call /// from this dialect, and a callable region. This method should generate an /// operation that takes 'input' as the only operand, and produces a single /// result of 'resultType'. If a conversion can not be generated, nullptr /// should be returned. Operation *materializeCallConversion(OpBuilder &amp;builder, Value input, Type resultType, Location conversionLoc) const final { return builder.create&lt;CastOp&gt;(conversionLoc, resultType, input); }}; 过程内shape传播内联前程序如下： 12345678910111213141516toy.func @multiply_transpose(%arg0: tensor&lt;*xf64&gt;, %arg1: tensor&lt;*xf64&gt;) -&gt; tensor&lt;*xf64&gt; { %0 = toy.transpose(%arg0 : tensor&lt;*xf64&gt;) to tensor&lt;*xf64&gt; %1 = toy.transpose(%arg1 : tensor&lt;*xf64&gt;) to tensor&lt;*xf64&gt; %2 = toy.mul %0, %1 : tensor&lt;*xf64&gt; toy.return %2 : tensor&lt;*xf64&gt;}toy.func @main() { %0 = toy.constant dense&lt;[[1.000000e+00, 2.000000e+00, 3.000000e+00], [4.000000e+00, 5.000000e+00, 6.000000e+00]]&gt; : tensor&lt;2x3xf64&gt; %1 = toy.reshape(%0 : tensor&lt;2x3xf64&gt;) to tensor&lt;2x3xf64&gt; %2 = toy.constant dense&lt;[1.000000e+00, 2.000000e+00, 3.000000e+00, 4.000000e+00, 5.000000e+00, 6.000000e+00]&gt; : tensor&lt;6xf64&gt; %3 = toy.reshape(%2 : tensor&lt;6xf64&gt;) to tensor&lt;2x3xf64&gt; %4 = toy.generic_call @multiply_transpose(%1, %3) : (tensor&lt;2x3xf64&gt;, tensor&lt;2x3xf64&gt;) -&gt; tensor&lt;*xf64&gt; %5 = toy.generic_call @multiply_transpose(%3, %1) : (tensor&lt;2x3xf64&gt;, tensor&lt;2x3xf64&gt;) -&gt; tensor&lt;*xf64&gt; toy.print %5 : tensor&lt;*xf64&gt; toy.return} 内联后程序如下： 1234567891011toy.func @main() { %0 = toy.constant dense&lt;[[1.000000e+00, 2.000000e+00, 3.000000e+00], [4.000000e+00, 5.000000e+00, 6.000000e+00]]&gt; : tensor&lt;2x3xf64&gt; %1 = toy.constant dense&lt;[[1.000000e+00, 2.000000e+00, 3.000000e+00], [4.000000e+00, 5.000000e+00, 6.000000e+00]]&gt; : tensor&lt;2x3xf64&gt; %2 = toy.cast %1 : tensor&lt;2x3xf64&gt; to tensor&lt;*xf64&gt; %3 = toy.cast %0 : tensor&lt;2x3xf64&gt; to tensor&lt;*xf64&gt; %4 = toy.transpose(%2 : tensor&lt;*xf64&gt;) to tensor&lt;*xf64&gt; %5 = toy.transpose(%3 : tensor&lt;*xf64&gt;) to tensor&lt;*xf64&gt; %6 = toy.mul %4, %5 : tensor&lt;*xf64&gt; toy.print %6 : tensor&lt;*xf64&gt; toy.return} 程序中出现了确定形状和不定形状张量类型的混合。为了让代码规范，shape传播可以被实现为toy dialect专有的pass，但是这个操作也很通用。将代码变换实现为通用的能够提高整个系统的可扩展性。完成这个pass的核心在于需要定义一个Op，它能够根据输入的类型推断合理的输出类型。 定义operation interface决定将这个Op实现为通用的组件，就需要将其实现为operation interface。 123456def ShapeInferenceOpInterface : OpInterface&lt;&quot;ShapeInference&quot;&gt; { let description = [{ Interface to access a registered method to infer the return types for an operation that can be used during type inference. }];} 接下来需要定义这个interface中的方法： 12345678def ShapeInferenceOpInterface : OpInterface&lt;&quot;ShapeInference&quot;&gt; { ... let methods = [ InterfaceMethod&lt;&quot;Infer and set the output shape for the current operation.&quot;, &quot;void&quot;, &quot;inferShapes&quot;&gt; ];} Interface方法包括： 描述信息 C++返回类型 方法名称 可选项 和之前使用inliner一样，向相关的toy Op添加trait，并以C++形式实现相关方法： 1234def MulOp : Toy_Op&lt;&quot;mul&quot;, [..., DeclareOpInterfaceMethods&lt;ShapeInferenceOpInterface&gt;]&gt; { ...} 123/// Infer the output shape of the MulOp, this is required by the shape inference/// interface.void MulOp::inferShapes() { getResult().setType(getLhs().getType()); } 定义pass1234567class ShapeInferencePass : public mlir::PassWrapper&lt;ShapeInferencePass, OperationPass&lt;FuncOp&gt;&gt; { void runOnOperation() override { FuncOp function = getOperation(); ... }}; OperationPass&lt;FuncOp&gt; 表示该pass只在func上使用 重载 runOnOperation 创建辅助函数以实例化该pass： 123std::unique_ptr&lt;mlir::Pass&gt; mlir::toy::createShapeInferencePass() { return std::make_unique&lt;ShapeInferencePass&gt;();} 向pass manager中注册： 1pm.addPass(mlir::createShapeInferencePass()); Shape inference的大致实现1234567891011// Ask the operation to infer its output shapes.LLVM_DEBUG(llvm::dbgs() &lt;&lt; &quot;Inferring shape for: &quot; &lt;&lt; *op &lt;&lt; &quot;\\n&quot;);/// We check if an operation has a particular interface by casting.if (ShapeInference shapeOp = dyn_cast&lt;ShapeInference&gt;(op)) { shapeOp.inferShapes();} else { op-&gt;emitError(&quot;unable to infer shape of operation without shape &quot; &quot;inference interface&quot;); return signalPassFailure();} Chap5生成能够真正执行的代码需要使用LLVM，但是直接通过LLVM builder会非常麻烦，因此真正采取的方法是对MLIR代码进行部分降级，达到一个各种dialect混合的状态。 这一节会将toy dialect中的某些结构转换为affine dialect：专门用来表示并优化计算密集的部分；将张量转换为 memref 使数据对象能够在affine循环中引用。这是因为tensor只表示一个数据类型，而不存在于内存中。 Dialect转换MLIR提供了一个框架 DialectConversion 对不同的dialect进行转换。这个框架需要以下信息： conversion target rewrite pattern type converter (option) Conversion target表示一个计算密集的部分可用的dialect有 affine, arith, func, memref。 123456789101112131415161718192021222324void ToyToAffineLoweringPass::runOnOperation() { // The first thing to define is the conversion target. This will define the // final target for this lowering. mlir::ConversionTarget target(getContext()); // We define the specific operations, or dialects, that are legal targets for // this lowering. In our case, we are lowering to a combination of the // `Affine`, `Arith`, `Func`, and `MemRef` dialects. target.addLegalDialect&lt;affine::AffineDialect, arith::ArithDialect, func::FuncDialect, memref::MemRefDialect&gt;(); // We also define the Toy dialect as Illegal so that the conversion will fail // if any of these operations are *not* converted. Given that we actually want // a partial lowering, we explicitly mark the Toy operations that don't want // to lower, `toy.print`, as *legal*. `toy.print` will still need its operands // to be updated though (as we convert from TensorType to MemRefType), so we // only treat it as `legal` if its operands are legal. target.addIllegalDialect&lt;ToyDialect&gt;(); target.addDynamicallyLegalOp&lt;toy::PrintOp&gt;([](toy::PrintOp op) { return llvm::none_of(op-&gt;getOperandTypes(), [](Type type) { return type.isa&lt;TensorType&gt;(); }); }); ...} Conversion target是保存降级后的代码的context 将toy dialect设置为illegal能够保证代码被完全转换；除了 toy.print Conversion pattern定义了conversion target之后，代码降级的过程就能够被定义为从illegal dialect向legal dialect的转换。相较于在dialect内优化代码的rewrite pattern，conversion pattern能够接受 operands 参数来处理操作数的类型转换。 123456789101112131415161718192021222324252627282930313233343536/// Lower the `toy.transpose` operation to an affine loop nest.struct TransposeOpLowering : public mlir::ConversionPattern { TransposeOpLowering(mlir::MLIRContext *ctx) : mlir::ConversionPattern(TransposeOp::getOperationName(), 1, ctx) {} /// Match and rewrite the given `toy.transpose` operation, with the given /// operands that have been remapped from `tensor&lt;...&gt;` to `memref&lt;...&gt;`. mlir::LogicalResult matchAndRewrite(mlir::Operation *op, ArrayRef&lt;mlir::Value&gt; operands, mlir::ConversionPatternRewriter &amp;rewriter) const final { auto loc = op-&gt;getLoc(); // Call to a helper function that will lower the current operation to a set // of affine loops. We provide a functor that operates on the remapped // operands, as well as the loop induction variables for the inner most // loop body. lowerOpToLoops( op, operands, rewriter, [loc](mlir::PatternRewriter &amp;rewriter, ArrayRef&lt;mlir::Value&gt; memRefOperands, ArrayRef&lt;mlir::Value&gt; loopIvs) { // Generate an adaptor for the remapped operands of the TransposeOp. // This allows for using the nice named accessors that are generated // by the ODS. This adaptor is automatically provided by the ODS // framework. TransposeOpAdaptor transposeAdaptor(memRefOperands); mlir::Value input = transposeAdaptor.input(); // Transpose the elements by generating a load from the reverse // indices. SmallVector&lt;mlir::Value, 2&gt; reverseIvs(llvm::reverse(loopIvs)); return rewriter.create&lt;mlir::AffineLoadOp&gt;(loc, input, reverseIvs); }); return success(); }}; 实现后conversion pattern需要注册会conversion target中： 12345678910void ToyToAffineLoweringPass::runOnOperation() { ... // Now that the conversion target has been defined, we just need to provide // the set of patterns that will lower the Toy operations. mlir::RewritePatternSet patterns(&amp;getContext()); patterns.add&lt;..., TransposeOpLowering&gt;(&amp;getContext()); ...} 部分降级123456789void ToyToAffineLoweringPass::runOnOperation() { ... // With the target and rewrite patterns defined, we can now attempt the // conversion. The conversion will signal failure if any of our *illegal* // operations were not converted successfully. if (mlir::failed(mlir::applyPartialConversion(getOperation(), target, patterns))) signalPassFailure();} partialConversion 是若干转换方法降级方式中的一种 注意事项一方面，我们将张量转换为了 memref；另一方面，toy.print 仍然以张量为参数类型。两者之间需要建立某种临时的辅助保证部分降级后的代码的正确性。以下几种方法都是可行的： 生成 load 操作来实例化tensor 可以不对 toy.print 进行修改 但是会影响affine的优化效果 另外创建一个类似 toy.print 但是能接受 memref 为参数的Op 不会引入额外的复制开销 但是会在dialect中引入冗余的Op 更新 toy.print 的定义 让toy dialect参与多个抽象层次，与MLIR的设计理念碰撞 从简便性考虑，教程最后采纳了第三种方案，允许 toy.print 接受 memref 作为参数： 1234567def PrintOp : Toy_Op&lt;&quot;print&quot;&gt; { ... // The print operation takes an input tensor to print. // We also allow a F64MemRef to enable interop during partial lowering. let arguments = (ins AnyTypeOf&lt;[F64Tensor, F64MemRef]&gt;:$input);} Chap 6降级到LLVM并生成代码在上一个步骤中，为了进行代码优化，我们进行了局部降级。现在为了生成可执行文件，我们必须要将代码彻底降级为LLVM dialect。 对 toy.print 降级方便起见，toy.print 会被转换为在每个元素上调用 printf。MLIR的转换是逐级进行的，因此不用直接映射到LLVM IR上。因此我们可以先生成SCF风格的 printf 循环而不是LLVM IR的基本块。 创建 printf 的函数声明1234567891011121314151617181920212223/// Return a symbol reference to the printf function, inserting it into the/// module if necessary.static FlatSymbolRefAttr getOrInsertPrintf(PatternRewriter &amp;rewriter, ModuleOp module, LLVM::LLVMDialect *llvmDialect) { auto *context = module.getContext(); if (module.lookupSymbol&lt;LLVM::LLVMFuncOp&gt;(&quot;printf&quot;)) return SymbolRefAttr::get(&quot;printf&quot;, context); // Create a function declaration for printf, the signature is: // * `i32 (i8*, ...)` auto llvmI32Ty = IntegerType::get(context, 32); auto llvmI8PtrTy = LLVM::LLVMPointerType::get(IntegerType::get(context, 8)); auto llvmFnType = LLVM::LLVMFunctionType::get(llvmI32Ty, llvmI8PtrTy, /*isVarArg=*/true); // Insert the printf function into the body of the parent module. PatternRewriter::InsertionGuard insertGuard(rewriter); rewriter.setInsertionPointToStart(module.getBody()); rewriter.create&lt;LLVM::LLVMFuncOp&gt;(module.getLoc(), &quot;printf&quot;, llvmFnType); return SymbolRefAttr::get(&quot;printf&quot;, context);} Conversion target123mlir::ConversionTarget target(getContext());target.addLegalDialect&lt;mlir::LLVMDialect&gt;();target.addLegalOp&lt;mlir::ModuleOp&gt;(); Type convertermemref 需要被转换为LLVM IR能够表示的类型，而type converter能够描述类型的映射关系。 1LLVMTypeConverter typeConverter(&amp;getContext()); Conversion pattern在降级的过程中，整个MLIR包含以下要素： toy affine arith std 好在 affine，arith 和 std 都已经内置像向LLVM dialect转换的pattern： 1234567891011mlir::RewritePatternSet patterns(&amp;getContext());mlir::populateAffineToStdConversionPatterns(patterns, &amp;getContext());mlir::cf::populateSCFToControlFlowConversionPatterns(patterns, &amp;getContext());mlir::arith::populateArithToLLVMConversionPatterns(typeConverter, patterns);mlir::populateFuncToLLVMConversionPatterns(typeConverter, patterns);mlir::cf::populateControlFlowToLLVMConversionPatterns(patterns, &amp;getContext());// The only remaining operation, to lower from the `toy` dialect, is the// PrintOp.patterns.add&lt;PrintOpLowering&gt;(&amp;getContext()); 完全降级与之前的部分降级相对，是另一种降级方式： 123mlir::ModuleOp module = getOperation();if (mlir::failed(mlir::applyFullConversion(module, target, patterns))) signalPassFailure(); 离开MLIR和代码生成LLVM dialect能够直接生成LLVM IR，接下来的工作只不过是调用工具而已。 123std::unique_ptr&lt;llvm::Module&gt; llvmModule = mlir::translateModuleToLLVMIR(module); if (!llvmModule) /* ... an error was encountered ... */ 设置JIT如果直接生成LLVM IR进行静态编译，还可以设置JIT编译 .mlir 文件。 1234567891011121314151617181920212223242526int runJit(mlir::ModuleOp module) { // Initialize LLVM targets. llvm::InitializeNativeTarget(); llvm::InitializeNativeTargetAsmPrinter(); // An optimization pipeline to use within the execution engine. auto optPipeline = mlir::makeOptimizingTransformer( /*optLevel=*/EnableOpt ? 3 : 0, /*sizeLevel=*/0, /*targetMachine=*/nullptr); // Create an MLIR execution engine. The execution engine eagerly JIT-compiles // the module. auto maybeEngine = mlir::ExecutionEngine::create(module, /*llvmModuleBuilder=*/nullptr, optPipeline); assert(maybeEngine &amp;&amp; &quot;failed to construct an execution engine&quot;); auto &amp;engine = maybeEngine.get(); // Invoke the JIT-compiled function. auto invocationResult = engine-&gt;invoke(&quot;main&quot;); if (invocationResult) { llvm::errs() &lt;&lt; &quot;JIT invocation failed\\n&quot;; return -1; } return 0;} Chap 7本节讨论如何在MLIR中添加一个新的复合数据对象。 Toy lang中的语法1234567# A struct is defined by using the `struct` keyword followed by a name.struct MyStruct { # Inside of the struct is a list of variable declarations without initializers # or shapes, which may also be other previously defined structs. var a; var b;} 在MLIR中增加定义定义type定义存储方式MLIR中的类型本质上是对 TypeStorage 对象的包装。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/// This class represents the internal storage of the Toy `StructType`.struct StructTypeStorage : public mlir::TypeStorage { /// The `KeyTy` is a required type that provides an interface for the storage /// instance. This type will be used when uniquing an instance of the type /// storage. For our struct type, we will unique each instance structurally on /// the elements that it contains. using KeyTy = llvm::ArrayRef&lt;mlir::Type&gt;; /// A constructor for the type storage instance. StructTypeStorage(llvm::ArrayRef&lt;mlir::Type&gt; elementTypes) : elementTypes(elementTypes) {} /// Define the comparison function for the key type with the current storage /// instance. This is used when constructing a new instance to ensure that we /// haven't already uniqued an instance of the given key. bool operator==(const KeyTy &amp;key) const { return key == elementTypes; } /// Define a hash function for the key type. This is used when uniquing /// instances of the storage. /// Note: This method isn't necessary as both llvm::ArrayRef and mlir::Type /// have hash functions available, so we could just omit this entirely. static llvm::hash_code hashKey(const KeyTy &amp;key) { return llvm::hash_value(key); } /// Define a construction function for the key type from a set of parameters. /// These parameters will be provided when constructing the storage instance /// itself, see the `StructType::get` method further below. /// Note: This method isn't necessary because KeyTy can be directly /// constructed with the given parameters. static KeyTy getKey(llvm::ArrayRef&lt;mlir::Type&gt; elementTypes) { return KeyTy(elementTypes); } /// Define a construction method for creating a new instance of this storage. /// This method takes an instance of a storage allocator, and an instance of a /// `KeyTy`. The given allocator must be used for *all* necessary dynamic /// allocations used to create the type storage and its internal. static StructTypeStorage *construct(mlir::TypeStorageAllocator &amp;allocator, const KeyTy &amp;key) { // Copy the elements from the provided `KeyTy` into the allocator. llvm::ArrayRef&lt;mlir::Type&gt; elementTypes = allocator.copyInto(key); // Allocate the storage instance and construct it. return new (allocator.allocate&lt;StructTypeStorage&gt;()) StructTypeStorage(elementTypes); } /// The following field contains the element types of the struct. llvm::ArrayRef&lt;mlir::Type&gt; elementTypes;}; 定义类型上述代码描述了类型该如何保存，而下面的定义才是真正用来交互的数据结构： 1234567891011121314151617181920212223242526272829303132/// This class defines the Toy struct type. It represents a collection of/// element types. All derived types in MLIR must inherit from the CRTP class/// 'Type::TypeBase'. It takes as template parameters the concrete type/// (StructType), the base class to use (Type), and the storage class/// (StructTypeStorage).class StructType : public mlir::Type::TypeBase&lt;StructType, mlir::Type, StructTypeStorage&gt; {public: /// Inherit some necessary constructors from 'TypeBase'. using Base::Base; /// Create an instance of a `StructType` with the given element types. There /// *must* be at least one element type. static StructType get(llvm::ArrayRef&lt;mlir::Type&gt; elementTypes) { assert(!elementTypes.empty() &amp;&amp; &quot;expected at least 1 element type&quot;); // Call into a helper 'get' method in 'TypeBase' to get a uniqued instance // of this type. The first parameter is the context to unique in. The // parameters after are forwarded to the storage instance. mlir::MLIRContext *ctx = elementTypes.front().getContext(); return Base::get(ctx, elementTypes); } /// Returns the element types of this struct type. llvm::ArrayRef&lt;mlir::Type&gt; getElementTypes() { // 'getImpl' returns a pointer to the internal storage instance. return getImpl()-&gt;elementTypes; } /// Returns the number of element type held by this struct. size_t getNumElementTypes() { return getElementTypes().size(); }}; 向toy dialect注册该类型： 123void ToyDialect::initialize() { addTypes&lt;StructType&gt;();} 暴露在ODS中使用ODS添加相关定义： 123456789// Provide a definition for the Toy StructType for use in ODS. This allows for// using StructType in a similar way to Tensor or MemRef. We use `DialectType`// to demarcate the StructType as belonging to the Toy dialect.def Toy_StructType : DialectType&lt;Toy_Dialect, CPred&lt;&quot;$_self.isa&lt;StructType&gt;()&quot;&gt;, &quot;Toy struct type&quot;&gt;;// Provide a definition of the types that are used within the Toy dialect.def Toy_Type : AnyTypeOf&lt;[F64Tensor, Toy_StructType]&gt;; 定义解析方式为了解析 StructType，需要在 ToyDialect 中添加解析方式： 123456789class ToyDialect : public mlir::Dialect {public: /// Parse an instance of a type registered to the toy dialect. mlir::Type parseType(mlir::DialectAsmParser &amp;parser) const override; /// Print an instance of a type registered to the toy dialect. void printType(mlir::Type type, mlir::DialectAsmPrinter &amp;printer) const override;}; 在实现上，我们需要给出正式的ODS语法： 1struct-type ::= `struct` `&lt;` type (`,` type)* `&gt;` 根据语法实现parser和printer： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/// Parse an instance of a type registered to the toy dialect.mlir::Type ToyDialect::parseType(mlir::DialectAsmParser &amp;parser) const { // Parse a struct type in the following form: // struct-type ::= `struct` `&lt;` type (`,` type)* `&gt;` // NOTE: All MLIR parser function return a ParseResult. This is a // specialization of LogicalResult that auto-converts to a `true` boolean // value on failure to allow for chaining, but may be used with explicit // `mlir::failed/mlir::succeeded` as desired. // Parse: `struct` `&lt;` if (parser.parseKeyword(&quot;struct&quot;) || parser.parseLess()) return Type(); // Parse the element types of the struct. SmallVector&lt;mlir::Type, 1&gt; elementTypes; do { // Parse the current element type. SMLoc typeLoc = parser.getCurrentLocation(); mlir::Type elementType; if (parser.parseType(elementType)) return nullptr; // Check that the type is either a TensorType or another StructType. if (!elementType.isa&lt;mlir::TensorType, StructType&gt;()) { parser.emitError(typeLoc, &quot;element type for a struct must either &quot; &quot;be a TensorType or a StructType, got: &quot;) &lt;&lt; elementType; return Type(); } elementTypes.push_back(elementType); // Parse the optional: `,` } while (succeeded(parser.parseOptionalComma())); // Parse: `&gt;` if (parser.parseGreater()) return Type(); return StructType::get(elementTypes);}/// Print an instance of a type registered to the toy dialect.void ToyDialect::printType(mlir::Type type, mlir::DialectAsmPrinter &amp;printer) const { // Currently the only toy type is a struct type. StructType structType = type.cast&lt;StructType&gt;(); // Print the struct type according to the parser format. printer &lt;&lt; &quot;struct&lt;&quot;; llvm::interleaveComma(structType.getElementTypes(), printer); printer &lt;&lt; '&gt;';} 添加使用 StructType 的Op更新既有的Op如 ReterunOp 需要添加对 StructType 的支持： 12345def ReturnOp : Toy_Op&lt;&quot;return&quot;, [Terminator, HasParent&lt;&quot;FuncOp&quot;&gt;]&gt; { ... let arguments = (ins Variadic&lt;Toy_Type&gt;:$input); ...} 实现新的Op12345%0 = toy.struct_constant [ dense&lt;[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]&gt; : tensor&lt;2x3xf64&gt;] : !toy.struct&lt;tensor&lt;*xf64&gt;&gt;%1 = toy.struct_access %0[0] : !toy.struct&lt;tensor&lt;*xf64&gt;&gt; -&gt; tensor&lt;*xf64&gt;","link":"/2024/01/04/MLIR/2_Toy-tutorial/"},{"title":"Abstract Syntax","text":"Abstract SyntaxASTAST的结构可以分为内部节点和叶子： 内部节点都是运算符 叶子只可能是：(1) 变量；(2) 没有参数的运算符。 在一门语言中，AST可以有多种类型 (sort)，如LLVM在它的教程Kaleidoscope中，AST有 ExprAST, PrototypeAST, FunctionAST等类型；又比如C语言中，表达式 (有值) 和语句 (没有值，但能描述一组操作) 也是两种AST。 “syntactic distinction between expressions and commands” 中的command是什么玩意？ 运算符除了作为AST内部节点以外，还能能将不同类型的AST组合起来。一个运算符能够操作的sort与数量由它的元数 (arity) 定义，e.g. 一个类型为 $s$ 的操作符，其元数为 $s_1, s_2, \\cdots, s_n$, 其中 $n \\geq 0$，将它们组合起来就能得到类型为 $s$ 的复合AST。这里 $s_i$ 没有将它们替换为具体的实例，因为我们现在讨论的内容就是抽象语法。 所谓函数原型就是脱胎于元数。 变量在抽象语法的视角看来几乎就是一个占位符，但是它有自己的作用域，即AST中的某棵子树。变量仅能被满足父节点 (一个运算符) 元数的定义的AST替换。 从程序的顶层AST开始，逐步替换变量为合法的AST，这个过程也就是程序解析中递归下降的过程。 考虑含有加法、乘法和整数构成的表达式，我们将描述它的抽象语法。这个抽象语法仅包括Exp类型的AST，而Exp包括两种运算符： $num[n]$：一元运算符，接收一个字符串形式的自然数 $n$，将其转换为抽象语法树中的数字类型 $plus$, $times$：二元运算符，接收两个Exp类型的AST 因此，表达式 $2+(3 \\times x)$ 在抽象语法中被可以写成 $plus(num[2], times(num[3], x))$，其中 $x$ 只能由上面两种运算符构造的AST进行替换。当所有的变量都被替换为AST，我们就称整个AST是闭合的 (closed)。 如果需要证明“对某类型 $s$ 的任意AST $a$，都有性质 $\\mathcal{P}(a)$”，那么使用的方法通常是结构归纳法 (structural induction)。以上述的Exp类型为例，有三种形式： 证明 $\\mathcal{P}(x)$，其中 $x$ 是变量 证明 $\\forall n \\in \\mathbb{N}, \\mathcal{P}(num[n])$ 证明 $\\mathcal{P}(a_1), \\mathcal{P}(a_2) \\Rightarrow \\mathcal{P}(times(a_1, a_2)), \\mathcal{P}(plus(a_1, a_2))$ AST的形式化定义令 $\\mathcal{S}$ 是sort的有限集合。给定 $\\mathcal{S}$，一个形式为 $(s_1, \\cdots, s_n)s$ 的arity表示一个sort为 $s\\in \\mathcal{S}$ 的运算符，每个参数都有类型 $s_i \\in \\mathcal{S}$。令 $\\mathcal{O} = {\\mathcal{O}_\\alpha }$，其中 $\\mathcal{O}_\\alpha$ 是具有arity $\\alpha$ 的集合，$\\forall \\alpha, \\beta, \\alpha \\neq \\beta, \\mathcal{O}_\\alpha \\cap \\mathcal{O}_\\beta = \\emptyset$。如果运算符 $o \\in \\mathcal{O}_\\alpha$，且 $\\alpha$ 具有形式 $(s_1, \\cdots, s_n) s$，那么 $o$ 类型为 $s$，$n$ 个参数的类型分别为 $s_1, \\cdots, s_n$。 给定 $\\mathcal{S}$ 和 $\\mathcal{O}$，令 $\\mathcal{X} = {\\mathcal{X}s}{s\\in \\mathcal{S}}$，其中 $\\mathcal{X}_s$ 是类型为 $s$ 的变量的集合，$\\forall s, t \\in S, s \\neq t, \\mathcal{X}_s \\cap \\mathcal{X}_t = \\emptyset$。特别地，给出上下文无关 (clear from context，不是上下文无关语法的context-free) 的 $\\mathcal{X}$，如果 $\\forall s \\in \\mathcal{S}, \\exists x \\in \\mathcal{X}, x \\notin \\mathcal{X}_s$，那么就称这个 $x$ 对 $\\mathcal{X}$ 是新的 (fresh)；或者说在理解 $\\mathcal{X}$ 时，$x$ 是新的。如果 $x$ 对 $\\mathcal{X}$ 是新的且类型是 $t$，那么 $\\mathcal{X}$ 是添加 $x$ 到 $\\mathcal{X}_t$ 得到的变量族集合。如果 $s$ 不是显式声明的而是上下文决定的，那么这个记法存在不确定性。 定义抽象语法树的族集合 $\\mathcal{A} = { \\mathcal{A}[\\mathcal{X}s] }{s \\in \\mathcal{S}}$ 为满足下列条件的最小族： 一个类别为 $s$ 的变量是一棵sort为 $s$ 的AST：$x \\in \\mathcal{X}_s \\Rightarrow x \\in \\mathcal{A}[\\mathcal{X}]_s$ 运算符能够将AST组合为新的AST：给定运算符 $o$，其arity形如 $(s_1, \\cdots, s_n)s$ 且 $a_1 \\in \\mathcal{A}{s_1}, \\cdots, a_n \\in \\mathcal{A}{s_n}$，则 $o(a_1, \\cdots, a_n) \\in \\mathcal{A}[\\mathcal{X}]_s$ 变量只有被代换后才有意义。如果 $a \\in \\mathcal{A}[\\mathcal{X}, x]_{s’}$ (类型为 $s’$ 的AST $a$ 中存在变量 $x$ 占位) 且 $b \\in \\mathcal{A}[\\mathcal{X}]s$，那么用 $b$ 替换 $a$ 中所有的 $x$ 得到的结果记为 $[b/x]a \\in \\mathcal{A}[\\mathcal{X}]{s’}$。此时我们称AST $a$ 为替换的目标 (target)，$x$ 为替换对象 (subject)。代换以下列等式定义： $[b/x]x = b$；当 $x \\neq y$ 时，$[b/x]y = y$ (代换不成立) $[b/x]o(a_1, \\cdots, a_n) = o([b/x]a_1, \\cdots, [b/x]a_n)$ Abstract Binding Tree在AST的基础上引入拥有作用域 (scope) 的变量/符号，它们被称为绑定 (binding)。Binding的作用域是一棵ABT，受其约束的变量只能在这个ABT中使用。比如表达式 $\\text{let} x \\text{be} a_1 \\text{in} a_2$，表示用变量 $x$ 表示 $a_2$ 中的 $a_1$，即变量 $x$ 与 $a_1$ 绑定。如 $\\text{let} x \\text{be} 7 \\text{in} x+x$，加式中的两个 $x$ 都是let引入的变量。$x$ 的作用域仅为 $a_2$，如果 $a_1$ 中如果还有变量 $x$，那么认为它们只是恰好重名的变量。 在ABT中，运算符的操作数被称为抽象子 (abstractor)，其形式为 $x_1, \\cdots, x_k.a$，可以简写为 $\\vec{x}.a$。变量序列 $x_1, \\cdots, x_k$ 在ABT $a$ 中是受作用域约束的。表达式 $\\text{let} x \\text{be} a_1 \\text{in} a_2$ 写成ABT形式有 $\\text{let}(a_1; x.a_2)$。 倒不如说那些泛型的参数 $\\vec{x}.a$ 才是抽象子，因为它们才反映了ABT中受约束的变量与AST中 (全局) 变量的差别。 Arity的概念在引入binding之后被扩展为泛化 (generalized) arity，形式为 $(v_1, \\cdots, v_n)s$，其中 $v_i$ 被称为抽象子的价 (valence)。一个价 $v$ 具有形式 $s_1, \\cdots, s_k.s$，即泛化类型 $s$ 与类型 $s_j$ 绑定。 大致可以理解为C++中模板为函数和类带来的泛型能力。 根据上述定义，例子中的let运算符的泛化arity为 $\\text{(Exp, Exp.Exp)Exp}$。这个运算符的类别是Exp，第一个参数Exp不与任何变量绑定，第二个参数Exp有一个约束变量Exp。$\\text{let} x \\text{be} 2+2 \\text{in} x\\times x$ 写作ABT有 $$\\text{let} ( \\text{plus}(\\text{num}[2]; \\text{num}[2]); x.\\text{times}(x; x))$$ ABT的形式化定义给定sort集合 $\\mathcal{S}$ 和按照泛化arity划分的操作符族集合 $\\mathcal{O}$。变量族集合 $\\mathcal{X}$","link":"/2023/11/15/PFPL/Chap1/"},{"title":"Monitor Tools","text":"top直接打开 top 其中几个和内存有关的数据项为： Mem Swap VIRT: Virtual memory RES: Resident memory vmstatvmstat 5 会每过5秒钟更新一次内存使用情况。 123456procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b 交换 空闲 缓冲 缓存 si so bi bo in cs us sy id wa st 0 0 8960 3609860 916364 20671172 0 0 1 5 0 1 1 0 99 0 0 0 0 8960 3567956 916376 20709652 0 0 0 80 2022 5622 2 1 97 0 0 0 0 8960 3598280 916400 20675932 0 0 0 88 1332 3941 1 0 98 0 0 0 0 8960 3589140 916400 20675884 0 0 0 42 1915 4444 2 1 98 0 0 当性能表现不佳时，需要关注 si 和 so 两项数据，它们表示交换空间的使用情况 (swap in/out)。","link":"/2024/03/20/PerformanceProf/Monitors/"},{"title":"ValgrindUsage","text":"ValgrindValgrind用于分析堆的使用情况。Valgrind相对Perf的好处在于，即使没有管理员权限 (sudo 密码) 的情况下，也能分析内存用量。Valgraind集成了多种测试工具，常见的有 memcheck, massif 等。 massif1valgrind --tool=massif &lt;prog&gt; [options] 生成的文件为 massif.out.&lt;pid&gt;，可以通过 ms_print 命令进行读取，或者使用 massif-visualizer 可视化。 1234# Install massif-visualizersudo add-apt-repository ppa:kubuntu-ppa/backportsapt-get updatesudo apt-get install massif-visualizer 调整横坐标massif 能够加上选项 --time-unit=&lt;opt&gt; 来调整横坐标： i：默认选项，横坐标为指令数 ms：横坐标为时间 (按毫秒计) B： 更细粒度的profile --detailed-freq=&lt;n&gt;：越小粒度越细，默认为10 --max-snapshots=&lt;n&gt;：快照的数量，默认值为100 --pages-as-heap=&lt;yes|no&gt;：能够统计页级别的操作，而不仅是malloc在块上的操作","link":"/2024/03/20/PerformanceProf/ValgrindUsage/"},{"title":"Polyhedral Optimizations Theory","text":"理论基础References More Iteration Space Tiling (M. Wolfe) 迭代空间一个嵌套深度为 $n$ 的嵌套循环，其迭代空间为 $\\mathcal{Z}^n$，每个迭代的实例被表示为一个向量。 123for I = 1 to 5 for J = 1 to 10 A(I, J) = B(i, j) + C(I)*D(J) 这样的一个迭代空间毫无疑问是矩阵的。 123for I = 1 to 5 for J = I to 5 A(I, J) = B(i, j) + C(I)*D(J) 像这样，内层循环的索引依赖于外层循环的索引时，迭代空间就变成了三角形。 数据依赖流依赖/真依赖/RAW流依赖 (flow dependence, RAW) 关系指的是，在一个迭代空间中，一个实例对某个地址 (地址、数组元素) 赋值，然后在后面执行的实例中，该地址中的值被使用，如下列代码所示。流依赖也被称为真依赖，记作 $S_1 \\delta S_1$。 12for I = 1 to N-1 A(I+1) = A(I) + B(I) (S1) 反依赖/假依赖/WAR反依赖 (anti dependence, WAR) 的定义是将流依赖定义中的写和读操作执行顺序反序得到的。如下列代码所示，其中的反依赖关系记作 $S_1 \\delta^a S_2$。 1234for I = 1 to N for J = 1 to M A(I, J) = B(I, J) + 1 (S1) B(I, J) = C(I, J) - 1 (S2) 写依赖/WAW写依赖 (output dependence, WAW) 指的是两个指令实例先后对同一块地址执行写操作。如下列代码所示，其中的写依赖关系记作 $S_2 \\delta^o S_1$。 123for I = 1 to N-1 if (A(I) &gt; 0) B(I) = C(I) / A(I) (S1) B(I+1) = C(I) / 2 (S2) 依赖向量考虑到存在依赖关系的两个实例在迭代空间内的距离大多都是常量，因此可以用距离向量来描述。如下列代码所示，语句间的依赖关系可以被表示为 $S_1 \\delta_{(0, 1)} S_1$。 123for I = 1 to N for J = 2 to M A(I, J) = A(I, J-1) + B(I, J) (S1) 当然，依赖向量也可以不是常量。下列代码中对 X 的读写操作的实例的距离是 $(1, J) &gt; (0, 0)$，所以永远写比读更早执行，保证依赖关系一直都是流依赖关系。 123for I = 1 to N for J = 1 to N X(I+1, 2*J) = X(I, J) + B(I) (S1) 方向向量 有时依赖向量只保留距离的符号 ${ +, 0, - }$，或者 ${ &lt;, =, &gt; }$，采用这种记法的向量被称为方向向量。 如果一个依赖关系是由第 $i$ 层循环携带的，那么方向向量 $d = (d_1, d_2, \\cdots, d_n)$ 有 $d_1, \\cdots, d_{i-1} = 0, d_i &gt; 0$。 并行循环执行我们用 par for 来表示并行循环，这意味着迭代之间会以任意顺序执行且不会进行同步。下列代码展示了一个并行循环和它的迭代空间。 123par for I = 1 to 5 for J = 1 to 10 A(I, J) = B(I, J) + C(I)*D(J) 123for I = 1 to 5 par for J = 1 to 10 A(I, J) = B(I, J) + C(I)*D(J) 一个串行循环能够被转换为并行循环的充分条件是该循环没有循环携带的依赖关系。 存在循环携带依赖也是可能被并行化的，但是需要插入同步指令，与 par for 的语义略有区别。 重构循环循环交换 (Loop interchange)循环交换会交换两个迭代的层次，如下所示。循环交换合法的充要条件是不存在 $(&lt;, &gt;)$ 类型的依赖向量。交换后的循环单看内层是没有循环携带的依赖关系的，因此内层的 I 循环能够被并行化。这在 M 的值较小的情况下非常有用。 123456789// beforefor I = 2 to N for J = 3 to M A(I, J) = A(I-1, J-2) + C(I)*D(j)// afterfor J = 3 to M for I = 2 to N A(I, J) = A(I-1, J-2) + C(I)*D(j) 循环倾斜 (Loop skewing)类似于下列模板计算的循环，每个迭代层次上都有循环携带的依赖关系。 1234for I = 2 to N-1 for J = 2 to M-1 A(I, J) = A(I-1, J) + A(I, J-1) + A(I+1, J) + A(I, J+1) 将它的迭代空间“倾斜”一下，能够消除一个维度的循环携带的依赖关系，从而进行并行化 1234for I = 2 to N-1 for J = I+2, I+M-1 A(I, J-I) = A(I-1, J-I) + A(I, J-I-1) + A(I+1, J-I) + A(I, J-I+1) 用矩阵表示，相当于对迭代空间进行了线性变换，依赖向量受到影响变为 $$\\left[\\begin{array}{l}1 &amp; 0 \\1 &amp; 1\\end{array}\\right] (d_1, d_2)^\\top= (d_1, d_1 + d_2)^\\top$$ 倾斜后的循环在交换时需要注意边界条件： 1234for K = 4 to N+M-2 for I = max(2, J-M+1) to min(N-1, J-2) A(I, J-I) = A(I-1, J-I) + A(I, J-I-1) + A(I+1, J-I) + A(I, J-I+1) 循环剥离 (Strip mining)循环剥离是以一维循环为操作对象的变换操作。通常以向量部件一次能够处理的数据量分离出一个内部循环来促进向量化： 123for IS = 1 to N by 64 for I = IS to min(IS+63, N) S1 外部的循环被称为跨步循环 (strip loop)。 尽管这个变换看起来是平凡的，但是从迭代空间的角度来看则是引入了额外的维度。不妨设原本的一维循环中依赖向量为 $(d)$，剥离出的步长为 $ss$，那么变换后会得到两个依赖向量：$$(\\lfloor \\frac{d}{ss} \\rfloor, d \\mod ss) \\(\\lceil \\frac{d}{ss} \\rceil, -d \\mod ss)$$ 循环分块 (Iteration space tiling)当一个嵌套循环在多维度上进行了循环剥离，再把跨步循环通过循环交换全部置于外层时，该循环变换被称为循环分块。 1234for I = 1 to N for J = 1 to N A(I, J) = A(I, J) + B(I, J) C(I, J) = A(I-1, J) * 2 123456for IT = 1 to N by SS for JT = 1 to N by SS for I = IT to min(N, N+SS-1) for J = JT to min(N, N+SS-1) A(I, J) = A(I, J) + B(I, J) C(I, J) = A(I-1, J) * 2 非规整 (非矩形) 的迭代空间在分块的思想如下图所示，这些迭代空间在进行倾斜后的循环和线性代数算法中比较常见。 访问足迹 (Footprint)于一个数组而言，在一个循环中，并非每一个元素都会被访问。为了做出区分，在循环内被访问到的数组的子集被称为足迹。如下列程序中，引用 $A(I, 1)$ 的足迹是 $A$ 的第一列，引用 $B(2, I)$ 的足迹是 $B$ 的第二行。 12for I = 1 to N A(I, 1) = B(2, I) * C(I) 因为不能确定 $N$ 是否达到了数组的边界，所以只能保守地假定整个行和列都被访问了。不过在下列循环剥离的情况下，我们能够准确地判定内存循环的访存足迹的大小为16。 123for IS = 1 to N by 16 for I = IS to min(IS+15, N) A(I, 1) = B(2, I) * C(I) “足迹”这个词语表达了“少量”的含义。我们希望在循环内存能够控制访存足迹，使其足够小来促进缓存使用。循环分块的一大作用就是让内部循环的界限明确，能够推断足迹大小来进行优化。 当某些数组的访存足迹大小小于对应循环空间的大小时，那么说明有数据重用的可能性。e.g. 矩阵乘法 $C = A \\times B$ 中 $A$ 的足迹大小是 $MK$，而整个迭代空间的大小为 $MNK$，显然能够设计数据重用策略来提高缓存利用率。 再给个更具体的例子。下列循环中，$C$ 在内存的访存足迹大小仅为1，然而 $B$ 的足迹大小为 $M$；循环交换后也只能大致上取得类似的足迹大小。 123for I = 1 to N for J = 1 to M A(I, J) = B(J) * C(I) 利用循环分块我们在内层循环限定两者的足迹大小均为32，内层循环的迭代空间大小为1024——这意味着每个数据都重用了32次。如果这32个元素能够放进寄存器文件/缓存中，能够极大地改善数据局部性。 12345for IT = 1 to N by 32 for JT = 1 to M by 32 for I = IT to min(N, IT+31) for j = JT to min(M, JT+31) A(I, J) = B(J) * C(I) 需要注意的是，缓存行只能加载连续的数据，所以即使我们在列上促进了数据重用，对于实际的体系结构而言效果可能微乎其微。","link":"/2023/12/26/Polyhedral/ClassicTheory/"},{"title":"Prequest knowledge","text":"预备知识CRTP (Curiously Recurring Template Pattern)CRTP也被叫做静态多态，它的写法看起来是这样的： 123struct Foo : Base&lt;Foo&gt; { /*...*/}; 这样写的好处有： 获得有类型信息的 this 指针 可以避免动态多态中因为虚函数表带来的开销 123456789101112template &lt;class Derived&gt;struct Base { void func() { for (auto &amp;it: *static_cast&lt;Derived *&gt;(this)) {...} }};struct Foo : Base&lt;Foo&gt; { class iterator {...}; iterator begin() const {...} iterator end() const {...}}; 一个例子假设我们正在开发一个消息管理器，能够向所有的网上博客推送消息。使用CRTP可能写出来的系统是这样的： 123456789101112131415161718192021template &lt;typename Impl&gt;class Notifier {public: void alertSMS(string_view msg) { impl().sendAlertSMS(msg); } void alertEmail(string_view msg) { impl().sendAlertEmail(msg); }private: Impl &amp;impl() { return static_cast&lt;TImpl &amp;&gt;(*this); } friend Impl;}；template &lt;typename Impl&gt;void alertAllChannels(Notifier&lt;Impl&gt; &amp;notifier, string_view msg) { notifier.alertSMS(msg); notifier.alertEmail(msg);}struct TestNotifier : public Notifier&lt;TestNotifier&gt; { void sendAlertSMS(string_view msg) {} void sendAleryEmail(string_view msg) {}}; 现在的写法存在的问题是：我们并没有检查 Impl 是否继承自 Notifier，只能等到编译器报错了之后才能发现 Impl 是否真的有 sendAltertSMS 方法！ 使用 concept 进行检查1234567891011template &lt;typename Impl&gt;concept IsANotifier = requires(Impl impl) { impl.alertSMS(string_view {}); impl.alertEmail(string_view {});};template &lt;IsANotifer Impl&gt;void alertAllChannels(Impl &amp;impl, string_view msg) { impl.alertSMS(msg); impl.alertEmail(msg);} requires 允许我们直接对类的接口进行检查，而不再需要构造一个奇怪的基类！ Mixin继承12template &lt;typename... T&gt;struct Mixin: T... {}; 这种写法能够将一组功能相互正交的类组合在一起使用。在C++20引入 concept 之后，能够提前对mixin的类型进行约束，而不需要等到编译器报错才知道有地方写错了。 属性属性指的是一个类的私有数据成员，以及为了读写它的相关方法： 123456class Person { int age;public: int getAge() const { return age; } void setAge(int value) { age = value; }}; 在C#和Kotlin这样的语言中，对属性的写法提供了语法上的支持，但是C++标准没有。但是MSVC和clang都提够了自己的编译器扩展： 1234567class Person { int _age;public: int getAge() const { return _age; } void setAge(int value) { _age = value; } __declspec(property(get=getAge, put=setAge)) int age; }; age 并不会占用额外的内存，在使用时会被编译器替换为原始的形式： 12Paerson p;p.age = 20; // invoke setAge(20) SOLID设计原则 Single Responsibility Principle (SRP) Open-Closed Principle (OCP) Liskov Substitution Principle (LSP) Interface Segregation Principle (ISP) Dependency Inversion Principle (DIP) SRP每个类都应该只有一项职责。SRP的反例是上帝对象 (God Object)，看起来包罗万象其实非常难用。 OCP实体对扩展是开放的，对修改是封闭的，即统一用户的实现接口。典型的例子是使用迭代器的算法库，用户不能直接修改其实现，但是通过在自己实现的对象中添加对迭代器的实现就能够让算法库扩展到自定义对象上。 LSP任何对象被它们的子类替换后，不应该发生错误。 ISP客户不应该被迫实现一个他们不需要的接口，因此应该把接口分解为多个接口，每个接口服务于一个模块。 DIP高层模块不应该依赖于底层模块，两者都应该依赖于抽象；抽象不依赖于细节，反而细节应该依赖于抽象。","link":"/2024/04/05/DesingnPatterns/0-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"},{"title":"1-CreationalPattern","text":"Creational Patterns创建一个对象是一件很常见的事情，但是在一个复杂的系统里却需要考虑很多事情：它应该分配在堆上还是栈上？它应该是裸指针、独有指针还是共享指针？这些问题的来源是C++提供的丰富的创建方式： 栈上分配 堆上分配 unique_ptr shared_ptr weak_ptr weak_ptr 是 shared_ptr 的辅助类，用于解决 shared_ptr 中循环引用的问题。 当我们创建了对象后如何返回也是一个令人操心的问题： 123456789struct Foo { /* a large object*/ Foo(int ) { cout &lt;&lt; &quot;Create Foo\\n&quot;; } Foo(Foo &amp;) { cout &lt;&lt; &quot;Copy Foo\\n&quot;; }};Foo make_foo(int n) { return Foo { n };} 我们当然不希望我们创建了一个 Foo 对象后，返回的时候又调用了复制构造函数产生额外的开销。不过好在大多数C++编译都实现了RVO (Return Value Optimization) 来减少复制构造函数的产生。但是，如果应用情景足够复杂，那么RVO可能不再靠谱。 BuilderBuilder模式用于创建复杂的对象。它将创建对象的过程封装在一个类中。 假如我们希望创建如下的HTML样式： 1234&lt;ul&gt; &lt;li&gt; Hello &lt;/li&gt;] &lt;li&gt; World &lt;/li&gt;&lt;/ul&gt; 显然，HTML标签的生成能够被独立出来，于是我们将HTML元素抽象出来，并为其创建了一个builder： 123456789101112131415161718192021222324struct HtmlElement { string name, text; vector&lt;HtmlElement&gt; elements; HtmlElements() {} HtmlElements(const string &amp;name, const string &amp;text) : name(name), text(text) {} string str(int indent = 0) const { // ... }};struct HtmlBuilder { HtmlElement root; HtmlBuilder(string root_name) { root.name = root_name; } void addChild(string child_name, string child_text) { root.elements.emplace_back(child_name, child_text); } string str() { return root.str(); }};HtmlBuilder builder { &quot;ul&quot; };builder.addChild(&quot;li&quot;, &quot;Hello&quot;);builder.addChild(&quot;li&quot;, &quot;World&quot;); 如果没有builder，那么创建一个 HtmlElement 对象会是这样的： 123456string words[] = { &quot;Hello&quot;, &quot;World&quot; };HtmlElement list {&quot;ul&quot;, &quot;&quot;};for (auto w: words) { root.elements.emplace_back(&quot;li&quot;, w);} 在使用上远不及前者。 链式调用将 addChild 的返回类型变为类本身 12345678struct HtmlBuilder { ... HtmlBuilder &amp;addChild(string child_name, string child_text) { root.elements.emplace_back(child_name, child_text); return *this; } ...} 这样修改后 HtmlBuilder 的调用就可以链式调用： 12builder.addChild(&quot;li&quot;, &quot;Hello&quot;) .addChild(&quot;li&quot;, &quot;World&quot;); 让用户知道如何使用强迫用户使用工厂函数第一种方法是强迫用户只能使用builder来创建对象： 123456789101112131415161718192021struct HtmlElement { friend HtmlBuilder; string name; string text; vector&lt;HtmlElement&gt; elements; const size_t indent_size = 2; static unique_ptr&lt;HtmlBuilder&gt; create(const string &amp;root_name) { return make_unique&lt;HtmlBuilder&gt;(root_name) }protected: HtmlElement() {} HtmlElement(const string &amp;name, const string &amp;text) : name(name), text(text) {}};struct HtmlBuilder { ... operator HtmlElement() const { return root; }}; 所有的构造函数被放在 protected 中，不再可以被用户调用，但是留下了一个工厂函数 create 但是这么做的后果是 HtmlBuilder 中无法使用构造函数了，需要添加为友元 通过 operator HtmlElement() 实现由builder向类对象的转换 Groovy-style builderGroovy，Kotlin等编程语言宣称自己的语言特性很适合于构建DSL语法结构。但是大家都是通用编程语言，谁又比谁差呢？ 12345678910111213141516171819202122232425262728struct Tag { string name; string text; vector&lt;Tag&gt; children; vector&lt;pair&lt;string, string&gt;&gt; attributes; friend ostream &amp;operator&lt;&lt;(ostream &amp;os, const Tag &amp;tag) {/*...*/}protected: Tag(const string &amp;name, const string &amp;text) : name(name), text(text) {} Tag(const string &amp;name, const vector&lt;Tag&gt; &amp;children) : name(name), children(children) {}};struct P : Tag { explicit P(const string &amp;text) : Tag(&quot;p&quot;, text) {} P(initilizer_list&lt;Tag&gt; children) : Tag(&quot;p&quot;, children) {} };struct IMG : Tag { explicit IMG(const string &amp;text) : Tag(&quot;p&quot;, text) { attributes.emplace_back({&quot;src&quot;, url}); }}; 这种方式要从基类派生合法的标签类型，这样就构建了一套类似于DSL的系统，使用起来是这样的： 1P { {IMG { &quot;http://urltoanimage.com/img.png&quot; }} }; 复合builder现在我们打算创建类来保存一些个人信息： 12345678class Person { string street_address, post_code, city; string company_name, position; int annual_income = 0; Person() {}}; 其中的数据成员可以分为两类，一类是住址信息，另一类是工作单位信息。现在我们希望由两个builder分别完成这两类信息的创建。这项工作并不容易，它需要四个类，其UML如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344class PersonBuilderBase {protected: Person &amp;person; explicit PersonBuilderBase(Person &amp;person) : person(person) {}public: operator Person() { return move(person); } PersonAddressBuilder lives() const; PersonJobBuilder works() const;};class PersonBuilder : public PersonBuilderBase { Person p; // object being builtpublic: PersonBuilder() : PersonBuilderBase(p) {}};class PersonAddressBuilder : public PersonBuilderBase { typedef PersonAddressBuilder self;public: explicit PersonAddressBuilder(Person &amp;person) : PersonBuilderBase { person } {} self &amp;at(string street_address) { person.street_address = street_address; return *this; } self &amp;withPostcode(string post_code) {/*...*/} self &amp;in(string city) {/*...*/} };class PersonJobBuilder: public PersonBuilderBase { /* identical fasion to PersonAddressBuilder */};Person p = Person::create() .lives.at(&quot;&quot;) .withPostcode(&quot;&quot;) .in(&quot;&quot;) .works.at(&quot;&quot;); 要创建的对象 Person 在基类里只是个引用，在 PersonBuilder 中才真的拥有存储空间 另外两个builder没有从 PersonBuilder 继承，这样就避免了多次创建 Person 对象 转换到 Person 对象时，直接将 person 成员的所有权转移走 内部类的builder假设现在有一个邮件系统，在作为底层实现的类中，一个邮件对象按如下方式描述： 12345class EmailImpl {public: string from, to, subject, body; // ...}; 既然是内部的底层实现，我们显然不希望用户直接和这些类进行交互","link":"/2024/04/06/DesingnPatterns/1-CreationalPattern/"},{"title":"01-Measuring CPU Time","text":"现代处理器的执行流程 超线程指的是一个CPU核上有两个PC和相关寄存器，但是ALU和cache资源量不变。当一个PC在等待数据时，另一个PC能够进行执行，在逻辑上有两个核。 测量一条 add 指令的时延这里的时延指的是从 add 指令被取指，到其结果对于依赖这条指令的指令可用时经过的时钟周期数。 朴素方法1234start = timer();add(a, b);end = timer();end - start; 在Intel处理器上，这个获取时钟的timer是位于 x86intrin.h 的 __rdtsc 函数。在ARMv8上，并没有和 rdtsc 直接等价的指令，但是有类似的寄存器，PMCCNTR_EL0。但是X86能够在用户态随便读取周期数，而ARM不行。 但是在现代处理器上，这种方法并不能准确测量按周期数计的时延，这是因为处理器有主频和外频之分，并且还能动态调频。对于标定频率为2.4GHz的处理器而言，其时间戳可能每10ns (100MHz) 增加24；当其降频或者超频，这个时间戳的递增速率不变，仍然每秒递增24亿次。这种测量方式给出了一致的测量值但是精度下降了一个数量级。 因此，为了减少每次获取时钟时那10ns的模糊性产生的失真，我们需要确保两次读取经过了1000ns (低于1%)，所以测量方式如下： 1234start = timer();for (i=0; i &lt; N; ++i) add(a, b);end = timer();end - start; 编译器优化123456uint64_t startcy, stopcy;uint64_t sum = 0;startcy = __rdtsc();for (i=0; i&lt;N; ++i) sum += 1;stopcy = __rdtsc(); 在编译器上，这个循环能够被常量折叠或者死代码删除优化掉。为了迷惑编译器，我们需要将 sum 声明为 volatile 来阻止编译器进行常量分析。 循环开销另一方面，循环开销确实也会对我们的测量产生影响，因此适度地循环展开是可行的。 另一个更有效的方法是写两个循环，一个循环体执行N1次add，另一个循环体执行N2次add，两者相减即可消除循环开销。但是N1和N2需要稍大一些，如4和8、10和20来减少编译器优化带来的影响；但也要避免循环体过大以致于不能放入循环缓冲区中，导致取指之间增加。 确保指令间数据依赖超标量 (多发射)123456for (i=0; i&lt;N; ++i) { sum += 1; sum2 += 1; sum += 1; sum2 += 1;} 这里 sum 和 sum2 相互独立，那么处理器能够使用超标量技术同时发射两条指令，导致最终测试的时延仅有一半，测出来的是发射率。 编译器指令重排在下面这个循环中： 1234for (i=0; i&lt;N; ++i) { prod *= incr0; prod *= incr1; prod *= incr2; prod *= incr3;} 明面上的计算顺序是 1pord = (((prod*incr0)*incr1)*incr2)*incr3 但是编译器重排之后可能把循环常量单独计算，并使用超标量发射多条指令： 12temp = incr0*incr1*incr2*incr3;pord = prod * temp; 为了避免这样的重写，应该加上 -fno-tree-reassoc 选项。","link":"/2024/04/16/PerformanceMeasuring/01-CPU/"},{"title":"02-Measuring Memory Hierarchy","text":"缓存的结构 在一个cache line中，需要至少有两个字的大小才实用，不然有大量硬件会浪费在标签上；最大也不能大过一个内存页的大小。一个字通常是一个指针的大小，即一个64位处理器中，一个cache line至少能容纳2个8字节指针，最大4KB。 在N路组相连的cache中，匹配时先选组，然后在选组内的行；连续但不在一组的数据分布于不同的组中。 数据对齐4字节对齐指的是字节地址是4的倍数。实际的缓存和内存引用都是用对齐量寻址的。未对齐引用会产生两次对齐的访问，然后进行一些字节的移位和合并，并选择被引用的字节来实现。 TLBTLB包含两级：每个物理核都包含的L1 TLB和由多个核心共享L2 TLB。TLB采用物理地址寻址。 页表和cache的设计彼此交互。在64位操作系统中，通常虚拟地址长度48位，物理地址40位。因为页表的大小是4KB，所以虚拟地址的低12位没有用来映射，转而用在选择合适的缓存组。如果一个cache line大小为64Byte，那么低6位用来在cache line内寻找特定的一个字节，所以最多只能有64组。如果每个组里只有1路组相连 (直接映射)，那么L1 cache总共只有4KB；如果是4路组相连，L1 cache大小为16KB。这种耦合性反映了意味着较小的内存页限制了L1 cache的大小。 测量内存缓存行的大小方案一让缓存一开始不包含我们需要的数据，然后从位置 $X$ 加载一个对齐的字，然后再从 $X+c$ 加载一个字，多次访问。当 $c$ 为 $1/4$, $1/2$, $1$ 和 $2$ cache line大小时访存状况不同，如下所示： 通过慢慢增加 $c$ 的到这个循环慢到一个临界点，那么 $c$ 就是cache line的大小。 缺陷现代cache在访问第N行时，也会顺路把第N+1行也预取了；同时乱序执行在一个周期内会启动多条指令，并且同时会有几十条等待内存响应的加载指令。这让多条指令的未命中的延迟合并在一起。 方案二设计一个链表，每项的大小为可能得cache line大小，且是对齐的。这种链表的设计让每一项的加载都依赖于前一项，即 ptr = ptr-&gt;next。这样就避免了因为乱序执行产生的并行加载，但是无法屏蔽数据预取。 为了屏蔽数据预取，一个合乎直觉的做法是把连续的项在地址空间中打乱。但是这样并不够，第N+1项的数据仍然在未来会被访问，产生一次命中。 来自DRAM的影响DRAM的访问包括以下几个步骤：预充电-&gt;行访问-&gt;列访问。 预充电是DRAM物理实现上的机制，行访问是DRAM的访存是每次读取一大块数据，然后再列访问取出所需的数据。这三个步骤所需的周期大致相同，都是大致15ns。一个行通常是1024Byte，一根DIMM (内存条) 上有多个DRAM芯片，通常是8个，有效的行大小为8KB；CPU会和每个DRAM芯片以8Byte宽的数据总线相连。如果主板上有多根DIMM，那么会相应变为多倍。以两个DIMM为例，CPU访问连续的行的时候会在两根DIMM上交替进行，以实现两倍的带宽。 由于DRAM提供了一种缓存机制，让CPU访问同一行的数据时只进行一次列访问，延迟降低为第一次访问的 $1/3$。因此，来自DRAM的影响也不容小觑。 避免DRAM的影响考虑系统为一个双通道的内存布局，我们需要将连续的项放入不同的DRAM行中，且以16KB为一组翻转它们的顺序，使访问顺序与地址递增顺序相反。 或许把这些项的地址放进一个数组里再shuffle能起到一样的效果？ 这些访存的延迟统计从完全命中到cache失效再到TLB失效一路递增。 一级缓存的总大小将N个Byte读入cache中，然后重新读取。如果能够全部放在cache中，那么重新读取就会很快，每次取数据只要几个周期。 不过在真实的测试中，我们不能得到完美的阶梯型的访存周期数。假设中的完美阶梯型需要：(1) L1 cache中没有其它任何数据；(2) cache替换策略为完美的LRU策略。然而这些条件在真实的系统中都是无法实现的。 组相连数在组相联的cache中，一个cache line可以处于组内的N个位置中的一个。如果cache line只能位于唯一确定的位置，那么N为1，以此类推。 测量组相连度需要读取一个列表，包含 $A$ 个不同行的地址，并且不断重复：0，4K，8K，12K，0，… (A=4)。然后重新读取这个列表，如果很快就说明它们都放在组中，直到开始变慢——这个 $A$ 就是组相连数。 对于L2和L3 cache而言，如果它们的组相联度高于L1，那么测量过程不变；反之，L1 cache会干扰计时结果。 页表的开销当我们访问的元素间隔大于4KB时，每次读取数据都会发生一次TLB的失效，但是相对于前面的几种情况，有页表引发的数据失真时可预测的。 缓存利用不足缓存通常由地址的低位确定。不妨设cache line大小为64Byte，一组内4路组相联，一共8组，那么需要用到 $[0,6)$ 位寻找特定一个Byte，$[6, 9)$ 位去匹配组，$[9, 12)$ 位和标签匹配判断命中。 如果我们只加载128Byte对齐的数据，那么它只会位于偶数的组，相当于有效cache大小减半。","link":"/2024/04/16/PerformanceMeasuring/02-MemoryHierarchical/"},{"title":"2 Frontend","text":"处理输入用户信息在大型软件中，输出的信息最好能够保存在一个地方集中管理，令整个项目看起来清爽，且在需要翻译的时候能够集中处理。 一条诊断包括下列信息：诊断ID、严重程度和信息字符串。 1DIAG(err_sym_declared, Error, &quot;symbol {0} already declared&quot;) 这些诊断信息最后回被保存到一个表中，用诊断ID索引。 这些信息条目通常由tablegen生成，保存在 .def 文件中。 诊断引擎在编译器中，这些信息统一由诊断引擎 DiagnosticsEngine 处理。在实现上可以借助 llvm::formatv 对诊断信息的字符串进行格式化。 Lexer 和 Token程序=数据结构+算法。那么这这一对类中，Token 就是那个数据结构，而 Lexer 就是那个算法。 Token 大致可以分为三类：关键字 (keyword)、符号 (punctuator) 和以标识符与数字为代表的词法单元 (token)。同时，在真实的编程语言中，关键字的数目非常多，所以还有 KeywordFilter 这样的辅助类帮助解析。 编程语言的文法总是与时俱进的，因此常常面临扩展的需求，所以也会由 .td/.def 文件统一保存。 递归下降的语法解析在语法解析的这个层次，Lexer 变成了数据结构，而 Parser 作为算法将 Lexer 中原本作为算法的部分封装起来。 对于每个非终结符，都应该有一个对应的解析方法 每个token用 consume 方法处理 对于可能存在多种解析方法的token，通过向前看 (look ahead) 决定其作为哪种语法结构被解析 比如对于下列if语句： 12ifStatement ::= &quot;IF&quot; expression &quot;THEN&quot; statementSequence ( &quot;ELSE&quot; statementSequence )? &quot;END&quot; ; 其对应的不考虑报错的解析方法为： 1234567891011void Parser::parseIfStatement() { // parseing if statement cosume(tok::kw_IF); // cosume keyword parseExpression(); cosume(tok::kw_THEN); parseStatementSequence(); if (tok.is(tok::kw_ELSE)) { // look ahead,aka. resolver advance(); parseEtatementSequence(); } cosume(tok::kw_END);} Follow集合和语法错误为了简化resolver和错误处理的复杂度，我们通常需要计算Follow集合。Follow集合是每个非终结符后可以跟上的token。在这个if语句解析的过程中，THEN、ELSE、END 都可能出现在非终结符的后方。 不妨假设现在有一个调用栈：parseStatement() -&gt; parseStatementSequence() -&gt; parseBlock() -&gt; parseModule()。现在 parseStatement() 解析出了一个语法错误。那么这个这个token就会被跳过，直到某个在Follow集合中出现它的非终结符为止。此时这个错误可以被修正，并向 parseStatementSequence() (caller) 返回 false。 Follow集合通常被实现为 std::bitset 或者 std::tuple。 在玩具级的编译器中，通常会使用 goto 语句跳转到错误恢复的代码块，但是在实际的编译器中这么多太复杂。在LLVM Clang中，通常使用 skipUntil 方法到达可以进行错误恢复的非终结符。 123456789101112131415161718192021222324bool Parser::parseifStatement() { auto _errorhandler = [this] { return skipUntil(tok::semi, tok::kw_ELSE, tok::kw_END); }; if (consume(tok::kw_IF)) return _errorhandler(); if (parseExpression(E)) return _errorhandler(); if (consume(tok::kw_THEN)); return _errorhandler(); if (parseStatementSequence(IfStmts)) return _errorhandler(); if (Tok.is(tok::kw_ELSE)) { advance(); if (parseStatementSequence(ElseStmts)) return _errorhandler(); } if (expect(tok::kw_END)) return _errorhandler(); return false} 这里的布尔值全是表示是否需要进行错误处理/能够进行错误恢复。 语义分析 一个新的声明语句中出现的符号不能在其它位置定义 被使用的变量名是否已经声明了 确定表达式返回值的类型 检查赋值表达式的类型匹配 … 变量名的域真实的编译器中，域会被实现为一个 Scope 类，使用 StringMap 作为基本的数据结构。在tinylang中，只有声明语句需要和一个域关联。 12345678910111213141516171819202122232425262728// Scope.hclass Decl;class Scope { Scope *Parent; StringMap&lt;Decl *&gt; Symbols;public: bool insert(Decl *Declaration); Decl *lookup(StringRef Name); ...};// Scope.cppbool Scope::insert(Decl *Declaration) { return Symbols.insert(std::pair&lt;StringRef, Decl *&gt;(Declaration-&gt;getName(), Declaration)).second;}Decl *Scope::loopup(StringRef Name) { Scope *S = this; while (S) { StringMap&lt;Decl *&gt;::const_iterator I = S-&gt;Symbols.find(Name); if (I != S-&gt;Symbol.end()) return I-&gt;second; S = S-&gt;getParent(); } return nullptr;} llvm::StringMap 的 insert 方法不会覆盖已有的key，其返回值的类型是 pair&lt;iterator, bool&gt;，第二个参数表示该字典是否被更新 (原本是否有这个key)。 LLVM RTTI (runtime type info)RTTI特性在运行时能够获得对象的声明信息，如 dynamic_cast。RTTI特性仅在C++类中有虚函数表时才可用；另一方面，C++ RTTI也是一个臃肿的特性。为了避免这样那样的缺点，LLVM有一套自己的RTTI风格，贯穿了整个LLVM库的实现。 12345678910111213class Decl {public: enum DeclKind { DK_Module, DK_Const, DK_Type, DK_Var, DK_Param, DK_Proc };private: const DeclKind Kind;};class VariableDecl : public Decl { static bool classof(const Decl *D) { return D-&gt;getKind() == DK_Value; }} 声明表达式的抽象基类 Decl 中增加了枚举 在每个 Decl 派生的具体声明表达式类型中实现 classof 方法，此时就能够使用 llvm::isa&lt;&gt; 进行调用 AST节点和语义分析器在完整的实现中，语法节点需要记录自己的源代码位置信息，通常记录为 SMLoc 类型。 1234567891011121314151617181920212223242526272829303132333435class Decl {public: enum DeclKind { DK_Module, DK_Const, DK_Type, DK_Var, DK_Param, DK_Proc };private: const DeclKind Kind;protected: Decl *EnclosingDecL; SMLoc Loc; StringRef Name;public: Decl(DeclKind Kind, Decl *EnclosingDecL, SMLoc Loc, StringRef Name) : Kind(Kind), EnclosingDecL(EnclosingDecL), Loc(Loc), Name(Name) {} DeclKind getKind() const { return Kind; } SMLoc getLocation() { return Loc; } StringRef getName() { return Name; } Decl *getEnclosingDecl() { return EnclosingDecL; }};class TypeDeclaration;class VariableDeclaration : public Decl { TypeDeclaration *Ty;public: VariableDeclaration(Decl *EnclosingDecL, SMLoc Loc, StringRef Name, TypeDeclaration *Ty) : Decl(DK_Var, EnclosingDecL, Loc, Name), Ty(Ty) {} TypeDeclaration *getType() { return Ty; } static bool classof(const Decl *D) { return D-&gt;getKind() == DK_Var; }}; 语义分析在语法解析器中收集信息；也可以理解为，纯粹的语法解析器并不需要创建节点，只需要按照解析规则将源代码遍历完即可，而创建节点是为了后续的分析。 1234567891011121314151617bool Parser::parseVariableDeclaration(DeclList &amp;Decls) { auto _errorhandler = [this] { while (!Tok.is(tok::semi)) { advance(); if (Tok.is(tok::eof)) return true; } return false; }; Decl *D = nullptr; IdentList Ids; if (parseIdentList(Ids)) return _errorhandler(); if (consume(tok::colon)) return _errorhandler(); if (parseQualident(D)) return _errorhandler(); Actions.actOnVariableDeclaration(Decls, Ids, D); return false;} Action 属于 Sema 类，用于进行语法检查。 1234567891011121314151617void Sema::actOnVariableDeclaration(DeclList &amp;Decls, IdentList &amp;Ids, Decl *D) { if (TypeDeclaration *Ty = dyn_cast&lt;TypeDeclaration&gt;(D)) { for (auto &amp;[Loc, Name] : Ids) { auto *Decl = new VariableDeclaration(CurrentDecl, Loc, Name, Ty); if (CurrentScope-&gt;insert(Decl)) Decls.push_back(Decl); else Diags.report(Loc, diag::err_symbold_declared, Name); } } else if (!Ids.empty()) { SMLoc Loc = Ids.front().first; Diags.report(Loc, diag::err_vardecl_requires_type); }}","link":"/2024/02/29/LLVM/2-Frontend/"},{"title":"CommonDialects","text":"scf dialectscf方言中的Op能够用来表征任意的代码块结构。 ConditionOpIfOpExample: 123456789%x, %y = scf.if %b -&gt; (f32, f32) { %x_true = ... %y_true = ... scf.yield %x_true, %y_true : f32, f32} else { %x_false = ... %y_false = ... scf.yield %x_false, %y_false : f32, f32} 相比于传统的数据流分析，scf.if 能够指定哪些变量在出口处活跃。 scf.yeild 表示一个控制块的结束，如果 scf.if 没有返回值，那么它能够被省略，被隐式地插入在代码中。 如果 if 语句中存在逻辑表达式的计算，那么会额外引入一个 scf.if 结构计算这个逻辑表达式的值，如： 123if(isCoordChanged || iter == 0) { ...} 对应于 12345678910%75 = scf.if %42 -&gt; (i1) { scf.yield %true : i1} else { %209 = memref.load %37[%c0] : memref&lt;1xi32&gt; %210 = arith.cmpi eq, %209, %c0_i32 : i32 scf.yield %210 : i1}scf.if %75 { ...} memref dialectGetGlobalOp获得一个全局变量的指针。 llvm dialectGEPOp (getelementptr)相当于从LLVM IR中的 getelementptr 指令，根据偏移量从计算结构体中元素的地址。 123struct { long num; int dim; Point *p; } Point *points;int num = points-&gt;num; // number of pointsint dim = points-&gt;dim; // number of dimension 12345%24 = llvm.getelementptr %arg1[%c0_i32, 0] : (!llvm.ptr&lt;!llvm.struct&lt;(i64, i32, !llvm.ptr&lt;!llvm.struct&lt;(f32, memref&lt;?xf32&gt;, i64, f32)&gt;&gt;)&gt;&gt;, i32) -&gt; !llvm.ptr&lt;i64&gt;%25 = llvm.load %24 : !llvm.ptr&lt;i64&gt;%26 = arith.trunci %25 : i64 to i32%27 = llvm.getelementptr %arg1[%c0_i32, 1] : (!llvm.ptr&lt;!llvm.struct&lt;(i64, i32, !llvm.ptr&lt;!llvm.struct&lt;(f32, memref&lt;?xf32&gt;, i64, f32)&gt;&gt;)&gt;&gt;, i32) -&gt; !llvm.ptr&lt;i32&gt;%28 = llvm.load %27 : !llvm.ptr&lt;i32&gt; arg1 是一个结构体 %c0_i32 是一个32位类型的常量0，表示以结构体大小为基准的偏移量 0 是结构体内的偏移量，表示结构体内的第一个元素 GEPOp只计算地址，所以要 load 以下","link":"/2024/03/25/MLIR/APP-A%20CommonDialects/"},{"title":"Rodinia","text":"安装与使用streamcluster","link":"/2024/03/25/PerformanceProf/Rodinia/"},{"title":"ARMv8 Architecture","text":"AArch64标量数据类型 Type Size(bits) C++ Type &lt;cstdint&gt; Singned 8 char int8_t 16 short int16_t 32 int, long int32_t 64 long, long long int64_t Unsigned 8 unsigned char uint8_t 16 unsigned short uint16_t 32 unsigned int, unsigned long uint32_t 64 unsigned long, unsigned long long uint64_t Float 32 float n/a 64 double n/a 标量指令12345678910111213; Immediatemov w0, 42 ; w0 = 42add x1, x0, 8 ; x1 = x0 + 8lsl w2, w1, 2 ; w2 = w1 &lt;&lt; 2; Registermov x1, x0 ; x1 = x0mul x2, x1, x0 ; x2 = x1 * x0smull x2, w0, w1 ; x2 = w0 * w1; Load/Storeldr x0, [sp] ; x0 = *spstr w0, [x4] ; *x4 = w0 寄存器标量/整型ARMv8的体系结构中有31个通用寄存器，64位的名称为 X0-X30，32位的名称为 W0-W30。X/W0-X/W28 可以随意用于加载数据、保存临时变量，X/W29 用于保存栈帧指针，X/W30 用于保存函数的返回地址。在硬件结构上并没有 X/W31 寄存器，但是这个寄存器的编码用于表示0寄存器。 除了通用寄存器之外，ARMv8还有一个 SP 寄存器保存栈指针，一个 PC 作为程序计数器，一个 NZCV (Negative, Zero, Carry, oVerflow) 寄存器用于保存状态。 向量/浮点ARMv8的体系结构中有32个SIMD/向量寄存器，每个寄存器长度为128 bits，命名为 V0-V31。整型只能被打包为向量才能保存在这些寄存器中，而浮点数无论标量还是向量都要保存在这些寄存器中。 完整的128位寄存器根据保存的数据类型在程序中有不同的写法，都以寄存器 V2 为例：保存一个128位类型时写作 v2.1q；保存2个64位类型时写作 v2.2d；保存4个32位类型时写作 v2.4s；保存8个16为类型时写作 v2.8h；保存16个8位类型时写作 v2.16b。另一方面，这些寄存器也可以只用低64位保存数据，一次写作 v2.1d, v2.2s, v2.4h, v2.8b。 ARMv7中的向量寄存器被称为 Q。 寻址模式寄存器寻址12ldr w1,[x0] ; w1 = *x0ldr x1,[x0] ; x1 = *x0 寄存器+偏移量寻址1234ldr w1, [x0,20] ; w1 = *(x0 + 20)ldr x2, [x1,x0] ; x2 = *(x1 + x0)ldr w2, [x1,x0,lsl 2] ; w2 = *(x1 + (x0&lt;&lt;2))ldr w2, [x1,w0,uxtw 2] ; w2 = *(x1 + (w0&lt;&lt;2)) 索引寻址取递增后地址的数据： 123ldr w1, [x0,4]! ; w1 = *(x0 + 4); x0 += 4ldr x2, [x1,x0]! ; x2 = *(x1 + x0); x1 += x0ldr x2, [x1,x0,lsl 2]! ; x2 = *(x1 + (x0&lt;&lt;2)); x1 += (x0&lt;&lt;2) 取数后递增索引： 123ldr x2, [x1], 8 ; x2 += *x1; x1 += 8ldr x2, [x1], x0 ; x2 = *x1; x1 += x0ldr x2, [x1], x0, lsl 2 ; x2 = *x1; x1 += (x0&lt;&lt;2) 相对PC偏移量寻址1ldr x2, label ; x2 = *(pc + label_offset)","link":"/2024/04/23/ARMAsm/01-Architecture/"},{"title":"Dpcpp on ARM CPU with PoCL","text":"说明本安装过程使用DPCPP 20230413，LLVM 16，PoCL4。经验证对于较新版本的DPCPP和PoCL5也依然有效。 安装DPCPP1234python3 buildbot/configure.py -t Debug \\ --cmake-opt=-DLLVM_USE_LINKER=gold \\ --cmake-opt=-DLLVM_TARGETS_TO_BUILD=&quot;ARM;AArch64&quot; \\ --cmake-opt=-DLLVM_ENABLE_RUNTIMES=openmp 在较高版本中可以加上 --native_cpu 安装LLVM根据PoCL的要求下载对应版本的LLVM即可： 123456789cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -DLLVM_ENABLE_ASSERTIONS=OFF -DLLVM_OPTIMIZED_TABLEGEN=ON \\-DLLVM_TARGETS_TO_BUILD=&quot;ARM;AArch64&quot; -DLLVM_ENABLE_PROJECTS=&quot;clang;clang-tools-extra;mlir&quot; -DLLVM_BUILD_TOOLS=ON \\-DLLVM_ENABLE_RUNTIMES=&quot;openmp&quot; -DBUILD_SHARED_LIBS=OFF -DLLVM_ENABLE_EH=ON -DLLVM_ENABLE_RTTI=ON \\-DLLVM_PARALLEL_LINK_JOBS=32 -DCMAKE_INSTALL_PREFIX=&lt;install-path&gt; -DLLVM_ENABLE_DOXYGEN=OFF \\-DLLVM_ENABLE_SPHINX=OFF -DLLVM_ENABLE_LLD=OFF -DLLVM_ENABLE_BINDINGS=OFF -DLLVM_ENABLE_LIBXML2=OFF \\-DOPENMP_ENABLE_LIBOMPTARGET=OFF -DLLVM_STATIC_LINK_CXX_STDLIB=ON ../llvmcmake --build buildcmake --install build --prefix &lt;install-path&gt; 安装OpenCL-Header和OpenCL-ICD-Loader在编译前需要检查git checkout是否和DPCPP的opencl目录下的CMakeLists.txt中的tag一致。 1234567# OpenCL-Headercmake -S . -B build -DCMAKE_INSTALL_PREFIX=&lt;install-path&gt;cmake --build build --target install# OpenCL-ICD-Loadercmake -DCMAKE_PREFIX_PATH=&lt;OpenCL-Header-install-path&gt; -DCMAKE_INSTALL_PREFIX=&lt;install-path&gt; -S . -B buildcmake --build build --target install 安装PoCL配置环境变量在此之前写好环境变量： 123456789101112131415161718# OpenCL-ICD-LoaderVVV_ICD_LOADER=&lt;OpenCL-ICD-Loader-install-path&gt;export LIBRARY_PATH=${VVV_ICD_LOADER}/lib:$LIBRARY_PATHexport LD_LIBRARY_PATH=${VVV_ICD_LOADER}/lib:$LD_LIBRARY_PATH# OpenCL-HeaderVVV_OCL_HEADERS=&lt;OpenCL-Headers-install-path&gt;export CPLUS_INCLUDE_PATH=${VVV_OCL_HEADERS}/include:$CPLUS_INCLUDE_PATHexport C_INCLUDE_PATH=${VVV_OCL_HEADERS}/include:$C_INCLUDE_PATHexport PKG_CONFIG_PATH=${VVV_OCL_HEADERS}/share/pkgconfig:$PKG_CONFIG_PATH# LLVM16LLVM_PATH=&lt;LLVM-install-path&gt;export PATH=&quot;$LLVM_PATH/bin&quot;:$PATHexport LD_LIBRARY_PATH=&quot;$LLVM_PATH/lib&quot;:$LD_LIBRARY_PATH 全部 source 到环境变量中。 编译PoCL123456789cmake -G Ninja -B build -S . \\ -DENABLE_ICD=ON -DCMAKE_PREFIX_PATH=&quot;&lt;llvm-install-path&gt;;&lt;OpenCL-ICD-Loader-install-path&gt;;&lt;OpenCL-Headers-install-path&gt;&quot; \\ -DENABLE_SPIR=ON -DENABLE_SPIRV=ON -DLLVM_SPIRV=&lt;DPCPP-path&gt;/build/install/bin/llvm-spirv \\ -DCMAKE_BUILD_TYPE=RelWithDebInfo -DSTATIC_LLVM=ON -DLLC_HOST_CPU=cortex-a57 \\ -DCMAKE_INSTALL_PREFIX=&lt;pocl-install-path&gt; \\ -DCMAKE_CXX_COMPILER=clang++ \\ -DCMAKE_C_COMPILER=clangcmake --build build --target install 使用与检查编辑环境变量1234567891011121314151617181920212223242526272829303132333435363738# DPCPP envexport DPCPP_HOME=&lt;DPCPP-ROOT&gt;BASE_PATH=$DPCPP_HOME/build/installexport PATH=${BASE_PATH}/bin:$PATHexport CPLUS_INCLUDE_PATH=${BASE_PATH}/include/:$CPLUS_INCLUDE_PATHexport C_INCLUDE_PATH=${BASE_PATH}/include/:$C_INCLUDE_PATHexport CPLUS_INCLUDE_PATH=${BASE_PATH}/include/sycl:$CPLUS_INCLUDE_PATHexport C_INCLUDE_PATH=${BASE_PATH}/include/sycl:$C_INCLUDE_PATHexport LD_LIBRARY_PATH=${BASE_PATH}/lib:$LD_LIBRARY_PATHexport LIBRARY_PATH=${BASE_PATH}/lib:$LIBRARY_PATHexport CC=clang CXX=clang++# PoCL envBASE_PATH=&lt;PoCL-install-path&gt;# BINexport PATH=${BASE_PATH}/bin:$PATH# HEADERSexport CPLUS_INCLUDE_PATH=$CPLUS_INCLUDE_PATH:${BASE_PATH}/includeexport C_INCLUDE_PATH=$CPLUS_INCLUDE_PATH:${BASE_PATH}/include# LIBSexport LD_LIBRARY_PATH=${BASE_PATH}/lib:$LD_LIBRARY_PATHexport LIBRARY_PATH=${BASE_PATH}/lib:$LIBRARY_PATHexport PKG_CONFIG_PATH=${BASE_PATH}/lib/pkgconfig:$PKG_CONFIG_PATHexport OCL_ICD_VENDORS=${BASE_PATH}/etc/OpenCL/vendors# Variables for debugging programsexport VVV_pocl_help=&quot;SYCL_PI_TRACE=2 POCL_DEBUG=all OCL_ICD_ENABLE_TRACE=1&quot; 使用如果使用PoCL4，设置环境变量如下 12source env-DPCPP.shsource env-PoCL4.sh 如果使用PoCL5，设置环境变量如下 1234source env-OpenCL-Header.shsource env-OpenCL-ICD-Loader.shsource env-DPCPP.shsource env-PoCL5.sh 之后运行 sycl-ls 检查是否出现 1[opencl:cpu:0] ... 表示DPCPP运行时检测到ICD Loader，可以用PoCL作为后端将ARM CPU视为device。","link":"/2024/04/06/EnvironmentSetting/DpcppOnARM/"},{"title":"02-Measuring Memory Hierarchy","text":"缓存的行为假设CPU中有着如下的L1 cache: 在这样的cache中，连续的内存分布于不同的组。这样的一个垂直的路能够保存4096Byte；相隔4096Byte的的数据又会落入同一个组中。 访问连续的4096Byte能够填充一路中的所有组；然而如果我们每次只访问每4096Byte中的前2组中的数据，那么这个cache的有效大小就变为了原来的 $1/32$，会产生大量的cache未命中。 矩阵乘法现在考虑一个1024x1024的双精度矩阵乘法，其一行为8KB。 对于按行连续访问的情况，如果该矩阵的行是64Byte对齐的 (和cache line大小一致)，那么这样的一行能够恰好能够放在64个缓存组中，整个L1 cache能够保存4行。 如果按列连续访问的情况，每个元素间隔了8KB，这意味着最多只有8个元素能够同时驻留在L1 cache中，所以按列访问几乎会产生100%的cache失效率。如果行数不是2的幂次，那么最多也只有64个元素驻留在L1 cache中。 朴素矩阵乘法123456for (i=0; i&lt;1024; ++i)for (j=0; j&lt;1024; ++j) { double sum = 0.0f; for (k=0; k&lt;1024; ++k) sum+=a[i, k]*b[k, j] c[i, j] = sum;} 估算在真正执行程序之前，我们不妨先估算这个程序需要的执行时间。 不考虑访存，我们需要 $2^30$ (约10亿) 次乘法和加法。如果每个双精度浮点乘法和加法分别需要4个周期，处理器频率为4GHz，那么乘法和加法各需要1s，总计2s。但是考虑乘法和加法能够被FMA重叠，且流水线能够重叠增加4倍吞吐，那么所有的计算能够在 $1/4$ s结束。 现在开始考虑访存的影响。对于数组 a ，它只在第一个访问第一个元素时会发生缓存不命中。读取8MB数据需要128K个缓存行，不考虑缓存行额外的预取，则应该发生至少128K次缓存未命中。对于数组 b，它几乎全部未命中，因此估计发生了10亿次未命中。如果一次未命中需要200周期，那么访问 b 需要50s。但是事实上存在一定程度的数据复用，我们可以估算这个访存未命中的平均后开销为实际的10%，由此估算得到一个可能的时间是5~50s。 书上示例给出的运行时间为6.482s。 我自己在一个ARM v8处理器上测试为50.1896s。 交换外层循环123456for (j=0; j&lt;1024; ++j) for (i=0; i&lt;1024; ++i) { double sum = 0.0f; for (k=0; k&lt;1024; ++k) sum+=a[i, k]*b[k, j] c[i, j] = sum;} 对于最内层的循环而言，它的行为并没有改变，仍然是扫描一行和一列。a 的行能够在cache中保存多行，对于它的访存失效率或许不会有太大变化。 但是在书中给出的结果是5.115s，反而略快一些。 我自己在ARM处理器上测试结果为51.1476，考虑到性能波动，其实就是没变化。 在书中测试用的机器上，其L3缓存并没有使用 $[6:15]$ 位的地址进行组索引，而是使用了某种hash算法将这些地址中这些较低的位和较高的位一起做了一个hash，让列能够分布在L3缓存中更多的组，来降低由列引发的缓存不命中。 转置矩阵再相乘将 b 转置为 bb 后再相乘是一个可行的做法。转置 b 需要先读取一行然后写入 bb 的一列。在读 b 的一行时会发生128K次的缓存未命中，然后在按列写入的时候发生1M次缓存未命中，总共113万次左右的未命中。 此时在矩阵乘法的最内层只会访问 a 的一行和 bb 的一行，共发生128次未命中，和外面两层循环乘起来就发生了2.56亿次未命中，不足朴素实现的30%。 更快地转置 b通过每次转置8x8的小块能够更快地完成转置操作。这是因为L1 cache时8路组相联的，每一列开头的元素位于同一组不同cache line上；同时一个cache line能容纳8个double。每次读写一个8x8的小块预计会发生16次缓存未命中，总共要读写128x128个这样的小块，总共发生256K次的缓存未命中，相较原本的转置仅有25%的未命中次数。 书中的测试对两种转置分别运行了1.144s和0.579s。 矩阵分块矩阵分块指从矩阵中拿出一个nxn小块然后存到一块连续的数据中。在书中测试的平台用32x32大小的块是最合适的。这是因为两个32x32大小的块刚好能填充L1 cache的所有cache line。 从快速转置中可知，这样分块的复制过程会产生256K次未命中，总共发生了1024次这样的分块，总共产生了256M (约2.56亿) 未命中。相较于初始版本的缓存为命中大幅度地下降。 书中的测试结果为0.392s，距离理论极限的0.25s已经比较接近了。","link":"/2024/04/16/PerformanceMeasuring/03-CPUandMemory/"}],"tags":[],"categories":[{"name":"hexo","slug":"hexo","link":"/categories/hexo/"},{"name":"Modern CPP","slug":"Modern-CPP","link":"/categories/Modern-CPP/"},{"name":"vim","slug":"vim","link":"/categories/vim/"},{"name":"git","slug":"git","link":"/categories/git/"},{"name":"Writing","slug":"Writing","link":"/categories/Writing/"},{"name":"LLVM","slug":"LLVM","link":"/categories/LLVM/"},{"name":"LLVM Meetings","slug":"LLVM-Meetings","link":"/categories/LLVM-Meetings/"},{"name":"CMAKE","slug":"CMAKE","link":"/categories/CMAKE/"},{"name":"MLIR","slug":"MLIR","link":"/categories/MLIR/"},{"name":"PFPL","slug":"PFPL","link":"/categories/PFPL/"},{"name":"Performance Profiling","slug":"Performance-Profiling","link":"/categories/Performance-Profiling/"},{"name":"Polyhedral","slug":"Polyhedral","link":"/categories/Polyhedral/"},{"name":"Design Patterns in CPP","slug":"Design-Patterns-in-CPP","link":"/categories/Design-Patterns-in-CPP/"},{"name":"Benchmarks","slug":"Benchmarks","link":"/categories/Benchmarks/"},{"name":"Assembly Language","slug":"Assembly-Language","link":"/categories/Assembly-Language/"},{"name":"环境配置","slug":"环境配置","link":"/categories/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"}],"pages":[{"title":"categories","text":"","link":"/categories/index.html"}]}